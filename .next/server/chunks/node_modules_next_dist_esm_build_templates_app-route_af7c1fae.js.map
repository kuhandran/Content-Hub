{"version":3,"sources":["../../../app/api/admin/content/route.js","../../../node_modules/next/dist/esm/build/templates/app-route.js","../../../node_modules/iceberg-js/src/errors/IcebergError.ts","../../../node_modules/next/src/build/templates/app-route.ts","../../../node_modules/%40supabase/storage-js/src/lib/errors.ts","../../../node_modules/%40supabase/postgrest-js/src/PostgrestError.ts","../../../node_modules/%40supabase/supabase-js/src/lib/version.ts","../../../node_modules/%40supabase/supabase-js/src/lib/constants.ts","../../../node_modules/%40supabase/postgrest-js/src/PostgrestBuilder.ts","../../../node_modules/iceberg-js/src/utils/url.ts","../../../node_modules/%40supabase/storage-js/src/lib/helpers.ts","../../../node_modules/iceberg-js/src/http/createFetchClient.ts","../../../node_modules/%40supabase/supabase-js/src/lib/fetch.ts","../../../node_modules/iceberg-js/src/catalog/namespaces.ts","../../../node_modules/%40supabase/supabase-js/src/lib/helpers.ts","../../../node_modules/%40supabase/storage-js/src/lib/fetch.ts","../../../node_modules/%40supabase/supabase-js/src/lib/SupabaseAuthClient.ts","../../../node_modules/%40supabase/supabase-js/src/SupabaseClient.ts","../../../node_modules/iceberg-js/src/catalog/tables.ts","../../../node_modules/%40supabase/storage-js/src/packages/StreamDownloadBuilder.ts","../../../node_modules/%40supabase/postgrest-js/src/PostgrestTransformBuilder.ts","../../../node_modules/%40supabase/storage-js/src/packages/BlobDownloadBuilder.ts","../../../node_modules/iceberg-js/src/catalog/IcebergRestCatalog.ts","../../../node_modules/%40supabase/storage-js/src/packages/StorageFileApi.ts","../../../node_modules/%40supabase/supabase-js/src/index.ts","../../../node_modules/%40supabase/postgrest-js/src/PostgrestFilterBuilder.ts","../../../node_modules/iceberg-js/src/catalog/types.ts","../../../node_modules/%40supabase/postgrest-js/src/PostgrestQueryBuilder.ts","../../../node_modules/%40supabase/postgrest-js/src/PostgrestClient.ts","../../../node_modules/%40supabase/storage-js/src/lib/version.ts","../../../node_modules/%40supabase/storage-js/src/lib/constants.ts","../../../node_modules/%40supabase/storage-js/src/packages/StorageBucketApi.ts","../../../node_modules/%40supabase/postgrest-js/src/index.ts","../../../node_modules/%40supabase/storage-js/src/packages/StorageAnalyticsClient.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/constants.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/errors.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/helpers.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/fetch.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/VectorIndexApi.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/VectorDataApi.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/VectorBucketApi.ts","../../../node_modules/%40supabase/storage-js/src/lib/vectors/StorageVectorsClient.ts","../../../node_modules/%40supabase/storage-js/src/StorageClient.ts"],"sourcesContent":["/**\n * app/api/admin/content/route.js\n * Admin content editor â€“ upsert JSON/text records into Supabase tables.\n * Supports: collections (lang/type scoped), config_files, data_files, static_files, javascript_files.\n */\n\nimport { NextResponse } from 'next/server';\nimport { createClient } from '@supabase/supabase-js';\n\nconst supabase = createClient(\n  process.env.SUPABASE_URL || '',\n  process.env.SUPABASE_SERVICE_ROLE_KEY || ''\n);\n\nconst TABLE_CONFIG = {\n  collections: { type: 'json', conflict: 'lang,type,filename' },\n  config_files: { type: 'json', conflict: 'filename' },\n  data_files: { type: 'json', conflict: 'filename' },\n  static_files: { type: 'text', conflict: 'filename' },\n  javascript_files: { type: 'text', conflict: 'filename' },\n};\n\nfunction validateRequest(body) {\n  const { table, filename, lang, type } = body;\n  if (!table || !TABLE_CONFIG[table]) return 'Invalid table';\n  if (!filename) return 'filename is required';\n  if (table === 'collections' && (!lang || !type)) return 'lang and type are required for collections';\n  return null;\n}\n\nexport async function POST(request) {\n  try {\n    const body = await request.json();\n    const errorMsg = validateRequest(body);\n    if (errorMsg) return NextResponse.json({ status: 'error', message: errorMsg }, { status: 400 });\n\n    const { table, filename, lang, type, content } = body;\n    const cfg = TABLE_CONFIG[table];\n    const now = new Date().toISOString();\n\n    let payload;\n    if (cfg.type === 'json') {\n      let parsed;\n      try {\n        parsed = typeof content === 'string' ? JSON.parse(content) : content;\n      } catch (e) {\n        return NextResponse.json({ status: 'error', message: 'Content must be valid JSON' }, { status: 400 });\n      }\n      if (table === 'collections') {\n        payload = { lang, type, filename, file_content: parsed, updated_at: now, synced_at: now };\n      } else {\n        payload = { filename, file_type: 'json', file_content: parsed, updated_at: now, synced_at: now };\n      }\n    } else {\n      // text/static/js\n      payload = { filename, file_type: 'text', file_content: content || '', updated_at: now, synced_at: now };\n    }\n\n    const { error } = await supabase\n      .from(table)\n      .upsert(payload, { onConflict: cfg.conflict, ignoreDuplicates: false });\n\n    if (error) {\n      return NextResponse.json({ status: 'error', message: error.message }, { status: 500 });\n    }\n\n    return NextResponse.json({ status: 'success', table, filename, updated_at: now });\n  } catch (error) {\n    return NextResponse.json({ status: 'error', message: error.message }, { status: 500 });\n  }\n}\n","import { AppRouteRouteModule } from \"next/dist/esm/server/route-modules/app-route/module.compiled\";\nimport { RouteKind } from \"next/dist/esm/server/route-kind\";\nimport { patchFetch as _patchFetch } from \"next/dist/esm/server/lib/patch-fetch\";\nimport { addRequestMeta, getRequestMeta } from \"next/dist/esm/server/request-meta\";\nimport { getTracer, SpanKind } from \"next/dist/esm/server/lib/trace/tracer\";\nimport { setManifestsSingleton } from \"next/dist/esm/server/app-render/manifests-singleton\";\nimport { normalizeAppPath } from \"next/dist/esm/shared/lib/router/utils/app-paths\";\nimport { NodeNextRequest, NodeNextResponse } from \"next/dist/esm/server/base-http/node\";\nimport { NextRequestAdapter, signalFromNodeResponse } from \"next/dist/esm/server/web/spec-extension/adapters/next-request\";\nimport { BaseServerSpan } from \"next/dist/esm/server/lib/trace/constants\";\nimport { getRevalidateReason } from \"next/dist/esm/server/instrumentation/utils\";\nimport { sendResponse } from \"next/dist/esm/server/send-response\";\nimport { fromNodeOutgoingHttpHeaders, toNodeOutgoingHttpHeaders } from \"next/dist/esm/server/web/utils\";\nimport { getCacheControlHeader } from \"next/dist/esm/server/lib/cache-control\";\nimport { INFINITE_CACHE, NEXT_CACHE_TAGS_HEADER } from \"next/dist/esm/lib/constants\";\nimport { NoFallbackError } from \"next/dist/esm/shared/lib/no-fallback-error.external\";\nimport { CachedRouteKind } from \"next/dist/esm/server/response-cache\";\nimport * as userland from \"INNER_APP_ROUTE\";\n// We inject the nextConfigOutput here so that we can use them in the route\n// module.\nconst nextConfigOutput = \"\"\nconst routeModule = new AppRouteRouteModule({\n    definition: {\n        kind: RouteKind.APP_ROUTE,\n        page: \"/api/admin/content/route\",\n        pathname: \"/api/admin/content\",\n        filename: \"route\",\n        bundlePath: \"\"\n    },\n    distDir: process.env.__NEXT_RELATIVE_DIST_DIR || '',\n    relativeProjectDir: process.env.__NEXT_RELATIVE_PROJECT_DIR || '',\n    resolvedPagePath: \"[project]/app/api/admin/content/route.js\",\n    nextConfigOutput,\n    userland\n});\n// Pull out the exports that we need to expose from the module. This should\n// be eliminated when we've moved the other routes to the new format. These\n// are used to hook into the route.\nconst { workAsyncStorage, workUnitAsyncStorage, serverHooks } = routeModule;\nfunction patchFetch() {\n    return _patchFetch({\n        workAsyncStorage,\n        workUnitAsyncStorage\n    });\n}\nexport { routeModule, workAsyncStorage, workUnitAsyncStorage, serverHooks, patchFetch,  };\nexport async function handler(req, res, ctx) {\n    if (routeModule.isDev) {\n        addRequestMeta(req, 'devRequestTimingInternalsEnd', process.hrtime.bigint());\n    }\n    let srcPage = \"/api/admin/content/route\";\n    // turbopack doesn't normalize `/index` in the page name\n    // so we need to to process dynamic routes properly\n    // TODO: fix turbopack providing differing value from webpack\n    if (process.env.TURBOPACK) {\n        srcPage = srcPage.replace(/\\/index$/, '') || '/';\n    } else if (srcPage === '/index') {\n        // we always normalize /index specifically\n        srcPage = '/';\n    }\n    const multiZoneDraftMode = process.env.__NEXT_MULTI_ZONE_DRAFT_MODE;\n    const prepareResult = await routeModule.prepare(req, res, {\n        srcPage,\n        multiZoneDraftMode\n    });\n    if (!prepareResult) {\n        res.statusCode = 400;\n        res.end('Bad Request');\n        ctx.waitUntil == null ? void 0 : ctx.waitUntil.call(ctx, Promise.resolve());\n        return null;\n    }\n    const { buildId, params, nextConfig, parsedUrl, isDraftMode, prerenderManifest, routerServerContext, isOnDemandRevalidate, revalidateOnlyGenerated, resolvedPathname, clientReferenceManifest, serverActionsManifest } = prepareResult;\n    const normalizedSrcPage = normalizeAppPath(srcPage);\n    let isIsr = Boolean(prerenderManifest.dynamicRoutes[normalizedSrcPage] || prerenderManifest.routes[resolvedPathname]);\n    const render404 = async ()=>{\n        // TODO: should route-module itself handle rendering the 404\n        if (routerServerContext == null ? void 0 : routerServerContext.render404) {\n            await routerServerContext.render404(req, res, parsedUrl, false);\n        } else {\n            res.end('This page could not be found');\n        }\n        return null;\n    };\n    if (isIsr && !isDraftMode) {\n        const isPrerendered = Boolean(prerenderManifest.routes[resolvedPathname]);\n        const prerenderInfo = prerenderManifest.dynamicRoutes[normalizedSrcPage];\n        if (prerenderInfo) {\n            if (prerenderInfo.fallback === false && !isPrerendered) {\n                if (nextConfig.experimental.adapterPath) {\n                    return await render404();\n                }\n                throw new NoFallbackError();\n            }\n        }\n    }\n    let cacheKey = null;\n    if (isIsr && !routeModule.isDev && !isDraftMode) {\n        cacheKey = resolvedPathname;\n        // ensure /index and / is normalized to one key\n        cacheKey = cacheKey === '/index' ? '/' : cacheKey;\n    }\n    const supportsDynamicResponse = // If we're in development, we always support dynamic HTML\n    routeModule.isDev === true || // If this is not SSG or does not have static paths, then it supports\n    // dynamic HTML.\n    !isIsr;\n    // This is a revalidation request if the request is for a static\n    // page and it is not being resumed from a postponed render and\n    // it is not a dynamic RSC request then it is a revalidation\n    // request.\n    const isStaticGeneration = isIsr && !supportsDynamicResponse;\n    // Before rendering (which initializes component tree modules), we have to\n    // set the reference manifests to our global store so Server Action's\n    // encryption util can access to them at the top level of the page module.\n    if (serverActionsManifest && clientReferenceManifest) {\n        setManifestsSingleton({\n            page: srcPage,\n            clientReferenceManifest,\n            serverActionsManifest\n        });\n    }\n    const method = req.method || 'GET';\n    const tracer = getTracer();\n    const activeSpan = tracer.getActiveScopeSpan();\n    const context = {\n        params,\n        prerenderManifest,\n        renderOpts: {\n            experimental: {\n                authInterrupts: Boolean(nextConfig.experimental.authInterrupts)\n            },\n            cacheComponents: Boolean(nextConfig.cacheComponents),\n            supportsDynamicResponse,\n            incrementalCache: getRequestMeta(req, 'incrementalCache'),\n            cacheLifeProfiles: nextConfig.cacheLife,\n            waitUntil: ctx.waitUntil,\n            onClose: (cb)=>{\n                res.on('close', cb);\n            },\n            onAfterTaskError: undefined,\n            onInstrumentationRequestError: (error, _request, errorContext, silenceLog)=>routeModule.onRequestError(req, error, errorContext, silenceLog, routerServerContext)\n        },\n        sharedContext: {\n            buildId\n        }\n    };\n    const nodeNextReq = new NodeNextRequest(req);\n    const nodeNextRes = new NodeNextResponse(res);\n    const nextReq = NextRequestAdapter.fromNodeNextRequest(nodeNextReq, signalFromNodeResponse(res));\n    try {\n        const invokeRouteModule = async (span)=>{\n            return routeModule.handle(nextReq, context).finally(()=>{\n                if (!span) return;\n                span.setAttributes({\n                    'http.status_code': res.statusCode,\n                    'next.rsc': false\n                });\n                const rootSpanAttributes = tracer.getRootSpanAttributes();\n                // We were unable to get attributes, probably OTEL is not enabled\n                if (!rootSpanAttributes) {\n                    return;\n                }\n                if (rootSpanAttributes.get('next.span_type') !== BaseServerSpan.handleRequest) {\n                    console.warn(`Unexpected root span type '${rootSpanAttributes.get('next.span_type')}'. Please report this Next.js issue https://github.com/vercel/next.js`);\n                    return;\n                }\n                const route = rootSpanAttributes.get('next.route');\n                if (route) {\n                    const name = `${method} ${route}`;\n                    span.setAttributes({\n                        'next.route': route,\n                        'http.route': route,\n                        'next.span_name': name\n                    });\n                    span.updateName(name);\n                } else {\n                    span.updateName(`${method} ${srcPage}`);\n                }\n            });\n        };\n        const isMinimalMode = Boolean(process.env.MINIMAL_MODE || getRequestMeta(req, 'minimalMode'));\n        const handleResponse = async (currentSpan)=>{\n            var _cacheEntry_value;\n            const responseGenerator = async ({ previousCacheEntry })=>{\n                try {\n                    if (!isMinimalMode && isOnDemandRevalidate && revalidateOnlyGenerated && !previousCacheEntry) {\n                        res.statusCode = 404;\n                        // on-demand revalidate always sets this header\n                        res.setHeader('x-nextjs-cache', 'REVALIDATED');\n                        res.end('This page could not be found');\n                        return null;\n                    }\n                    const response = await invokeRouteModule(currentSpan);\n                    req.fetchMetrics = context.renderOpts.fetchMetrics;\n                    let pendingWaitUntil = context.renderOpts.pendingWaitUntil;\n                    // Attempt using provided waitUntil if available\n                    // if it's not we fallback to sendResponse's handling\n                    if (pendingWaitUntil) {\n                        if (ctx.waitUntil) {\n                            ctx.waitUntil(pendingWaitUntil);\n                            pendingWaitUntil = undefined;\n                        }\n                    }\n                    const cacheTags = context.renderOpts.collectedTags;\n                    // If the request is for a static response, we can cache it so long\n                    // as it's not edge.\n                    if (isIsr) {\n                        const blob = await response.blob();\n                        // Copy the headers from the response.\n                        const headers = toNodeOutgoingHttpHeaders(response.headers);\n                        if (cacheTags) {\n                            headers[NEXT_CACHE_TAGS_HEADER] = cacheTags;\n                        }\n                        if (!headers['content-type'] && blob.type) {\n                            headers['content-type'] = blob.type;\n                        }\n                        const revalidate = typeof context.renderOpts.collectedRevalidate === 'undefined' || context.renderOpts.collectedRevalidate >= INFINITE_CACHE ? false : context.renderOpts.collectedRevalidate;\n                        const expire = typeof context.renderOpts.collectedExpire === 'undefined' || context.renderOpts.collectedExpire >= INFINITE_CACHE ? undefined : context.renderOpts.collectedExpire;\n                        // Create the cache entry for the response.\n                        const cacheEntry = {\n                            value: {\n                                kind: CachedRouteKind.APP_ROUTE,\n                                status: response.status,\n                                body: Buffer.from(await blob.arrayBuffer()),\n                                headers\n                            },\n                            cacheControl: {\n                                revalidate,\n                                expire\n                            }\n                        };\n                        return cacheEntry;\n                    } else {\n                        // send response without caching if not ISR\n                        await sendResponse(nodeNextReq, nodeNextRes, response, context.renderOpts.pendingWaitUntil);\n                        return null;\n                    }\n                } catch (err) {\n                    // if this is a background revalidate we need to report\n                    // the request error here as it won't be bubbled\n                    if (previousCacheEntry == null ? void 0 : previousCacheEntry.isStale) {\n                        const silenceLog = false;\n                        await routeModule.onRequestError(req, err, {\n                            routerKind: 'App Router',\n                            routePath: srcPage,\n                            routeType: 'route',\n                            revalidateReason: getRevalidateReason({\n                                isStaticGeneration,\n                                isOnDemandRevalidate\n                            })\n                        }, silenceLog, routerServerContext);\n                    }\n                    throw err;\n                }\n            };\n            const cacheEntry = await routeModule.handleResponse({\n                req,\n                nextConfig,\n                cacheKey,\n                routeKind: RouteKind.APP_ROUTE,\n                isFallback: false,\n                prerenderManifest,\n                isRoutePPREnabled: false,\n                isOnDemandRevalidate,\n                revalidateOnlyGenerated,\n                responseGenerator,\n                waitUntil: ctx.waitUntil,\n                isMinimalMode\n            });\n            // we don't create a cacheEntry for ISR\n            if (!isIsr) {\n                return null;\n            }\n            if ((cacheEntry == null ? void 0 : (_cacheEntry_value = cacheEntry.value) == null ? void 0 : _cacheEntry_value.kind) !== CachedRouteKind.APP_ROUTE) {\n                var _cacheEntry_value1;\n                throw Object.defineProperty(new Error(`Invariant: app-route received invalid cache entry ${cacheEntry == null ? void 0 : (_cacheEntry_value1 = cacheEntry.value) == null ? void 0 : _cacheEntry_value1.kind}`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E701\",\n                    enumerable: false,\n                    configurable: true\n                });\n            }\n            if (!isMinimalMode) {\n                res.setHeader('x-nextjs-cache', isOnDemandRevalidate ? 'REVALIDATED' : cacheEntry.isMiss ? 'MISS' : cacheEntry.isStale ? 'STALE' : 'HIT');\n            }\n            // Draft mode should never be cached\n            if (isDraftMode) {\n                res.setHeader('Cache-Control', 'private, no-cache, no-store, max-age=0, must-revalidate');\n            }\n            const headers = fromNodeOutgoingHttpHeaders(cacheEntry.value.headers);\n            if (!(isMinimalMode && isIsr)) {\n                headers.delete(NEXT_CACHE_TAGS_HEADER);\n            }\n            // If cache control is already set on the response we don't\n            // override it to allow users to customize it via next.config\n            if (cacheEntry.cacheControl && !res.getHeader('Cache-Control') && !headers.get('Cache-Control')) {\n                headers.set('Cache-Control', getCacheControlHeader(cacheEntry.cacheControl));\n            }\n            await sendResponse(nodeNextReq, nodeNextRes, // @ts-expect-error - Argument of type 'Buffer<ArrayBufferLike>' is not assignable to parameter of type 'BodyInit | null | undefined'.\n            new Response(cacheEntry.value.body, {\n                headers,\n                status: cacheEntry.value.status || 200\n            }));\n            return null;\n        };\n        // TODO: activeSpan code path is for when wrapped by\n        // next-server can be removed when this is no longer used\n        if (activeSpan) {\n            await handleResponse(activeSpan);\n        } else {\n            await tracer.withPropagatedContext(req.headers, ()=>tracer.trace(BaseServerSpan.handleRequest, {\n                    spanName: `${method} ${srcPage}`,\n                    kind: SpanKind.SERVER,\n                    attributes: {\n                        'http.method': method,\n                        'http.target': req.url\n                    }\n                }, handleResponse));\n        }\n    } catch (err) {\n        if (!(err instanceof NoFallbackError)) {\n            const silenceLog = false;\n            await routeModule.onRequestError(req, err, {\n                routerKind: 'App Router',\n                routePath: normalizedSrcPage,\n                routeType: 'route',\n                revalidateReason: getRevalidateReason({\n                    isStaticGeneration,\n                    isOnDemandRevalidate\n                })\n            }, silenceLog, routerServerContext);\n        }\n        // rethrow so that we can handle serving error page\n        // If this is during static generation, throw the error again.\n        if (isIsr) throw err;\n        // Otherwise, send a 500 response.\n        await sendResponse(nodeNextReq, nodeNextRes, new Response(null, {\n            status: 500\n        }));\n        return null;\n    }\n}\n\n//# sourceMappingURL=app-route.js.map\n","export interface IcebergErrorResponse {\n  error: {\n    message: string\n    type: string\n    code: number\n    stack?: string[]\n  }\n}\n\nexport class IcebergError extends Error {\n  readonly status: number\n  readonly icebergType?: string\n  readonly icebergCode?: number\n  readonly details?: unknown\n  readonly isCommitStateUnknown: boolean\n\n  constructor(\n    message: string,\n    opts: {\n      status: number\n      icebergType?: string\n      icebergCode?: number\n      details?: unknown\n    }\n  ) {\n    super(message)\n    this.name = 'IcebergError'\n    this.status = opts.status\n    this.icebergType = opts.icebergType\n    this.icebergCode = opts.icebergCode\n    this.details = opts.details\n\n    // Detect CommitStateUnknownException (500, 502, 504 during table commits)\n    this.isCommitStateUnknown =\n      opts.icebergType === 'CommitStateUnknownException' ||\n      ([500, 502, 504].includes(opts.status) && opts.icebergType?.includes('CommitState') === true)\n  }\n\n  /**\n   * Returns true if the error is a 404 Not Found error.\n   */\n  isNotFound(): boolean {\n    return this.status === 404\n  }\n\n  /**\n   * Returns true if the error is a 409 Conflict error.\n   */\n  isConflict(): boolean {\n    return this.status === 409\n  }\n\n  /**\n   * Returns true if the error is a 419 Authentication Timeout error.\n   */\n  isAuthenticationTimeout(): boolean {\n    return this.status === 419\n  }\n}\n","import {\n  AppRouteRouteModule,\n  type AppRouteRouteHandlerContext,\n  type AppRouteRouteModuleOptions,\n} from '../../server/route-modules/app-route/module.compiled'\nimport { RouteKind } from '../../server/route-kind'\nimport { patchFetch as _patchFetch } from '../../server/lib/patch-fetch'\nimport type { IncomingMessage, ServerResponse } from 'node:http'\nimport { addRequestMeta, getRequestMeta } from '../../server/request-meta'\nimport { getTracer, type Span, SpanKind } from '../../server/lib/trace/tracer'\nimport { setManifestsSingleton } from '../../server/app-render/manifests-singleton'\nimport { normalizeAppPath } from '../../shared/lib/router/utils/app-paths'\nimport { NodeNextRequest, NodeNextResponse } from '../../server/base-http/node'\nimport {\n  NextRequestAdapter,\n  signalFromNodeResponse,\n} from '../../server/web/spec-extension/adapters/next-request'\nimport { BaseServerSpan } from '../../server/lib/trace/constants'\nimport { getRevalidateReason } from '../../server/instrumentation/utils'\nimport { sendResponse } from '../../server/send-response'\nimport {\n  fromNodeOutgoingHttpHeaders,\n  toNodeOutgoingHttpHeaders,\n} from '../../server/web/utils'\nimport { getCacheControlHeader } from '../../server/lib/cache-control'\nimport { INFINITE_CACHE, NEXT_CACHE_TAGS_HEADER } from '../../lib/constants'\nimport { NoFallbackError } from '../../shared/lib/no-fallback-error.external'\nimport {\n  CachedRouteKind,\n  type ResponseCacheEntry,\n  type ResponseGenerator,\n} from '../../server/response-cache'\n\nimport * as userland from 'VAR_USERLAND'\n\n// These are injected by the loader afterwards. This is injected as a variable\n// instead of a replacement because this could also be `undefined` instead of\n// an empty string.\ndeclare const nextConfigOutput: AppRouteRouteModuleOptions['nextConfigOutput']\n\n// We inject the nextConfigOutput here so that we can use them in the route\n// module.\n// INJECT:nextConfigOutput\n\nconst routeModule = new AppRouteRouteModule({\n  definition: {\n    kind: RouteKind.APP_ROUTE,\n    page: 'VAR_DEFINITION_PAGE',\n    pathname: 'VAR_DEFINITION_PATHNAME',\n    filename: 'VAR_DEFINITION_FILENAME',\n    bundlePath: 'VAR_DEFINITION_BUNDLE_PATH',\n  },\n  distDir: process.env.__NEXT_RELATIVE_DIST_DIR || '',\n  relativeProjectDir: process.env.__NEXT_RELATIVE_PROJECT_DIR || '',\n  resolvedPagePath: 'VAR_RESOLVED_PAGE_PATH',\n  nextConfigOutput,\n  userland,\n})\n\n// Pull out the exports that we need to expose from the module. This should\n// be eliminated when we've moved the other routes to the new format. These\n// are used to hook into the route.\nconst { workAsyncStorage, workUnitAsyncStorage, serverHooks } = routeModule\n\nfunction patchFetch() {\n  return _patchFetch({\n    workAsyncStorage,\n    workUnitAsyncStorage,\n  })\n}\n\nexport {\n  routeModule,\n  workAsyncStorage,\n  workUnitAsyncStorage,\n  serverHooks,\n  patchFetch,\n}\n\nexport async function handler(\n  req: IncomingMessage,\n  res: ServerResponse,\n  ctx: {\n    waitUntil: (prom: Promise<void>) => void\n  }\n) {\n  if (routeModule.isDev) {\n    addRequestMeta(req, 'devRequestTimingInternalsEnd', process.hrtime.bigint())\n  }\n  let srcPage = 'VAR_DEFINITION_PAGE'\n\n  // turbopack doesn't normalize `/index` in the page name\n  // so we need to to process dynamic routes properly\n  // TODO: fix turbopack providing differing value from webpack\n  if (process.env.TURBOPACK) {\n    srcPage = srcPage.replace(/\\/index$/, '') || '/'\n  } else if (srcPage === '/index') {\n    // we always normalize /index specifically\n    srcPage = '/'\n  }\n  const multiZoneDraftMode = process.env\n    .__NEXT_MULTI_ZONE_DRAFT_MODE as any as boolean\n\n  const prepareResult = await routeModule.prepare(req, res, {\n    srcPage,\n    multiZoneDraftMode,\n  })\n\n  if (!prepareResult) {\n    res.statusCode = 400\n    res.end('Bad Request')\n    ctx.waitUntil?.(Promise.resolve())\n    return null\n  }\n\n  const {\n    buildId,\n    params,\n    nextConfig,\n    parsedUrl,\n    isDraftMode,\n    prerenderManifest,\n    routerServerContext,\n    isOnDemandRevalidate,\n    revalidateOnlyGenerated,\n    resolvedPathname,\n    clientReferenceManifest,\n    serverActionsManifest,\n  } = prepareResult\n\n  const normalizedSrcPage = normalizeAppPath(srcPage)\n\n  let isIsr = Boolean(\n    prerenderManifest.dynamicRoutes[normalizedSrcPage] ||\n      prerenderManifest.routes[resolvedPathname]\n  )\n\n  const render404 = async () => {\n    // TODO: should route-module itself handle rendering the 404\n    if (routerServerContext?.render404) {\n      await routerServerContext.render404(req, res, parsedUrl, false)\n    } else {\n      res.end('This page could not be found')\n    }\n    return null\n  }\n\n  if (isIsr && !isDraftMode) {\n    const isPrerendered = Boolean(prerenderManifest.routes[resolvedPathname])\n    const prerenderInfo = prerenderManifest.dynamicRoutes[normalizedSrcPage]\n\n    if (prerenderInfo) {\n      if (prerenderInfo.fallback === false && !isPrerendered) {\n        if (nextConfig.experimental.adapterPath) {\n          return await render404()\n        }\n        throw new NoFallbackError()\n      }\n    }\n  }\n\n  let cacheKey: string | null = null\n\n  if (isIsr && !routeModule.isDev && !isDraftMode) {\n    cacheKey = resolvedPathname\n    // ensure /index and / is normalized to one key\n    cacheKey = cacheKey === '/index' ? '/' : cacheKey\n  }\n\n  const supportsDynamicResponse: boolean =\n    // If we're in development, we always support dynamic HTML\n    routeModule.isDev === true ||\n    // If this is not SSG or does not have static paths, then it supports\n    // dynamic HTML.\n    !isIsr\n\n  // This is a revalidation request if the request is for a static\n  // page and it is not being resumed from a postponed render and\n  // it is not a dynamic RSC request then it is a revalidation\n  // request.\n  const isStaticGeneration = isIsr && !supportsDynamicResponse\n\n  // Before rendering (which initializes component tree modules), we have to\n  // set the reference manifests to our global store so Server Action's\n  // encryption util can access to them at the top level of the page module.\n  if (serverActionsManifest && clientReferenceManifest) {\n    setManifestsSingleton({\n      page: srcPage,\n      clientReferenceManifest,\n      serverActionsManifest,\n    })\n  }\n\n  const method = req.method || 'GET'\n  const tracer = getTracer()\n  const activeSpan = tracer.getActiveScopeSpan()\n\n  const context: AppRouteRouteHandlerContext = {\n    params,\n    prerenderManifest,\n    renderOpts: {\n      experimental: {\n        authInterrupts: Boolean(nextConfig.experimental.authInterrupts),\n      },\n      cacheComponents: Boolean(nextConfig.cacheComponents),\n      supportsDynamicResponse,\n      incrementalCache: getRequestMeta(req, 'incrementalCache'),\n      cacheLifeProfiles: nextConfig.cacheLife,\n      waitUntil: ctx.waitUntil,\n      onClose: (cb) => {\n        res.on('close', cb)\n      },\n      onAfterTaskError: undefined,\n      onInstrumentationRequestError: (\n        error,\n        _request,\n        errorContext,\n        silenceLog\n      ) =>\n        routeModule.onRequestError(\n          req,\n          error,\n          errorContext,\n          silenceLog,\n          routerServerContext\n        ),\n    },\n    sharedContext: {\n      buildId,\n    },\n  }\n  const nodeNextReq = new NodeNextRequest(req)\n  const nodeNextRes = new NodeNextResponse(res)\n\n  const nextReq = NextRequestAdapter.fromNodeNextRequest(\n    nodeNextReq,\n    signalFromNodeResponse(res)\n  )\n\n  try {\n    const invokeRouteModule = async (span?: Span) => {\n      return routeModule.handle(nextReq, context).finally(() => {\n        if (!span) return\n\n        span.setAttributes({\n          'http.status_code': res.statusCode,\n          'next.rsc': false,\n        })\n\n        const rootSpanAttributes = tracer.getRootSpanAttributes()\n        // We were unable to get attributes, probably OTEL is not enabled\n        if (!rootSpanAttributes) {\n          return\n        }\n\n        if (\n          rootSpanAttributes.get('next.span_type') !==\n          BaseServerSpan.handleRequest\n        ) {\n          console.warn(\n            `Unexpected root span type '${rootSpanAttributes.get(\n              'next.span_type'\n            )}'. Please report this Next.js issue https://github.com/vercel/next.js`\n          )\n          return\n        }\n\n        const route = rootSpanAttributes.get('next.route')\n        if (route) {\n          const name = `${method} ${route}`\n\n          span.setAttributes({\n            'next.route': route,\n            'http.route': route,\n            'next.span_name': name,\n          })\n          span.updateName(name)\n        } else {\n          span.updateName(`${method} ${srcPage}`)\n        }\n      })\n    }\n    const isMinimalMode = Boolean(\n      process.env.MINIMAL_MODE || getRequestMeta(req, 'minimalMode')\n    )\n\n    const handleResponse = async (currentSpan?: Span) => {\n      const responseGenerator: ResponseGenerator = async ({\n        previousCacheEntry,\n      }) => {\n        try {\n          if (\n            !isMinimalMode &&\n            isOnDemandRevalidate &&\n            revalidateOnlyGenerated &&\n            !previousCacheEntry\n          ) {\n            res.statusCode = 404\n            // on-demand revalidate always sets this header\n            res.setHeader('x-nextjs-cache', 'REVALIDATED')\n            res.end('This page could not be found')\n            return null\n          }\n\n          const response = await invokeRouteModule(currentSpan)\n\n          ;(req as any).fetchMetrics = (context.renderOpts as any).fetchMetrics\n          let pendingWaitUntil = context.renderOpts.pendingWaitUntil\n\n          // Attempt using provided waitUntil if available\n          // if it's not we fallback to sendResponse's handling\n          if (pendingWaitUntil) {\n            if (ctx.waitUntil) {\n              ctx.waitUntil(pendingWaitUntil)\n              pendingWaitUntil = undefined\n            }\n          }\n          const cacheTags = context.renderOpts.collectedTags\n\n          // If the request is for a static response, we can cache it so long\n          // as it's not edge.\n          if (isIsr) {\n            const blob = await response.blob()\n\n            // Copy the headers from the response.\n            const headers = toNodeOutgoingHttpHeaders(response.headers)\n\n            if (cacheTags) {\n              headers[NEXT_CACHE_TAGS_HEADER] = cacheTags\n            }\n\n            if (!headers['content-type'] && blob.type) {\n              headers['content-type'] = blob.type\n            }\n\n            const revalidate =\n              typeof context.renderOpts.collectedRevalidate === 'undefined' ||\n              context.renderOpts.collectedRevalidate >= INFINITE_CACHE\n                ? false\n                : context.renderOpts.collectedRevalidate\n\n            const expire =\n              typeof context.renderOpts.collectedExpire === 'undefined' ||\n              context.renderOpts.collectedExpire >= INFINITE_CACHE\n                ? undefined\n                : context.renderOpts.collectedExpire\n\n            // Create the cache entry for the response.\n            const cacheEntry: ResponseCacheEntry = {\n              value: {\n                kind: CachedRouteKind.APP_ROUTE,\n                status: response.status,\n                body: Buffer.from(await blob.arrayBuffer()),\n                headers,\n              },\n              cacheControl: { revalidate, expire },\n            }\n\n            return cacheEntry\n          } else {\n            // send response without caching if not ISR\n            await sendResponse(\n              nodeNextReq,\n              nodeNextRes,\n              response,\n              context.renderOpts.pendingWaitUntil\n            )\n            return null\n          }\n        } catch (err) {\n          // if this is a background revalidate we need to report\n          // the request error here as it won't be bubbled\n          if (previousCacheEntry?.isStale) {\n            const silenceLog = false\n            await routeModule.onRequestError(\n              req,\n              err,\n              {\n                routerKind: 'App Router',\n                routePath: srcPage,\n                routeType: 'route',\n                revalidateReason: getRevalidateReason({\n                  isStaticGeneration,\n                  isOnDemandRevalidate,\n                }),\n              },\n              silenceLog,\n              routerServerContext\n            )\n          }\n          throw err\n        }\n      }\n\n      const cacheEntry = await routeModule.handleResponse({\n        req,\n        nextConfig,\n        cacheKey,\n        routeKind: RouteKind.APP_ROUTE,\n        isFallback: false,\n        prerenderManifest,\n        isRoutePPREnabled: false,\n        isOnDemandRevalidate,\n        revalidateOnlyGenerated,\n        responseGenerator,\n        waitUntil: ctx.waitUntil,\n        isMinimalMode,\n      })\n\n      // we don't create a cacheEntry for ISR\n      if (!isIsr) {\n        return null\n      }\n\n      if (cacheEntry?.value?.kind !== CachedRouteKind.APP_ROUTE) {\n        throw new Error(\n          `Invariant: app-route received invalid cache entry ${cacheEntry?.value?.kind}`\n        )\n      }\n\n      if (!isMinimalMode) {\n        res.setHeader(\n          'x-nextjs-cache',\n          isOnDemandRevalidate\n            ? 'REVALIDATED'\n            : cacheEntry.isMiss\n              ? 'MISS'\n              : cacheEntry.isStale\n                ? 'STALE'\n                : 'HIT'\n        )\n      }\n\n      // Draft mode should never be cached\n      if (isDraftMode) {\n        res.setHeader(\n          'Cache-Control',\n          'private, no-cache, no-store, max-age=0, must-revalidate'\n        )\n      }\n\n      const headers = fromNodeOutgoingHttpHeaders(cacheEntry.value.headers)\n\n      if (!(isMinimalMode && isIsr)) {\n        headers.delete(NEXT_CACHE_TAGS_HEADER)\n      }\n\n      // If cache control is already set on the response we don't\n      // override it to allow users to customize it via next.config\n      if (\n        cacheEntry.cacheControl &&\n        !res.getHeader('Cache-Control') &&\n        !headers.get('Cache-Control')\n      ) {\n        headers.set(\n          'Cache-Control',\n          getCacheControlHeader(cacheEntry.cacheControl)\n        )\n      }\n\n      await sendResponse(\n        nodeNextReq,\n        nodeNextRes,\n        // @ts-expect-error - Argument of type 'Buffer<ArrayBufferLike>' is not assignable to parameter of type 'BodyInit | null | undefined'.\n        new Response(cacheEntry.value.body, {\n          headers,\n          status: cacheEntry.value.status || 200,\n        })\n      )\n      return null\n    }\n\n    // TODO: activeSpan code path is for when wrapped by\n    // next-server can be removed when this is no longer used\n    if (activeSpan) {\n      await handleResponse(activeSpan)\n    } else {\n      await tracer.withPropagatedContext(req.headers, () =>\n        tracer.trace(\n          BaseServerSpan.handleRequest,\n          {\n            spanName: `${method} ${srcPage}`,\n            kind: SpanKind.SERVER,\n            attributes: {\n              'http.method': method,\n              'http.target': req.url,\n            },\n          },\n          handleResponse\n        )\n      )\n    }\n  } catch (err) {\n    if (!(err instanceof NoFallbackError)) {\n      const silenceLog = false\n      await routeModule.onRequestError(\n        req,\n        err,\n        {\n          routerKind: 'App Router',\n          routePath: normalizedSrcPage,\n          routeType: 'route',\n          revalidateReason: getRevalidateReason({\n            isStaticGeneration,\n            isOnDemandRevalidate,\n          }),\n        },\n        silenceLog,\n        routerServerContext\n      )\n    }\n\n    // rethrow so that we can handle serving error page\n\n    // If this is during static generation, throw the error again.\n    if (isIsr) throw err\n\n    // Otherwise, send a 500 response.\n    await sendResponse(\n      nodeNextReq,\n      nodeNextRes,\n      new Response(null, { status: 500 })\n    )\n    return null\n  }\n}\n","export class StorageError extends Error {\n  protected __isStorageError = true\n\n  constructor(message: string) {\n    super(message)\n    this.name = 'StorageError'\n  }\n}\n\nexport function isStorageError(error: unknown): error is StorageError {\n  return typeof error === 'object' && error !== null && '__isStorageError' in error\n}\n\nexport class StorageApiError extends StorageError {\n  status: number\n  statusCode: string\n\n  constructor(message: string, status: number, statusCode: string) {\n    super(message)\n    this.name = 'StorageApiError'\n    this.status = status\n    this.statusCode = statusCode\n  }\n\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n      statusCode: this.statusCode,\n    }\n  }\n}\n\nexport class StorageUnknownError extends StorageError {\n  originalError: unknown\n\n  constructor(message: string, originalError: unknown) {\n    super(message)\n    this.name = 'StorageUnknownError'\n    this.originalError = originalError\n  }\n}\n","/**\n * Error format\n *\n * {@link https://postgrest.org/en/stable/api.html?highlight=options#errors-and-http-status-codes}\n */\nexport default class PostgrestError extends Error {\n  details: string\n  hint: string\n  code: string\n\n  /**\n   * @example\n   * ```ts\n   * import PostgrestError from '@supabase/postgrest-js'\n   *\n   * throw new PostgrestError({\n   *   message: 'Row level security prevented the request',\n   *   details: 'RLS denied the insert',\n   *   hint: 'Check your policies',\n   *   code: 'PGRST301',\n   * })\n   * ```\n   */\n  constructor(context: { message: string; details: string; hint: string; code: string }) {\n    super(context.message)\n    this.name = 'PostgrestError'\n    this.details = context.details\n    this.hint = context.hint\n    this.code = context.code\n  }\n}\n","// Generated automatically during releases by scripts/update-version-files.ts\n// This file provides runtime access to the package version for:\n// - HTTP request headers (e.g., X-Client-Info header for API requests)\n// - Debugging and support (identifying which version is running)\n// - Telemetry and logging (version reporting in errors/analytics)\n// - Ensuring build artifacts match the published package version\nexport const version = '2.90.1'\n","// constants.ts\nimport { RealtimeClientOptions } from '@supabase/realtime-js'\nimport { SupabaseAuthClientOptions } from './types'\nimport { version } from './version'\n\nlet JS_ENV = ''\n// @ts-ignore\nif (typeof Deno !== 'undefined') {\n  JS_ENV = 'deno'\n} else if (typeof document !== 'undefined') {\n  JS_ENV = 'web'\n} else if (typeof navigator !== 'undefined' && navigator.product === 'ReactNative') {\n  JS_ENV = 'react-native'\n} else {\n  JS_ENV = 'node'\n}\n\nexport const DEFAULT_HEADERS = { 'X-Client-Info': `supabase-js-${JS_ENV}/${version}` }\n\nexport const DEFAULT_GLOBAL_OPTIONS = {\n  headers: DEFAULT_HEADERS,\n}\n\nexport const DEFAULT_DB_OPTIONS = {\n  schema: 'public',\n}\n\nexport const DEFAULT_AUTH_OPTIONS: SupabaseAuthClientOptions = {\n  autoRefreshToken: true,\n  persistSession: true,\n  detectSessionInUrl: true,\n  flowType: 'implicit',\n}\n\nexport const DEFAULT_REALTIME_OPTIONS: RealtimeClientOptions = {}\n","import type {\n  PostgrestSingleResponse,\n  PostgrestResponseSuccess,\n  CheckMatchingArrayTypes,\n  MergePartialResult,\n  IsValidResultOverride,\n} from './types/types'\nimport { ClientServerOptions, Fetch } from './types/common/common'\nimport PostgrestError from './PostgrestError'\nimport { ContainsNull } from './select-query-parser/types'\n\nexport default abstract class PostgrestBuilder<\n  ClientOptions extends ClientServerOptions,\n  Result,\n  ThrowOnError extends boolean = false,\n> implements\n    PromiseLike<\n      ThrowOnError extends true ? PostgrestResponseSuccess<Result> : PostgrestSingleResponse<Result>\n    >\n{\n  protected method: 'GET' | 'HEAD' | 'POST' | 'PATCH' | 'DELETE'\n  protected url: URL\n  protected headers: Headers\n  protected schema?: string\n  protected body?: unknown\n  protected shouldThrowOnError = false\n  protected signal?: AbortSignal\n  protected fetch: Fetch\n  protected isMaybeSingle: boolean\n\n  /**\n   * Creates a builder configured for a specific PostgREST request.\n   *\n   * @example\n   * ```ts\n   * import PostgrestQueryBuilder from '@supabase/postgrest-js'\n   *\n   * const builder = new PostgrestQueryBuilder(\n   *   new URL('https://xyzcompany.supabase.co/rest/v1/users'),\n   *   { headers: new Headers({ apikey: 'public-anon-key' }) }\n   * )\n   * ```\n   */\n  constructor(builder: {\n    method: 'GET' | 'HEAD' | 'POST' | 'PATCH' | 'DELETE'\n    url: URL\n    headers: HeadersInit\n    schema?: string\n    body?: unknown\n    shouldThrowOnError?: boolean\n    signal?: AbortSignal\n    fetch?: Fetch\n    isMaybeSingle?: boolean\n  }) {\n    this.method = builder.method\n    this.url = builder.url\n    this.headers = new Headers(builder.headers)\n    this.schema = builder.schema\n    this.body = builder.body\n    this.shouldThrowOnError = builder.shouldThrowOnError ?? false\n    this.signal = builder.signal\n    this.isMaybeSingle = builder.isMaybeSingle ?? false\n\n    if (builder.fetch) {\n      this.fetch = builder.fetch\n    } else {\n      this.fetch = fetch\n    }\n  }\n\n  /**\n   * If there's an error with the query, throwOnError will reject the promise by\n   * throwing the error instead of returning it as part of a successful response.\n   *\n   * {@link https://github.com/supabase/supabase-js/issues/92}\n   */\n  throwOnError(): this & PostgrestBuilder<ClientOptions, Result, true> {\n    this.shouldThrowOnError = true\n    return this as this & PostgrestBuilder<ClientOptions, Result, true>\n  }\n\n  /**\n   * Set an HTTP header for the request.\n   */\n  setHeader(name: string, value: string): this {\n    this.headers = new Headers(this.headers)\n    this.headers.set(name, value)\n    return this\n  }\n\n  then<\n    TResult1 = ThrowOnError extends true\n      ? PostgrestResponseSuccess<Result>\n      : PostgrestSingleResponse<Result>,\n    TResult2 = never,\n  >(\n    onfulfilled?:\n      | ((\n          value: ThrowOnError extends true\n            ? PostgrestResponseSuccess<Result>\n            : PostgrestSingleResponse<Result>\n        ) => TResult1 | PromiseLike<TResult1>)\n      | undefined\n      | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null\n  ): PromiseLike<TResult1 | TResult2> {\n    // https://postgrest.org/en/stable/api.html#switching-schemas\n    if (this.schema === undefined) {\n      // skip\n    } else if (['GET', 'HEAD'].includes(this.method)) {\n      this.headers.set('Accept-Profile', this.schema)\n    } else {\n      this.headers.set('Content-Profile', this.schema)\n    }\n    if (this.method !== 'GET' && this.method !== 'HEAD') {\n      this.headers.set('Content-Type', 'application/json')\n    }\n\n    // NOTE: Invoke w/o `this` to avoid illegal invocation error.\n    // https://github.com/supabase/postgrest-js/pull/247\n    const _fetch = this.fetch\n    let res = _fetch(this.url.toString(), {\n      method: this.method,\n      headers: this.headers,\n      body: JSON.stringify(this.body),\n      signal: this.signal,\n    }).then(async (res) => {\n      let error = null\n      let data = null\n      let count: number | null = null\n      let status = res.status\n      let statusText = res.statusText\n\n      if (res.ok) {\n        if (this.method !== 'HEAD') {\n          const body = await res.text()\n          if (body === '') {\n            // Prefer: return=minimal\n          } else if (this.headers.get('Accept') === 'text/csv') {\n            data = body\n          } else if (\n            this.headers.get('Accept') &&\n            this.headers.get('Accept')?.includes('application/vnd.pgrst.plan+text')\n          ) {\n            data = body\n          } else {\n            data = JSON.parse(body)\n          }\n        }\n\n        const countHeader = this.headers.get('Prefer')?.match(/count=(exact|planned|estimated)/)\n        const contentRange = res.headers.get('content-range')?.split('/')\n        if (countHeader && contentRange && contentRange.length > 1) {\n          count = parseInt(contentRange[1])\n        }\n\n        // Temporary partial fix for https://github.com/supabase/postgrest-js/issues/361\n        // Issue persists e.g. for `.insert([...]).select().maybeSingle()`\n        if (this.isMaybeSingle && this.method === 'GET' && Array.isArray(data)) {\n          if (data.length > 1) {\n            error = {\n              // https://github.com/PostgREST/postgrest/blob/a867d79c42419af16c18c3fb019eba8df992626f/src/PostgREST/Error.hs#L553\n              code: 'PGRST116',\n              details: `Results contain ${data.length} rows, application/vnd.pgrst.object+json requires 1 row`,\n              hint: null,\n              message: 'JSON object requested, multiple (or no) rows returned',\n            }\n            data = null\n            count = null\n            status = 406\n            statusText = 'Not Acceptable'\n          } else if (data.length === 1) {\n            data = data[0]\n          } else {\n            data = null\n          }\n        }\n      } else {\n        const body = await res.text()\n\n        try {\n          error = JSON.parse(body)\n\n          // Workaround for https://github.com/supabase/postgrest-js/issues/295\n          if (Array.isArray(error) && res.status === 404) {\n            data = []\n            error = null\n            status = 200\n            statusText = 'OK'\n          }\n        } catch {\n          // Workaround for https://github.com/supabase/postgrest-js/issues/295\n          if (res.status === 404 && body === '') {\n            status = 204\n            statusText = 'No Content'\n          } else {\n            error = {\n              message: body,\n            }\n          }\n        }\n\n        if (error && this.isMaybeSingle && error?.details?.includes('0 rows')) {\n          error = null\n          status = 200\n          statusText = 'OK'\n        }\n\n        if (error && this.shouldThrowOnError) {\n          throw new PostgrestError(error)\n        }\n      }\n\n      const postgrestResponse = {\n        error,\n        data,\n        count,\n        status,\n        statusText,\n      }\n\n      return postgrestResponse\n    })\n    if (!this.shouldThrowOnError) {\n      res = res.catch((fetchError) => {\n        // Build detailed error information including cause if available\n        // Note: We don't populate code/hint for client-side network errors since those\n        // fields are meant for upstream service errors (PostgREST/PostgreSQL)\n        let errorDetails = ''\n\n        // Add cause information if available (e.g., DNS errors, network failures)\n        const cause = fetchError?.cause\n        if (cause) {\n          const causeMessage = cause?.message ?? ''\n          const causeCode = cause?.code ?? ''\n\n          errorDetails = `${fetchError?.name ?? 'FetchError'}: ${fetchError?.message}`\n          errorDetails += `\\n\\nCaused by: ${cause?.name ?? 'Error'}: ${causeMessage}`\n          if (causeCode) {\n            errorDetails += ` (${causeCode})`\n          }\n          if (cause?.stack) {\n            errorDetails += `\\n${cause.stack}`\n          }\n        } else {\n          // No cause available, just include the error stack\n          errorDetails = fetchError?.stack ?? ''\n        }\n\n        return {\n          error: {\n            message: `${fetchError?.name ?? 'FetchError'}: ${fetchError?.message}`,\n            details: errorDetails,\n            hint: '',\n            code: '',\n          },\n          data: null,\n          count: null,\n          status: 0,\n          statusText: '',\n        }\n      })\n    }\n\n    return res.then(onfulfilled, onrejected)\n  }\n\n  /**\n   * Override the type of the returned `data`.\n   *\n   * @typeParam NewResult - The new result type to override with\n   * @deprecated Use overrideTypes<yourType, { merge: false }>() method at the end of your call chain instead\n   */\n  returns<NewResult>(): PostgrestBuilder<\n    ClientOptions,\n    CheckMatchingArrayTypes<Result, NewResult>,\n    ThrowOnError\n  > {\n    /* istanbul ignore next */\n    return this as unknown as PostgrestBuilder<\n      ClientOptions,\n      CheckMatchingArrayTypes<Result, NewResult>,\n      ThrowOnError\n    >\n  }\n\n  /**\n   * Override the type of the returned `data` field in the response.\n   *\n   * @typeParam NewResult - The new type to cast the response data to\n   * @typeParam Options - Optional type configuration (defaults to { merge: true })\n   * @typeParam Options.merge - When true, merges the new type with existing return type. When false, replaces the existing types entirely (defaults to true)\n   * @example\n   * ```typescript\n   * // Merge with existing types (default behavior)\n   * const query = supabase\n   *   .from('users')\n   *   .select()\n   *   .overrideTypes<{ custom_field: string }>()\n   *\n   * // Replace existing types completely\n   * const replaceQuery = supabase\n   *   .from('users')\n   *   .select()\n   *   .overrideTypes<{ id: number; name: string }, { merge: false }>()\n   * ```\n   * @returns A PostgrestBuilder instance with the new type\n   */\n  overrideTypes<\n    NewResult,\n    Options extends { merge?: boolean } = { merge: true },\n  >(): PostgrestBuilder<\n    ClientOptions,\n    IsValidResultOverride<Result, NewResult, false, false> extends true\n      ? // Preserve the optionality of the result if the overriden type is an object (case of chaining with `maybeSingle`)\n        ContainsNull<Result> extends true\n        ? MergePartialResult<NewResult, NonNullable<Result>, Options> | null\n        : MergePartialResult<NewResult, Result, Options>\n      : CheckMatchingArrayTypes<Result, NewResult>,\n    ThrowOnError\n  > {\n    return this as unknown as PostgrestBuilder<\n      ClientOptions,\n      IsValidResultOverride<Result, NewResult, false, false> extends true\n        ? // Preserve the optionality of the result if the overriden type is an object (case of chaining with `maybeSingle`)\n          ContainsNull<Result> extends true\n          ? MergePartialResult<NewResult, NonNullable<Result>, Options> | null\n          : MergePartialResult<NewResult, Result, Options>\n        : CheckMatchingArrayTypes<Result, NewResult>,\n      ThrowOnError\n    >\n  }\n}\n","export function buildUrl(\n  baseUrl: string,\n  path: string,\n  query?: Record<string, string | undefined>\n): string {\n  const url = new URL(path, baseUrl)\n\n  if (query) {\n    for (const [key, value] of Object.entries(query)) {\n      if (value !== undefined) {\n        url.searchParams.set(key, value)\n      }\n    }\n  }\n\n  return url.toString()\n}\n","type Fetch = typeof fetch\n\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args) => customFetch(...args)\n  }\n  return (...args) => fetch(...args)\n}\n\nexport const resolveResponse = (): typeof Response => {\n  return Response\n}\n\nexport const recursiveToCamel = (item: Record<string, any>): unknown => {\n  if (Array.isArray(item)) {\n    return item.map((el) => recursiveToCamel(el))\n  } else if (typeof item === 'function' || item !== Object(item)) {\n    return item\n  }\n\n  const result: Record<string, any> = {}\n  Object.entries(item).forEach(([key, value]) => {\n    const newKey = key.replace(/([-_][a-z])/gi, (c) => c.toUpperCase().replace(/[-_]/g, ''))\n    result[newKey] = recursiveToCamel(value)\n  })\n\n  return result\n}\n\n/**\n * Determine if input is a plain object\n * An object is plain if it's created by either {}, new Object(), or Object.create(null)\n * source: https://github.com/sindresorhus/is-plain-obj\n */\nexport const isPlainObject = (value: object): boolean => {\n  if (typeof value !== 'object' || value === null) {\n    return false\n  }\n\n  const prototype = Object.getPrototypeOf(value)\n  return (\n    (prototype === null ||\n      prototype === Object.prototype ||\n      Object.getPrototypeOf(prototype) === null) &&\n    !(Symbol.toStringTag in value) &&\n    !(Symbol.iterator in value)\n  )\n}\n\n/**\n * Validates if a given bucket name is valid according to Supabase Storage API rules\n * Mirrors backend validation from: storage/src/storage/limits.ts:isValidBucketName()\n *\n * Rules:\n * - Length: 1-100 characters\n * - Allowed characters: alphanumeric (a-z, A-Z, 0-9), underscore (_), and safe special characters\n * - Safe special characters: ! - . * ' ( ) space & $ @ = ; : + , ?\n * - Forbidden: path separators (/, \\), path traversal (..), leading/trailing whitespace\n *\n * AWS S3 Reference: https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-keys.html\n *\n * @param bucketName - The bucket name to validate\n * @returns true if valid, false otherwise\n */\nexport const isValidBucketName = (bucketName: string): boolean => {\n  if (!bucketName || typeof bucketName !== 'string') {\n    return false\n  }\n\n  // Check length constraints (1-100 characters)\n  if (bucketName.length === 0 || bucketName.length > 100) {\n    return false\n  }\n\n  // Check for leading/trailing whitespace\n  if (bucketName.trim() !== bucketName) {\n    return false\n  }\n\n  // Explicitly reject path separators (security)\n  // Note: Consecutive periods (..) are allowed by backend - the AWS restriction\n  // on relative paths applies to object keys, not bucket names\n  if (bucketName.includes('/') || bucketName.includes('\\\\')) {\n    return false\n  }\n\n  // Validate against allowed character set\n  // Pattern matches backend regex: /^(\\w|!|-|\\.|\\*|'|\\(|\\)| |&|\\$|@|=|;|:|\\+|,|\\?)*$/\n  // This explicitly excludes path separators (/, \\) and other problematic characters\n  const bucketNameRegex = /^[\\w!.\\*'() &$@=;:+,?-]+$/\n  return bucketNameRegex.test(bucketName)\n}\n","import { IcebergError, type IcebergErrorResponse } from '../errors/IcebergError'\nimport { buildUrl } from '../utils/url'\nimport type { AuthConfig, HttpClient, HttpRequest, HttpResponse } from './types'\n\nasync function buildAuthHeaders(auth?: AuthConfig): Promise<Record<string, string>> {\n  if (!auth || auth.type === 'none') {\n    return {}\n  }\n\n  if (auth.type === 'bearer') {\n    return { Authorization: `Bearer ${auth.token}` }\n  }\n\n  if (auth.type === 'header') {\n    return { [auth.name]: auth.value }\n  }\n\n  if (auth.type === 'custom') {\n    return await auth.getHeaders()\n  }\n\n  return {}\n}\n\nexport function createFetchClient(options: {\n  baseUrl: string\n  auth?: AuthConfig\n  fetchImpl?: typeof fetch\n}): HttpClient {\n  const fetchFn = options.fetchImpl ?? globalThis.fetch\n\n  return {\n    async request<T>({\n      method,\n      path,\n      query,\n      body,\n      headers,\n    }: HttpRequest): Promise<HttpResponse<T>> {\n      const url = buildUrl(options.baseUrl, path, query)\n      const authHeaders = await buildAuthHeaders(options.auth)\n\n      const res = await fetchFn(url, {\n        method,\n        headers: {\n          ...(body ? { 'Content-Type': 'application/json' } : {}),\n          ...authHeaders,\n          ...headers,\n        },\n        body: body ? JSON.stringify(body) : undefined,\n      })\n\n      const text = await res.text()\n      const isJson = (res.headers.get('content-type') || '').includes('application/json')\n      const data = isJson && text ? (JSON.parse(text) as T) : (text as T)\n\n      if (!res.ok) {\n        const errBody = isJson ? (data as IcebergErrorResponse) : undefined\n        const errorDetail = errBody?.error\n        throw new IcebergError(\n          errorDetail?.message ?? `Request failed with status ${res.status}`,\n          {\n            status: res.status,\n            icebergType: errorDetail?.type,\n            icebergCode: errorDetail?.code,\n            details: errBody,\n          }\n        )\n      }\n\n      return { status: res.status, headers: res.headers, data: data as T }\n    },\n  }\n}\n","type Fetch = typeof fetch\n\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args: Parameters<Fetch>) => customFetch(...args)\n  }\n  return (...args: Parameters<Fetch>) => fetch(...args)\n}\n\nexport const resolveHeadersConstructor = () => {\n  return Headers\n}\n\nexport const fetchWithAuth = (\n  supabaseKey: string,\n  getAccessToken: () => Promise<string | null>,\n  customFetch?: Fetch\n): Fetch => {\n  const fetch = resolveFetch(customFetch)\n  const HeadersConstructor = resolveHeadersConstructor()\n\n  return async (input, init) => {\n    const accessToken = (await getAccessToken()) ?? supabaseKey\n    let headers = new HeadersConstructor(init?.headers)\n\n    if (!headers.has('apikey')) {\n      headers.set('apikey', supabaseKey)\n    }\n\n    if (!headers.has('Authorization')) {\n      headers.set('Authorization', `Bearer ${accessToken}`)\n    }\n\n    return fetch(input, { ...init, headers })\n  }\n}\n","import type { HttpClient } from '../http/types'\nimport { IcebergError } from '../errors/IcebergError'\nimport type {\n  CreateNamespaceRequest,\n  CreateNamespaceResponse,\n  GetNamespaceResponse,\n  ListNamespacesResponse,\n  NamespaceIdentifier,\n  NamespaceMetadata,\n} from './types'\n\nfunction namespaceToPath(namespace: string[]): string {\n  return namespace.join('\\x1F')\n}\n\nexport class NamespaceOperations {\n  constructor(\n    private readonly client: HttpClient,\n    private readonly prefix: string = ''\n  ) {}\n\n  async listNamespaces(parent?: NamespaceIdentifier): Promise<NamespaceIdentifier[]> {\n    const query = parent ? { parent: namespaceToPath(parent.namespace) } : undefined\n\n    const response = await this.client.request<ListNamespacesResponse>({\n      method: 'GET',\n      path: `${this.prefix}/namespaces`,\n      query,\n    })\n\n    return response.data.namespaces.map((ns) => ({ namespace: ns }))\n  }\n\n  async createNamespace(\n    id: NamespaceIdentifier,\n    metadata?: NamespaceMetadata\n  ): Promise<CreateNamespaceResponse> {\n    const request: CreateNamespaceRequest = {\n      namespace: id.namespace,\n      properties: metadata?.properties,\n    }\n\n    const response = await this.client.request<CreateNamespaceResponse>({\n      method: 'POST',\n      path: `${this.prefix}/namespaces`,\n      body: request,\n    })\n\n    return response.data\n  }\n\n  async dropNamespace(id: NamespaceIdentifier): Promise<void> {\n    await this.client.request<void>({\n      method: 'DELETE',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}`,\n    })\n  }\n\n  async loadNamespaceMetadata(id: NamespaceIdentifier): Promise<NamespaceMetadata> {\n    const response = await this.client.request<GetNamespaceResponse>({\n      method: 'GET',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}`,\n    })\n\n    return {\n      properties: response.data.properties,\n    }\n  }\n\n  async namespaceExists(id: NamespaceIdentifier): Promise<boolean> {\n    try {\n      await this.client.request<void>({\n        method: 'HEAD',\n        path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}`,\n      })\n      return true\n    } catch (error) {\n      if (error instanceof IcebergError && error.status === 404) {\n        return false\n      }\n      throw error\n    }\n  }\n\n  async createNamespaceIfNotExists(\n    id: NamespaceIdentifier,\n    metadata?: NamespaceMetadata\n  ): Promise<CreateNamespaceResponse | void> {\n    try {\n      return await this.createNamespace(id, metadata)\n    } catch (error) {\n      if (error instanceof IcebergError && error.status === 409) {\n        return\n      }\n      throw error\n    }\n  }\n}\n","// helpers.ts\nimport { SupabaseClientOptions } from './types'\n\nexport function uuid() {\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {\n    var r = (Math.random() * 16) | 0,\n      v = c == 'x' ? r : (r & 0x3) | 0x8\n    return v.toString(16)\n  })\n}\n\nexport function ensureTrailingSlash(url: string): string {\n  return url.endsWith('/') ? url : url + '/'\n}\n\nexport const isBrowser = () => typeof window !== 'undefined'\n\nexport function applySettingDefaults<\n  Database = any,\n  SchemaName extends string & keyof Database = 'public' extends keyof Database\n    ? 'public'\n    : string & keyof Database,\n>(\n  options: SupabaseClientOptions<SchemaName>,\n  defaults: SupabaseClientOptions<any>\n): Required<SupabaseClientOptions<SchemaName>> {\n  const {\n    db: dbOptions,\n    auth: authOptions,\n    realtime: realtimeOptions,\n    global: globalOptions,\n  } = options\n  const {\n    db: DEFAULT_DB_OPTIONS,\n    auth: DEFAULT_AUTH_OPTIONS,\n    realtime: DEFAULT_REALTIME_OPTIONS,\n    global: DEFAULT_GLOBAL_OPTIONS,\n  } = defaults\n\n  const result: Required<SupabaseClientOptions<SchemaName>> = {\n    db: {\n      ...DEFAULT_DB_OPTIONS,\n      ...dbOptions,\n    },\n    auth: {\n      ...DEFAULT_AUTH_OPTIONS,\n      ...authOptions,\n    },\n    realtime: {\n      ...DEFAULT_REALTIME_OPTIONS,\n      ...realtimeOptions,\n    },\n    storage: {},\n    global: {\n      ...DEFAULT_GLOBAL_OPTIONS,\n      ...globalOptions,\n      headers: {\n        ...(DEFAULT_GLOBAL_OPTIONS?.headers ?? {}),\n        ...(globalOptions?.headers ?? {}),\n      },\n    },\n    accessToken: async () => '',\n  }\n\n  if (options.accessToken) {\n    result.accessToken = options.accessToken\n  } else {\n    // hack around Required<>\n    delete (result as any).accessToken\n  }\n\n  return result\n}\n\n/**\n * Validates a Supabase client URL\n *\n * @param {string} supabaseUrl - The Supabase client URL string.\n * @returns {URL} - The validated base URL.\n * @throws {Error}\n */\nexport function validateSupabaseUrl(supabaseUrl: string): URL {\n  const trimmedUrl = supabaseUrl?.trim()\n\n  if (!trimmedUrl) {\n    throw new Error('supabaseUrl is required.')\n  }\n\n  if (!trimmedUrl.match(/^https?:\\/\\//i)) {\n    throw new Error('Invalid supabaseUrl: Must be a valid HTTP or HTTPS URL.')\n  }\n\n  try {\n    return new URL(ensureTrailingSlash(trimmedUrl))\n  } catch {\n    throw Error('Invalid supabaseUrl: Provided URL is malformed.')\n  }\n}\n","import { StorageApiError, StorageUnknownError } from './errors'\nimport { isPlainObject, resolveResponse } from './helpers'\nimport { FetchParameters } from './types'\n\nexport type Fetch = typeof fetch\n\nexport interface FetchOptions {\n  headers?: {\n    [key: string]: string\n  }\n  duplex?: string\n  noResolveJson?: boolean\n}\n\nexport type RequestMethodType = 'GET' | 'POST' | 'PUT' | 'DELETE' | 'HEAD'\n\nconst _getErrorMessage = (err: any): string =>\n  err.msg ||\n  err.message ||\n  err.error_description ||\n  (typeof err.error === 'string' ? err.error : err.error?.message) ||\n  JSON.stringify(err)\n\nconst handleError = async (\n  error: unknown,\n  reject: (reason?: any) => void,\n  options?: FetchOptions\n) => {\n  const Res = await resolveResponse()\n\n  if (error instanceof Res && !options?.noResolveJson) {\n    error\n      .json()\n      .then((err) => {\n        const status = error.status || 500\n        const statusCode = err?.statusCode || status + ''\n        reject(new StorageApiError(_getErrorMessage(err), status, statusCode))\n      })\n      .catch((err) => {\n        reject(new StorageUnknownError(_getErrorMessage(err), err))\n      })\n  } else {\n    reject(new StorageUnknownError(_getErrorMessage(error), error))\n  }\n}\n\nconst _getRequestParams = (\n  method: RequestMethodType,\n  options?: FetchOptions,\n  parameters?: FetchParameters,\n  body?: object\n) => {\n  const params: { [k: string]: any } = { method, headers: options?.headers || {} }\n\n  if (method === 'GET' || !body) {\n    return params\n  }\n\n  if (isPlainObject(body)) {\n    params.headers = { 'Content-Type': 'application/json', ...options?.headers }\n    params.body = JSON.stringify(body)\n  } else {\n    params.body = body\n  }\n\n  if (options?.duplex) {\n    params.duplex = options.duplex\n  }\n\n  return { ...params, ...parameters }\n}\n\nasync function _handleRequest(\n  fetcher: Fetch,\n  method: RequestMethodType,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters,\n  body?: object\n): Promise<any> {\n  return new Promise((resolve, reject) => {\n    fetcher(url, _getRequestParams(method, options, parameters, body))\n      .then((result) => {\n        if (!result.ok) throw result\n        if (options?.noResolveJson) return result\n        return result.json()\n      })\n      .then((data) => resolve(data))\n      .catch((error) => handleError(error, reject, options))\n  })\n}\n\nexport async function get(\n  fetcher: Fetch,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'GET', url, options, parameters)\n}\n\nexport async function post(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'POST', url, options, parameters, body)\n}\n\nexport async function put(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'PUT', url, options, parameters, body)\n}\n\nexport async function head(\n  fetcher: Fetch,\n  url: string,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(\n    fetcher,\n    'HEAD',\n    url,\n    {\n      ...options,\n      noResolveJson: true,\n    },\n    parameters\n  )\n}\n\nexport async function remove(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: FetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'DELETE', url, options, parameters, body)\n}\n","import { AuthClient } from '@supabase/auth-js'\nimport { SupabaseAuthClientOptions } from './types'\n\nexport class SupabaseAuthClient extends AuthClient {\n  constructor(options: SupabaseAuthClientOptions) {\n    super(options)\n  }\n}\n","import type { AuthChangeEvent } from '@supabase/auth-js'\nimport { FunctionsClient } from '@supabase/functions-js'\nimport {\n  PostgrestClient,\n  type PostgrestFilterBuilder,\n  type PostgrestQueryBuilder,\n} from '@supabase/postgrest-js'\nimport {\n  type RealtimeChannel,\n  type RealtimeChannelOptions,\n  RealtimeClient,\n  type RealtimeClientOptions,\n} from '@supabase/realtime-js'\nimport { StorageClient as SupabaseStorageClient } from '@supabase/storage-js'\nimport {\n  DEFAULT_AUTH_OPTIONS,\n  DEFAULT_DB_OPTIONS,\n  DEFAULT_GLOBAL_OPTIONS,\n  DEFAULT_REALTIME_OPTIONS,\n} from './lib/constants'\nimport { fetchWithAuth } from './lib/fetch'\nimport { applySettingDefaults, validateSupabaseUrl } from './lib/helpers'\nimport { SupabaseAuthClient } from './lib/SupabaseAuthClient'\nimport type {\n  Fetch,\n  GenericSchema,\n  SupabaseAuthClientOptions,\n  SupabaseClientOptions,\n} from './lib/types'\nimport { GetRpcFunctionFilterBuilderByArgs } from './lib/rest/types/common/rpc'\n\n/**\n * Supabase Client.\n *\n * An isomorphic Javascript client for interacting with Postgres.\n */\nexport default class SupabaseClient<\n  Database = any,\n  // The second type parameter is also used for specifying db_schema, so we\n  // support both cases.\n  // TODO: Allow setting db_schema from ClientOptions.\n  SchemaNameOrClientOptions extends\n    | (string & keyof Omit<Database, '__InternalSupabase'>)\n    | { PostgrestVersion: string } = 'public' extends keyof Omit<Database, '__InternalSupabase'>\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? SchemaNameOrClientOptions\n    : 'public' extends keyof Omit<Database, '__InternalSupabase'>\n      ? 'public'\n      : string & keyof Omit<Omit<Database, '__InternalSupabase'>, '__InternalSupabase'>,\n  Schema extends Omit<Database, '__InternalSupabase'>[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : never = Omit<Database, '__InternalSupabase'>[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : never,\n  ClientOptions extends { PostgrestVersion: string } = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? // If the version isn't explicitly set, look for it in the __InternalSupabase object to infer the right version\n      Database extends { __InternalSupabase: { PostgrestVersion: string } }\n      ? Database['__InternalSupabase']\n      : // otherwise default to 12\n        { PostgrestVersion: '12' }\n    : SchemaNameOrClientOptions extends { PostgrestVersion: string }\n      ? SchemaNameOrClientOptions\n      : never,\n> {\n  /**\n   * Supabase Auth allows you to create and manage user sessions for access to data that is secured by access policies.\n   */\n  auth: SupabaseAuthClient\n  realtime: RealtimeClient\n  /**\n   * Supabase Storage allows you to manage user-generated content, such as photos or videos.\n   */\n  storage: SupabaseStorageClient\n\n  protected realtimeUrl: URL\n  protected authUrl: URL\n  protected storageUrl: URL\n  protected functionsUrl: URL\n  protected rest: PostgrestClient<Database, ClientOptions, SchemaName>\n  protected storageKey: string\n  protected fetch?: Fetch\n  protected changedAccessToken?: string\n  protected accessToken?: () => Promise<string | null>\n\n  protected headers: Record<string, string>\n\n  /**\n   * Create a new client for use in the browser.\n   * @param supabaseUrl The unique Supabase URL which is supplied when you create a new project in your project dashboard.\n   * @param supabaseKey The unique Supabase Key which is supplied when you create a new project in your project dashboard.\n   * @param options.db.schema You can switch in between schemas. The schema needs to be on the list of exposed schemas inside Supabase.\n   * @param options.auth.autoRefreshToken Set to \"true\" if you want to automatically refresh the token before expiring.\n   * @param options.auth.persistSession Set to \"true\" if you want to automatically save the user session into local storage.\n   * @param options.auth.detectSessionInUrl Set to \"true\" if you want to automatically detects OAuth grants in the URL and signs in the user.\n   * @param options.realtime Options passed along to realtime-js constructor.\n   * @param options.storage Options passed along to the storage-js constructor.\n   * @param options.global.fetch A custom fetch implementation.\n   * @param options.global.headers Any additional headers to send with each network request.\n   * @example\n   * ```ts\n   * import { createClient } from '@supabase/supabase-js'\n   *\n   * const supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key')\n   * const { data } = await supabase.from('profiles').select('*')\n   * ```\n   */\n  constructor(\n    protected supabaseUrl: string,\n    protected supabaseKey: string,\n    options?: SupabaseClientOptions<SchemaName>\n  ) {\n    const baseUrl = validateSupabaseUrl(supabaseUrl)\n    if (!supabaseKey) throw new Error('supabaseKey is required.')\n\n    this.realtimeUrl = new URL('realtime/v1', baseUrl)\n    this.realtimeUrl.protocol = this.realtimeUrl.protocol.replace('http', 'ws')\n    this.authUrl = new URL('auth/v1', baseUrl)\n    this.storageUrl = new URL('storage/v1', baseUrl)\n    this.functionsUrl = new URL('functions/v1', baseUrl)\n\n    // default storage key uses the supabase project ref as a namespace\n    const defaultStorageKey = `sb-${baseUrl.hostname.split('.')[0]}-auth-token`\n    const DEFAULTS = {\n      db: DEFAULT_DB_OPTIONS,\n      realtime: DEFAULT_REALTIME_OPTIONS,\n      auth: { ...DEFAULT_AUTH_OPTIONS, storageKey: defaultStorageKey },\n      global: DEFAULT_GLOBAL_OPTIONS,\n    }\n\n    const settings = applySettingDefaults(options ?? {}, DEFAULTS)\n\n    this.storageKey = settings.auth.storageKey ?? ''\n    this.headers = settings.global.headers ?? {}\n\n    if (!settings.accessToken) {\n      this.auth = this._initSupabaseAuthClient(\n        settings.auth ?? {},\n        this.headers,\n        settings.global.fetch\n      )\n    } else {\n      this.accessToken = settings.accessToken\n\n      this.auth = new Proxy<SupabaseAuthClient>({} as any, {\n        get: (_, prop) => {\n          throw new Error(\n            `@supabase/supabase-js: Supabase Client is configured with the accessToken option, accessing supabase.auth.${String(\n              prop\n            )} is not possible`\n          )\n        },\n      })\n    }\n\n    this.fetch = fetchWithAuth(supabaseKey, this._getAccessToken.bind(this), settings.global.fetch)\n    this.realtime = this._initRealtimeClient({\n      headers: this.headers,\n      accessToken: this._getAccessToken.bind(this),\n      ...settings.realtime,\n    })\n    if (this.accessToken) {\n      // Start auth immediately to avoid race condition with channel subscriptions\n      this.accessToken()\n        .then((token) => this.realtime.setAuth(token))\n        .catch((e) => console.warn('Failed to set initial Realtime auth token:', e))\n    }\n\n    this.rest = new PostgrestClient(new URL('rest/v1', baseUrl).href, {\n      headers: this.headers,\n      schema: settings.db.schema,\n      fetch: this.fetch,\n    })\n\n    this.storage = new SupabaseStorageClient(\n      this.storageUrl.href,\n      this.headers,\n      this.fetch,\n      options?.storage\n    )\n\n    if (!settings.accessToken) {\n      this._listenForAuthEvents()\n    }\n  }\n\n  /**\n   * Supabase Functions allows you to deploy and invoke edge functions.\n   */\n  get functions(): FunctionsClient {\n    return new FunctionsClient(this.functionsUrl.href, {\n      headers: this.headers,\n      customFetch: this.fetch,\n    })\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.from\n  from<\n    TableName extends string & keyof Schema['Tables'],\n    Table extends Schema['Tables'][TableName],\n  >(relation: TableName): PostgrestQueryBuilder<ClientOptions, Schema, Table, TableName>\n  from<ViewName extends string & keyof Schema['Views'], View extends Schema['Views'][ViewName]>(\n    relation: ViewName\n  ): PostgrestQueryBuilder<ClientOptions, Schema, View, ViewName>\n  /**\n   * Perform a query on a table or a view.\n   *\n   * @param relation - The table or view name to query\n   */\n  from(relation: string): PostgrestQueryBuilder<ClientOptions, Schema, any> {\n    return this.rest.from(relation)\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.schema\n  /**\n   * Select a schema to query or perform an function (rpc) call.\n   *\n   * The schema needs to be on the list of exposed schemas inside Supabase.\n   *\n   * @param schema - The schema to query\n   */\n  schema<DynamicSchema extends string & keyof Omit<Database, '__InternalSupabase'>>(\n    schema: DynamicSchema\n  ): PostgrestClient<\n    Database,\n    ClientOptions,\n    DynamicSchema,\n    Database[DynamicSchema] extends GenericSchema ? Database[DynamicSchema] : any\n  > {\n    return this.rest.schema<DynamicSchema>(schema)\n  }\n\n  // NOTE: signatures must be kept in sync with PostgrestClient.rpc\n  /**\n   * Perform a function call.\n   *\n   * @param fn - The function name to call\n   * @param args - The arguments to pass to the function call\n   * @param options - Named parameters\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   * @param options.get - When set to `true`, the function will be called with\n   * read-only access mode.\n   * @param options.count - Count algorithm to use to count rows returned by the\n   * function. Only applicable for [set-returning\n   * functions](https://www.postgresql.org/docs/current/functions-srf.html).\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  rpc<\n    FnName extends string & keyof Schema['Functions'],\n    Args extends Schema['Functions'][FnName]['Args'] = never,\n    FilterBuilder extends GetRpcFunctionFilterBuilderByArgs<\n      Schema,\n      FnName,\n      Args\n    > = GetRpcFunctionFilterBuilderByArgs<Schema, FnName, Args>,\n  >(\n    fn: FnName,\n    args: Args = {} as Args,\n    options: {\n      head?: boolean\n      get?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {\n      head: false,\n      get: false,\n      count: undefined,\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    FilterBuilder['Row'],\n    FilterBuilder['Result'],\n    FilterBuilder['RelationName'],\n    FilterBuilder['Relationships'],\n    'RPC'\n  > {\n    return this.rest.rpc(fn, args, options) as unknown as PostgrestFilterBuilder<\n      ClientOptions,\n      Schema,\n      FilterBuilder['Row'],\n      FilterBuilder['Result'],\n      FilterBuilder['RelationName'],\n      FilterBuilder['Relationships'],\n      'RPC'\n    >\n  }\n\n  /**\n   * Creates a Realtime channel with Broadcast, Presence, and Postgres Changes.\n   *\n   * @param {string} name - The name of the Realtime channel.\n   * @param {Object} opts - The options to pass to the Realtime channel.\n   *\n   */\n  channel(name: string, opts: RealtimeChannelOptions = { config: {} }): RealtimeChannel {\n    return this.realtime.channel(name, opts)\n  }\n\n  /**\n   * Returns all Realtime channels.\n   */\n  getChannels(): RealtimeChannel[] {\n    return this.realtime.getChannels()\n  }\n\n  /**\n   * Unsubscribes and removes Realtime channel from Realtime client.\n   *\n   * @param {RealtimeChannel} channel - The name of the Realtime channel.\n   *\n   */\n  removeChannel(channel: RealtimeChannel): Promise<'ok' | 'timed out' | 'error'> {\n    return this.realtime.removeChannel(channel)\n  }\n\n  /**\n   * Unsubscribes and removes all Realtime channels from Realtime client.\n   */\n  removeAllChannels(): Promise<('ok' | 'timed out' | 'error')[]> {\n    return this.realtime.removeAllChannels()\n  }\n\n  private async _getAccessToken() {\n    if (this.accessToken) {\n      return await this.accessToken()\n    }\n\n    const { data } = await this.auth.getSession()\n\n    return data.session?.access_token ?? this.supabaseKey\n  }\n\n  private _initSupabaseAuthClient(\n    {\n      autoRefreshToken,\n      persistSession,\n      detectSessionInUrl,\n      storage,\n      userStorage,\n      storageKey,\n      flowType,\n      lock,\n      debug,\n      throwOnError,\n    }: SupabaseAuthClientOptions,\n    headers?: Record<string, string>,\n    fetch?: Fetch\n  ) {\n    const authHeaders = {\n      Authorization: `Bearer ${this.supabaseKey}`,\n      apikey: `${this.supabaseKey}`,\n    }\n    return new SupabaseAuthClient({\n      url: this.authUrl.href,\n      headers: { ...authHeaders, ...headers },\n      storageKey: storageKey,\n      autoRefreshToken,\n      persistSession,\n      detectSessionInUrl,\n      storage,\n      userStorage,\n      flowType,\n      lock,\n      debug,\n      throwOnError,\n      fetch,\n      // auth checks if there is a custom authorizaiton header using this flag\n      // so it knows whether to return an error when getUser is called with no session\n      hasCustomAuthorizationHeader: Object.keys(this.headers).some(\n        (key) => key.toLowerCase() === 'authorization'\n      ),\n    })\n  }\n\n  private _initRealtimeClient(options: RealtimeClientOptions) {\n    return new RealtimeClient(this.realtimeUrl.href, {\n      ...options,\n      params: { ...{ apikey: this.supabaseKey }, ...options?.params },\n    })\n  }\n\n  private _listenForAuthEvents() {\n    const data = this.auth.onAuthStateChange((event, session) => {\n      this._handleTokenChanged(event, 'CLIENT', session?.access_token)\n    })\n    return data\n  }\n\n  private _handleTokenChanged(\n    event: AuthChangeEvent,\n    source: 'CLIENT' | 'STORAGE',\n    token?: string\n  ) {\n    if (\n      (event === 'TOKEN_REFRESHED' || event === 'SIGNED_IN') &&\n      this.changedAccessToken !== token\n    ) {\n      this.changedAccessToken = token\n      this.realtime.setAuth(token)\n    } else if (event === 'SIGNED_OUT') {\n      this.realtime.setAuth()\n      if (source == 'STORAGE') this.auth.signOut()\n      this.changedAccessToken = undefined\n    }\n  }\n}\n","import type { HttpClient } from '../http/types'\nimport { IcebergError } from '../errors/IcebergError'\nimport type {\n  CreateTableRequest,\n  CommitTableResponse,\n  ListTablesResponse,\n  LoadTableResponse,\n  NamespaceIdentifier,\n  TableIdentifier,\n  TableMetadata,\n  UpdateTableRequest,\n  DropTableRequest,\n} from './types'\n\nfunction namespaceToPath(namespace: string[]): string {\n  return namespace.join('\\x1F')\n}\n\nexport class TableOperations {\n  constructor(\n    private readonly client: HttpClient,\n    private readonly prefix: string = '',\n    private readonly accessDelegation?: string\n  ) {}\n\n  async listTables(namespace: NamespaceIdentifier): Promise<TableIdentifier[]> {\n    const response = await this.client.request<ListTablesResponse>({\n      method: 'GET',\n      path: `${this.prefix}/namespaces/${namespaceToPath(namespace.namespace)}/tables`,\n    })\n\n    return response.data.identifiers\n  }\n\n  async createTable(\n    namespace: NamespaceIdentifier,\n    request: CreateTableRequest\n  ): Promise<TableMetadata> {\n    const headers: Record<string, string> = {}\n    if (this.accessDelegation) {\n      headers['X-Iceberg-Access-Delegation'] = this.accessDelegation\n    }\n\n    const response = await this.client.request<LoadTableResponse>({\n      method: 'POST',\n      path: `${this.prefix}/namespaces/${namespaceToPath(namespace.namespace)}/tables`,\n      body: request,\n      headers,\n    })\n\n    return response.data.metadata\n  }\n\n  async updateTable(id: TableIdentifier, request: UpdateTableRequest): Promise<CommitTableResponse> {\n    const response = await this.client.request<LoadTableResponse>({\n      method: 'POST',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}/tables/${id.name}`,\n      body: request,\n    })\n\n    return {\n      'metadata-location': response.data['metadata-location'],\n      metadata: response.data.metadata,\n    }\n  }\n\n  async dropTable(id: TableIdentifier, options?: DropTableRequest): Promise<void> {\n    await this.client.request<void>({\n      method: 'DELETE',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}/tables/${id.name}`,\n      query: { purgeRequested: String(options?.purge ?? false) },\n    })\n  }\n\n  async loadTable(id: TableIdentifier): Promise<TableMetadata> {\n    const headers: Record<string, string> = {}\n    if (this.accessDelegation) {\n      headers['X-Iceberg-Access-Delegation'] = this.accessDelegation\n    }\n\n    const response = await this.client.request<LoadTableResponse>({\n      method: 'GET',\n      path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}/tables/${id.name}`,\n      headers,\n    })\n\n    return response.data.metadata\n  }\n\n  async tableExists(id: TableIdentifier): Promise<boolean> {\n    const headers: Record<string, string> = {}\n    if (this.accessDelegation) {\n      headers['X-Iceberg-Access-Delegation'] = this.accessDelegation\n    }\n\n    try {\n      await this.client.request<void>({\n        method: 'HEAD',\n        path: `${this.prefix}/namespaces/${namespaceToPath(id.namespace)}/tables/${id.name}`,\n        headers,\n      })\n      return true\n    } catch (error) {\n      if (error instanceof IcebergError && error.status === 404) {\n        return false\n      }\n      throw error\n    }\n  }\n\n  async createTableIfNotExists(\n    namespace: NamespaceIdentifier,\n    request: CreateTableRequest\n  ): Promise<TableMetadata> {\n    try {\n      return await this.createTable(namespace, request)\n    } catch (error) {\n      if (error instanceof IcebergError && error.status === 409) {\n        return await this.loadTable({ namespace: namespace.namespace, name: request.name })\n      }\n      throw error\n    }\n  }\n}\n","import { isStorageError } from '../lib/errors'\nimport { DownloadResult } from '../lib/types'\n\nexport default class StreamDownloadBuilder implements PromiseLike<DownloadResult<ReadableStream>> {\n  constructor(\n    private downloadFn: () => Promise<Response>,\n    private shouldThrowOnError: boolean\n  ) {}\n\n  then<TResult1 = DownloadResult<ReadableStream>, TResult2 = never>(\n    onfulfilled?:\n      | ((value: DownloadResult<ReadableStream>) => TResult1 | PromiseLike<TResult1>)\n      | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | null\n  ): Promise<TResult1 | TResult2> {\n    return this.execute().then(onfulfilled, onrejected)\n  }\n\n  private async execute(): Promise<DownloadResult<ReadableStream>> {\n    try {\n      const result = await this.downloadFn()\n\n      return {\n        data: result.body as ReadableStream,\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n","import PostgrestBuilder from './PostgrestBuilder'\nimport PostgrestFilterBuilder, { InvalidMethodError } from './PostgrestFilterBuilder'\nimport { GetResult } from './select-query-parser/result'\nimport { CheckMatchingArrayTypes } from './types/types'\nimport { ClientServerOptions, GenericSchema } from './types/common/common'\nimport type { MaxAffectedEnabled } from './types/feature-flags'\n\nexport default class PostgrestTransformBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  Result,\n  RelationName = unknown,\n  Relationships = unknown,\n  Method = unknown,\n> extends PostgrestBuilder<ClientOptions, Result> {\n  /**\n   * Perform a SELECT on the query result.\n   *\n   * By default, `.insert()`, `.update()`, `.upsert()`, and `.delete()` do not\n   * return modified rows. By calling this method, modified rows are returned in\n   * `data`.\n   *\n   * @param columns - The columns to retrieve, separated by commas\n   */\n  select<\n    Query extends string = '*',\n    NewResultOne = GetResult<Schema, Row, RelationName, Relationships, Query, ClientOptions>,\n  >(\n    columns?: Query\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Row,\n    Method extends 'RPC'\n      ? Result extends unknown[]\n        ? NewResultOne[]\n        : NewResultOne\n      : NewResultOne[],\n    RelationName,\n    Relationships,\n    Method\n  > {\n    // Remove whitespaces except when quoted\n    let quoted = false\n    const cleanedColumns = (columns ?? '*')\n      .split('')\n      .map((c) => {\n        if (/\\s/.test(c) && !quoted) {\n          return ''\n        }\n        if (c === '\"') {\n          quoted = !quoted\n        }\n        return c\n      })\n      .join('')\n    this.url.searchParams.set('select', cleanedColumns)\n    this.headers.append('Prefer', 'return=representation')\n    return this as unknown as PostgrestFilterBuilder<\n      ClientOptions,\n      Schema,\n      Row,\n      Method extends 'RPC'\n        ? Result extends unknown[]\n          ? NewResultOne[]\n          : NewResultOne\n        : NewResultOne[],\n      RelationName,\n      Relationships,\n      Method\n    >\n  }\n\n  order<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    options?: { ascending?: boolean; nullsFirst?: boolean; referencedTable?: undefined }\n  ): this\n  order(\n    column: string,\n    options?: { ascending?: boolean; nullsFirst?: boolean; referencedTable?: string }\n  ): this\n  /**\n   * @deprecated Use `options.referencedTable` instead of `options.foreignTable`\n   */\n  order<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    options?: { ascending?: boolean; nullsFirst?: boolean; foreignTable?: undefined }\n  ): this\n  /**\n   * @deprecated Use `options.referencedTable` instead of `options.foreignTable`\n   */\n  order(\n    column: string,\n    options?: { ascending?: boolean; nullsFirst?: boolean; foreignTable?: string }\n  ): this\n  /**\n   * Order the query result by `column`.\n   *\n   * You can call this method multiple times to order by multiple columns.\n   *\n   * You can order referenced tables, but it only affects the ordering of the\n   * parent table if you use `!inner` in the query.\n   *\n   * @param column - The column to order by\n   * @param options - Named parameters\n   * @param options.ascending - If `true`, the result will be in ascending order\n   * @param options.nullsFirst - If `true`, `null`s appear first. If `false`,\n   * `null`s appear last.\n   * @param options.referencedTable - Set this to order a referenced table by\n   * its columns\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  order(\n    column: string,\n    {\n      ascending = true,\n      nullsFirst,\n      foreignTable,\n      referencedTable = foreignTable,\n    }: {\n      ascending?: boolean\n      nullsFirst?: boolean\n      foreignTable?: string\n      referencedTable?: string\n    } = {}\n  ): this {\n    const key = referencedTable ? `${referencedTable}.order` : 'order'\n    const existingOrder = this.url.searchParams.get(key)\n\n    this.url.searchParams.set(\n      key,\n      `${existingOrder ? `${existingOrder},` : ''}${column}.${ascending ? 'asc' : 'desc'}${\n        nullsFirst === undefined ? '' : nullsFirst ? '.nullsfirst' : '.nullslast'\n      }`\n    )\n    return this\n  }\n\n  /**\n   * Limit the query result by `count`.\n   *\n   * @param count - The maximum number of rows to return\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to limit rows of referenced\n   * tables instead of the parent table\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  limit(\n    count: number,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const key = typeof referencedTable === 'undefined' ? 'limit' : `${referencedTable}.limit`\n    this.url.searchParams.set(key, `${count}`)\n    return this\n  }\n\n  /**\n   * Limit the query result by starting at an offset `from` and ending at the offset `to`.\n   * Only records within this range are returned.\n   * This respects the query order and if there is no order clause the range could behave unexpectedly.\n   * The `from` and `to` values are 0-based and inclusive: `range(1, 3)` will include the second, third\n   * and fourth rows of the query.\n   *\n   * @param from - The starting index from which to limit the result\n   * @param to - The last index to which to limit the result\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to limit rows of referenced\n   * tables instead of the parent table\n   * @param options.foreignTable - Deprecated, use `options.referencedTable`\n   * instead\n   */\n  range(\n    from: number,\n    to: number,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const keyOffset =\n      typeof referencedTable === 'undefined' ? 'offset' : `${referencedTable}.offset`\n    const keyLimit = typeof referencedTable === 'undefined' ? 'limit' : `${referencedTable}.limit`\n    this.url.searchParams.set(keyOffset, `${from}`)\n    // Range is inclusive, so add 1\n    this.url.searchParams.set(keyLimit, `${to - from + 1}`)\n    return this\n  }\n\n  /**\n   * Set the AbortSignal for the fetch request.\n   *\n   * @param signal - The AbortSignal to use for the fetch request\n   */\n  abortSignal(signal: AbortSignal): this {\n    this.signal = signal\n    return this\n  }\n\n  /**\n   * Return `data` as a single object instead of an array of objects.\n   *\n   * Query result must be one row (e.g. using `.limit(1)`), otherwise this\n   * returns an error.\n   */\n  single<ResultOne = Result extends (infer ResultOne)[] ? ResultOne : never>(): PostgrestBuilder<\n    ClientOptions,\n    ResultOne\n  > {\n    this.headers.set('Accept', 'application/vnd.pgrst.object+json')\n    return this as unknown as PostgrestBuilder<ClientOptions, ResultOne>\n  }\n\n  /**\n   * Return `data` as a single object instead of an array of objects.\n   *\n   * Query result must be zero or one row (e.g. using `.limit(1)`), otherwise\n   * this returns an error.\n   */\n  maybeSingle<\n    ResultOne = Result extends (infer ResultOne)[] ? ResultOne : never,\n  >(): PostgrestBuilder<ClientOptions, ResultOne | null> {\n    // Temporary partial fix for https://github.com/supabase/postgrest-js/issues/361\n    // Issue persists e.g. for `.insert([...]).select().maybeSingle()`\n    if (this.method === 'GET') {\n      this.headers.set('Accept', 'application/json')\n    } else {\n      this.headers.set('Accept', 'application/vnd.pgrst.object+json')\n    }\n    this.isMaybeSingle = true\n    return this as unknown as PostgrestBuilder<ClientOptions, ResultOne | null>\n  }\n\n  /**\n   * Return `data` as a string in CSV format.\n   */\n  csv(): PostgrestBuilder<ClientOptions, string> {\n    this.headers.set('Accept', 'text/csv')\n    return this as unknown as PostgrestBuilder<ClientOptions, string>\n  }\n\n  /**\n   * Return `data` as an object in [GeoJSON](https://geojson.org) format.\n   */\n  geojson(): PostgrestBuilder<ClientOptions, Record<string, unknown>> {\n    this.headers.set('Accept', 'application/geo+json')\n    return this as unknown as PostgrestBuilder<ClientOptions, Record<string, unknown>>\n  }\n\n  /**\n   * Return `data` as the EXPLAIN plan for the query.\n   *\n   * You need to enable the\n   * [db_plan_enabled](https://supabase.com/docs/guides/database/debugging-performance#enabling-explain)\n   * setting before using this method.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.analyze - If `true`, the query will be executed and the\n   * actual run time will be returned\n   *\n   * @param options.verbose - If `true`, the query identifier will be returned\n   * and `data` will include the output columns of the query\n   *\n   * @param options.settings - If `true`, include information on configuration\n   * parameters that affect query planning\n   *\n   * @param options.buffers - If `true`, include information on buffer usage\n   *\n   * @param options.wal - If `true`, include information on WAL record generation\n   *\n   * @param options.format - The format of the output, can be `\"text\"` (default)\n   * or `\"json\"`\n   */\n  explain({\n    analyze = false,\n    verbose = false,\n    settings = false,\n    buffers = false,\n    wal = false,\n    format = 'text',\n  }: {\n    analyze?: boolean\n    verbose?: boolean\n    settings?: boolean\n    buffers?: boolean\n    wal?: boolean\n    format?: 'json' | 'text'\n  } = {}) {\n    const options = [\n      analyze ? 'analyze' : null,\n      verbose ? 'verbose' : null,\n      settings ? 'settings' : null,\n      buffers ? 'buffers' : null,\n      wal ? 'wal' : null,\n    ]\n      .filter(Boolean)\n      .join('|')\n    // An Accept header can carry multiple media types but postgrest-js always sends one\n    const forMediatype = this.headers.get('Accept') ?? 'application/json'\n    this.headers.set(\n      'Accept',\n      `application/vnd.pgrst.plan+${format}; for=\"${forMediatype}\"; options=${options};`\n    )\n    if (format === 'json') {\n      return this as unknown as PostgrestBuilder<ClientOptions, Record<string, unknown>[]>\n    } else {\n      return this as unknown as PostgrestBuilder<ClientOptions, string>\n    }\n  }\n\n  /**\n   * Rollback the query.\n   *\n   * `data` will still be returned, but the query is not committed.\n   */\n  rollback(): this {\n    this.headers.append('Prefer', 'tx=rollback')\n    return this\n  }\n\n  /**\n   * Override the type of the returned `data`.\n   *\n   * @typeParam NewResult - The new result type to override with\n   * @deprecated Use overrideTypes<yourType, { merge: false }>() method at the end of your call chain instead\n   */\n  returns<NewResult>(): PostgrestTransformBuilder<\n    ClientOptions,\n    Schema,\n    Row,\n    CheckMatchingArrayTypes<Result, NewResult>,\n    RelationName,\n    Relationships,\n    Method\n  > {\n    return this as unknown as PostgrestTransformBuilder<\n      ClientOptions,\n      Schema,\n      Row,\n      CheckMatchingArrayTypes<Result, NewResult>,\n      RelationName,\n      Relationships,\n      Method\n    >\n  }\n\n  /**\n   * Set the maximum number of rows that can be affected by the query.\n   * Only available in PostgREST v13+ and only works with PATCH and DELETE methods.\n   *\n   * @param value - The maximum number of rows that can be affected\n   */\n  maxAffected(value: number): MaxAffectedEnabled<ClientOptions['PostgrestVersion']> extends true\n    ? // TODO: update the RPC case to only work on RPC that returns SETOF rows\n      Method extends 'PATCH' | 'DELETE' | 'RPC'\n      ? this\n      : InvalidMethodError<'maxAffected method only available on update or delete'>\n    : InvalidMethodError<'maxAffected method only available on postgrest 13+'> {\n    this.headers.append('Prefer', 'handling=strict')\n    this.headers.append('Prefer', `max-affected=${value}`)\n    return this as unknown as MaxAffectedEnabled<ClientOptions['PostgrestVersion']> extends true\n      ? Method extends 'PATCH' | 'DELETE' | 'RPC'\n        ? this\n        : InvalidMethodError<'maxAffected method only available on update or delete'>\n      : InvalidMethodError<'maxAffected method only available on postgrest 13+'>\n  }\n}\n","import { isStorageError } from '../lib/errors'\nimport { DownloadResult } from '../lib/types'\nimport StreamDownloadBuilder from './StreamDownloadBuilder'\n\nexport default class BlobDownloadBuilder implements Promise<DownloadResult<Blob>> {\n  readonly [Symbol.toStringTag]: string = 'BlobDownloadBuilder'\n  private promise: Promise<DownloadResult<Blob>> | null = null\n\n  constructor(\n    private downloadFn: () => Promise<Response>,\n    private shouldThrowOnError: boolean\n  ) {}\n\n  asStream(): StreamDownloadBuilder {\n    return new StreamDownloadBuilder(this.downloadFn, this.shouldThrowOnError)\n  }\n\n  then<TResult1 = DownloadResult<Blob>, TResult2 = never>(\n    onfulfilled?: ((value: DownloadResult<Blob>) => TResult1 | PromiseLike<TResult1>) | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | null\n  ): Promise<TResult1 | TResult2> {\n    return this.getPromise().then(onfulfilled, onrejected)\n  }\n\n  catch<TResult = never>(\n    onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | null\n  ): Promise<DownloadResult<Blob> | TResult> {\n    return this.getPromise().catch(onrejected)\n  }\n\n  finally(onfinally?: (() => void) | null): Promise<DownloadResult<Blob>> {\n    return this.getPromise().finally(onfinally)\n  }\n\n  private getPromise(): Promise<DownloadResult<Blob>> {\n    if (!this.promise) {\n      this.promise = this.execute()\n    }\n    return this.promise\n  }\n\n  private async execute(): Promise<DownloadResult<Blob>> {\n    try {\n      const result = await this.downloadFn()\n\n      return {\n        data: await result.blob(),\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n}\n","import { createFetchClient } from '../http/createFetchClient'\nimport type { AuthConfig, HttpClient } from '../http/types'\nimport { NamespaceOperations } from './namespaces'\nimport { TableOperations } from './tables'\nimport type {\n  CreateTableRequest,\n  CreateNamespaceResponse,\n  CommitTableResponse,\n  NamespaceIdentifier,\n  NamespaceMetadata,\n  TableIdentifier,\n  TableMetadata,\n  UpdateTableRequest,\n  DropTableRequest,\n} from './types'\n\n/**\n * Access delegation mechanisms supported by the Iceberg REST Catalog.\n *\n * - `vended-credentials`: Server provides temporary credentials for data access\n * - `remote-signing`: Server signs requests on behalf of the client\n */\nexport type AccessDelegation = 'vended-credentials' | 'remote-signing'\n\n/**\n * Configuration options for the Iceberg REST Catalog client.\n */\nexport interface IcebergRestCatalogOptions {\n  /** Base URL of the Iceberg REST Catalog API */\n  baseUrl: string\n  /** Optional catalog name prefix for multi-catalog servers */\n  catalogName?: string\n  /** Authentication configuration */\n  auth?: AuthConfig\n  /** Custom fetch implementation (defaults to globalThis.fetch) */\n  fetch?: typeof fetch\n  /**\n   * Access delegation mechanisms to request from the server.\n   * When specified, the X-Iceberg-Access-Delegation header will be sent\n   * with supported operations (createTable, loadTable).\n   *\n   * @example ['vended-credentials']\n   * @example ['vended-credentials', 'remote-signing']\n   */\n  accessDelegation?: AccessDelegation[]\n}\n\n/**\n * Client for interacting with an Apache Iceberg REST Catalog.\n *\n * This class provides methods for managing namespaces and tables in an Iceberg catalog.\n * It handles authentication, request formatting, and error handling automatically.\n *\n * @example\n * ```typescript\n * const catalog = new IcebergRestCatalog({\n *   baseUrl: 'https://my-catalog.example.com/iceberg/v1',\n *   auth: { type: 'bearer', token: process.env.ICEBERG_TOKEN }\n * });\n *\n * // Create a namespace\n * await catalog.createNamespace({ namespace: ['analytics'] });\n *\n * // Create a table\n * await catalog.createTable(\n *   { namespace: ['analytics'] },\n *   {\n *     name: 'events',\n *     schema: { type: 'struct', fields: [...] }\n *   }\n * );\n * ```\n */\nexport class IcebergRestCatalog {\n  private readonly client: HttpClient\n  private readonly namespaceOps: NamespaceOperations\n  private readonly tableOps: TableOperations\n  private readonly accessDelegation?: string\n\n  /**\n   * Creates a new Iceberg REST Catalog client.\n   *\n   * @param options - Configuration options for the catalog client\n   */\n  constructor(options: IcebergRestCatalogOptions) {\n    let prefix = 'v1'\n    if (options.catalogName) {\n      prefix += `/${options.catalogName}`\n    }\n\n    const baseUrl = options.baseUrl.endsWith('/') ? options.baseUrl : `${options.baseUrl}/`\n\n    this.client = createFetchClient({\n      baseUrl,\n      auth: options.auth,\n      fetchImpl: options.fetch,\n    })\n\n    // Format accessDelegation as comma-separated string per spec\n    this.accessDelegation = options.accessDelegation?.join(',')\n\n    this.namespaceOps = new NamespaceOperations(this.client, prefix)\n    this.tableOps = new TableOperations(this.client, prefix, this.accessDelegation)\n  }\n\n  /**\n   * Lists all namespaces in the catalog.\n   *\n   * @param parent - Optional parent namespace to list children under\n   * @returns Array of namespace identifiers\n   *\n   * @example\n   * ```typescript\n   * // List all top-level namespaces\n   * const namespaces = await catalog.listNamespaces();\n   *\n   * // List namespaces under a parent\n   * const children = await catalog.listNamespaces({ namespace: ['analytics'] });\n   * ```\n   */\n  async listNamespaces(parent?: NamespaceIdentifier): Promise<NamespaceIdentifier[]> {\n    return this.namespaceOps.listNamespaces(parent)\n  }\n\n  /**\n   * Creates a new namespace in the catalog.\n   *\n   * @param id - Namespace identifier to create\n   * @param metadata - Optional metadata properties for the namespace\n   * @returns Response containing the created namespace and its properties\n   *\n   * @example\n   * ```typescript\n   * const response = await catalog.createNamespace(\n   *   { namespace: ['analytics'] },\n   *   { properties: { owner: 'data-team' } }\n   * );\n   * console.log(response.namespace); // ['analytics']\n   * console.log(response.properties); // { owner: 'data-team', ... }\n   * ```\n   */\n  async createNamespace(id: NamespaceIdentifier, metadata?: NamespaceMetadata): Promise<CreateNamespaceResponse> {\n    return this.namespaceOps.createNamespace(id, metadata)\n  }\n\n  /**\n   * Drops a namespace from the catalog.\n   *\n   * The namespace must be empty (contain no tables) before it can be dropped.\n   *\n   * @param id - Namespace identifier to drop\n   *\n   * @example\n   * ```typescript\n   * await catalog.dropNamespace({ namespace: ['analytics'] });\n   * ```\n   */\n  async dropNamespace(id: NamespaceIdentifier): Promise<void> {\n    await this.namespaceOps.dropNamespace(id)\n  }\n\n  /**\n   * Loads metadata for a namespace.\n   *\n   * @param id - Namespace identifier to load\n   * @returns Namespace metadata including properties\n   *\n   * @example\n   * ```typescript\n   * const metadata = await catalog.loadNamespaceMetadata({ namespace: ['analytics'] });\n   * console.log(metadata.properties);\n   * ```\n   */\n  async loadNamespaceMetadata(id: NamespaceIdentifier): Promise<NamespaceMetadata> {\n    return this.namespaceOps.loadNamespaceMetadata(id)\n  }\n\n  /**\n   * Lists all tables in a namespace.\n   *\n   * @param namespace - Namespace identifier to list tables from\n   * @returns Array of table identifiers\n   *\n   * @example\n   * ```typescript\n   * const tables = await catalog.listTables({ namespace: ['analytics'] });\n   * console.log(tables); // [{ namespace: ['analytics'], name: 'events' }, ...]\n   * ```\n   */\n  async listTables(namespace: NamespaceIdentifier): Promise<TableIdentifier[]> {\n    return this.tableOps.listTables(namespace)\n  }\n\n  /**\n   * Creates a new table in the catalog.\n   *\n   * @param namespace - Namespace to create the table in\n   * @param request - Table creation request including name, schema, partition spec, etc.\n   * @returns Table metadata for the created table\n   *\n   * @example\n   * ```typescript\n   * const metadata = await catalog.createTable(\n   *   { namespace: ['analytics'] },\n   *   {\n   *     name: 'events',\n   *     schema: {\n   *       type: 'struct',\n   *       fields: [\n   *         { id: 1, name: 'id', type: 'long', required: true },\n   *         { id: 2, name: 'timestamp', type: 'timestamp', required: true }\n   *       ],\n   *       'schema-id': 0\n   *     },\n   *     'partition-spec': {\n   *       'spec-id': 0,\n   *       fields: [\n   *         { source_id: 2, field_id: 1000, name: 'ts_day', transform: 'day' }\n   *       ]\n   *     }\n   *   }\n   * );\n   * ```\n   */\n  async createTable(\n    namespace: NamespaceIdentifier,\n    request: CreateTableRequest\n  ): Promise<TableMetadata> {\n    return this.tableOps.createTable(namespace, request)\n  }\n\n  /**\n   * Updates an existing table's metadata.\n   *\n   * Can update the schema, partition spec, or properties of a table.\n   *\n   * @param id - Table identifier to update\n   * @param request - Update request with fields to modify\n   * @returns Response containing the metadata location and updated table metadata\n   *\n   * @example\n   * ```typescript\n   * const response = await catalog.updateTable(\n   *   { namespace: ['analytics'], name: 'events' },\n   *   {\n   *     properties: { 'read.split.target-size': '134217728' }\n   *   }\n   * );\n   * console.log(response['metadata-location']); // s3://...\n   * console.log(response.metadata); // TableMetadata object\n   * ```\n   */\n  async updateTable(id: TableIdentifier, request: UpdateTableRequest): Promise<CommitTableResponse> {\n    return this.tableOps.updateTable(id, request)\n  }\n\n  /**\n   * Drops a table from the catalog.\n   *\n   * @param id - Table identifier to drop\n   *\n   * @example\n   * ```typescript\n   * await catalog.dropTable({ namespace: ['analytics'], name: 'events' });\n   * ```\n   */\n  async dropTable(id: TableIdentifier, options?: DropTableRequest): Promise<void> {\n    await this.tableOps.dropTable(id, options)\n  }\n\n  /**\n   * Loads metadata for a table.\n   *\n   * @param id - Table identifier to load\n   * @returns Table metadata including schema, partition spec, location, etc.\n   *\n   * @example\n   * ```typescript\n   * const metadata = await catalog.loadTable({ namespace: ['analytics'], name: 'events' });\n   * console.log(metadata.schema);\n   * console.log(metadata.location);\n   * ```\n   */\n  async loadTable(id: TableIdentifier): Promise<TableMetadata> {\n    return this.tableOps.loadTable(id)\n  }\n\n  /**\n   * Checks if a namespace exists in the catalog.\n   *\n   * @param id - Namespace identifier to check\n   * @returns True if the namespace exists, false otherwise\n   *\n   * @example\n   * ```typescript\n   * const exists = await catalog.namespaceExists({ namespace: ['analytics'] });\n   * console.log(exists); // true or false\n   * ```\n   */\n  async namespaceExists(id: NamespaceIdentifier): Promise<boolean> {\n    return this.namespaceOps.namespaceExists(id)\n  }\n\n  /**\n   * Checks if a table exists in the catalog.\n   *\n   * @param id - Table identifier to check\n   * @returns True if the table exists, false otherwise\n   *\n   * @example\n   * ```typescript\n   * const exists = await catalog.tableExists({ namespace: ['analytics'], name: 'events' });\n   * console.log(exists); // true or false\n   * ```\n   */\n  async tableExists(id: TableIdentifier): Promise<boolean> {\n    return this.tableOps.tableExists(id)\n  }\n\n  /**\n   * Creates a namespace if it does not exist.\n   *\n   * If the namespace already exists, returns void. If created, returns the response.\n   *\n   * @param id - Namespace identifier to create\n   * @param metadata - Optional metadata properties for the namespace\n   * @returns Response containing the created namespace and its properties, or void if it already exists\n   *\n   * @example\n   * ```typescript\n   * const response = await catalog.createNamespaceIfNotExists(\n   *   { namespace: ['analytics'] },\n   *   { properties: { owner: 'data-team' } }\n   * );\n   * if (response) {\n   *   console.log('Created:', response.namespace);\n   * } else {\n   *   console.log('Already exists');\n   * }\n   * ```\n   */\n  async createNamespaceIfNotExists(\n    id: NamespaceIdentifier,\n    metadata?: NamespaceMetadata\n  ): Promise<CreateNamespaceResponse | void> {\n    return this.namespaceOps.createNamespaceIfNotExists(id, metadata)\n  }\n\n  /**\n   * Creates a table if it does not exist.\n   *\n   * If the table already exists, returns its metadata instead.\n   *\n   * @param namespace - Namespace to create the table in\n   * @param request - Table creation request including name, schema, partition spec, etc.\n   * @returns Table metadata for the created or existing table\n   *\n   * @example\n   * ```typescript\n   * const metadata = await catalog.createTableIfNotExists(\n   *   { namespace: ['analytics'] },\n   *   {\n   *     name: 'events',\n   *     schema: {\n   *       type: 'struct',\n   *       fields: [\n   *         { id: 1, name: 'id', type: 'long', required: true },\n   *         { id: 2, name: 'timestamp', type: 'timestamp', required: true }\n   *       ],\n   *       'schema-id': 0\n   *     }\n   *   }\n   * );\n   * ```\n   */\n  async createTableIfNotExists(\n    namespace: NamespaceIdentifier,\n    request: CreateTableRequest\n  ): Promise<TableMetadata> {\n    return this.tableOps.createTableIfNotExists(namespace, request)\n  }\n}\n","import { isStorageError, StorageError, StorageUnknownError } from '../lib/errors'\nimport { Fetch, get, head, post, put, remove } from '../lib/fetch'\nimport { recursiveToCamel, resolveFetch } from '../lib/helpers'\nimport {\n  FileObject,\n  FileOptions,\n  SearchOptions,\n  FetchParameters,\n  TransformOptions,\n  DestinationOptions,\n  FileObjectV2,\n  Camelize,\n  SearchV2Options,\n  SearchV2Result,\n} from '../lib/types'\nimport BlobDownloadBuilder from './BlobDownloadBuilder'\n\nconst DEFAULT_SEARCH_OPTIONS = {\n  limit: 100,\n  offset: 0,\n  sortBy: {\n    column: 'name',\n    order: 'asc',\n  },\n}\n\nconst DEFAULT_FILE_OPTIONS: FileOptions = {\n  cacheControl: '3600',\n  contentType: 'text/plain;charset=UTF-8',\n  upsert: false,\n}\n\ntype FileBody =\n  | ArrayBuffer\n  | ArrayBufferView\n  | Blob\n  | Buffer\n  | File\n  | FormData\n  | NodeJS.ReadableStream\n  | ReadableStream<Uint8Array>\n  | URLSearchParams\n  | string\n\nexport default class StorageFileApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected bucketId?: string\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    bucketId?: string,\n    fetch?: Fetch\n  ) {\n    this.url = url\n    this.headers = headers\n    this.bucketId = bucketId\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /**\n   * Enable throwing errors instead of returning them.\n   *\n   * @category File Buckets\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * Uploads a file to an existing bucket or replaces an existing file at the specified path with a new one.\n   *\n   * @param method HTTP method.\n   * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param fileBody The body of the file to be stored in the bucket.\n   */\n  private async uploadOrUpdate(\n    method: 'POST' | 'PUT',\n    path: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let body\n      const options = { ...DEFAULT_FILE_OPTIONS, ...fileOptions }\n      let headers: Record<string, string> = {\n        ...this.headers,\n        ...(method === 'POST' && { 'x-upsert': String(options.upsert as boolean) }),\n      }\n\n      const metadata = options.metadata\n\n      if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n        body = new FormData()\n        body.append('cacheControl', options.cacheControl as string)\n        if (metadata) {\n          body.append('metadata', this.encodeMetadata(metadata))\n        }\n        body.append('', fileBody)\n      } else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n        body = fileBody\n        // Only append if not already present\n        if (!body.has('cacheControl')) {\n          body.append('cacheControl', options.cacheControl as string)\n        }\n        if (metadata && !body.has('metadata')) {\n          body.append('metadata', this.encodeMetadata(metadata))\n        }\n      } else {\n        body = fileBody\n        headers['cache-control'] = `max-age=${options.cacheControl}`\n        headers['content-type'] = options.contentType as string\n\n        if (metadata) {\n          headers['x-metadata'] = this.toBase64(this.encodeMetadata(metadata))\n        }\n\n        // Node.js streams require duplex option for fetch in Node 20+\n        // Check for both web ReadableStream and Node.js streams\n        const isStream =\n          (typeof ReadableStream !== 'undefined' && body instanceof ReadableStream) ||\n          (body && typeof body === 'object' && 'pipe' in body && typeof body.pipe === 'function')\n\n        if (isStream && !options.duplex) {\n          options.duplex = 'half'\n        }\n      }\n\n      if (fileOptions?.headers) {\n        headers = { ...headers, ...fileOptions.headers }\n      }\n\n      const cleanPath = this._removeEmptyFolders(path)\n      const _path = this._getFinalPath(cleanPath)\n      const data = await (method == 'PUT' ? put : post)(\n        this.fetch,\n        `${this.url}/object/${_path}`,\n        body as object,\n        { headers, ...(options?.duplex ? { duplex: options.duplex } : {}) }\n      )\n\n      return {\n        data: { path: cleanPath, id: data.Id, fullPath: data.Key },\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Uploads a file to an existing bucket.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n   * @returns Promise with response containing file path, id, and fullPath or error\n   *\n   * @example Upload file\n   * ```js\n   * const avatarFile = event.target.files[0]\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .upload('public/avatar1.png', avatarFile, {\n   *     cacheControl: '3600',\n   *     upsert: false\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"public/avatar1.png\",\n   *     \"fullPath\": \"avatars/public/avatar1.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Upload file using `ArrayBuffer` from base64 file data\n   * ```js\n   * import { decode } from 'base64-arraybuffer'\n   *\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .upload('public/avatar1.png', decode('base64FileData'), {\n   *     contentType: 'image/png'\n   *   })\n   * ```\n   */\n  async upload(\n    path: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.uploadOrUpdate('POST', path, fileBody, fileOptions)\n  }\n\n  /**\n   * Upload a file with a token generated from `createSignedUploadUrl`.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n   * @param token The token generated from `createSignedUploadUrl`\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions HTTP headers (cacheControl, contentType, etc.).\n   * **Note:** The `upsert` option has no effect here. To enable upsert behavior,\n   * pass `{ upsert: true }` when calling `createSignedUploadUrl()` instead.\n   * @returns Promise with response containing file path and fullPath or error\n   *\n   * @example Upload to a signed URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .uploadToSignedUrl('folder/cat.jpg', 'token-from-createSignedUploadUrl', file)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"folder/cat.jpg\",\n   *     \"fullPath\": \"avatars/folder/cat.jpg\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async uploadToSignedUrl(\n    path: string,\n    token: string,\n    fileBody: FileBody,\n    fileOptions?: FileOptions\n  ) {\n    const cleanPath = this._removeEmptyFolders(path)\n    const _path = this._getFinalPath(cleanPath)\n\n    const url = new URL(this.url + `/object/upload/sign/${_path}`)\n    url.searchParams.set('token', token)\n\n    try {\n      let body\n      const options = { upsert: DEFAULT_FILE_OPTIONS.upsert, ...fileOptions }\n      const headers: Record<string, string> = {\n        ...this.headers,\n        ...{ 'x-upsert': String(options.upsert as boolean) },\n      }\n\n      if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n        body = new FormData()\n        body.append('cacheControl', options.cacheControl as string)\n        body.append('', fileBody)\n      } else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n        body = fileBody\n        body.append('cacheControl', options.cacheControl as string)\n      } else {\n        body = fileBody\n        headers['cache-control'] = `max-age=${options.cacheControl}`\n        headers['content-type'] = options.contentType as string\n      }\n\n      const data = await put(this.fetch, url.toString(), body as object, { headers })\n\n      return {\n        data: { path: cleanPath, fullPath: data.Key },\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a signed upload URL.\n   * Signed upload URLs can be used to upload files to the bucket without further authentication.\n   * They are valid for 2 hours.\n   *\n   * @category File Buckets\n   * @param path The file path, including the current file name. For example `folder/image.png`.\n   * @param options.upsert If set to true, allows the file to be overwritten if it already exists.\n   * @returns Promise with response containing signed upload URL, token, and path or error\n   *\n   * @example Create Signed Upload URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUploadUrl('folder/cat.jpg')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/upload/sign/avatars/folder/cat.jpg?token=<TOKEN>\",\n   *     \"path\": \"folder/cat.jpg\",\n   *     \"token\": \"<TOKEN>\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createSignedUploadUrl(\n    path: string,\n    options?: { upsert: boolean }\n  ): Promise<\n    | {\n        data: { signedUrl: string; token: string; path: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let _path = this._getFinalPath(path)\n\n      const headers = { ...this.headers }\n\n      if (options?.upsert) {\n        headers['x-upsert'] = 'true'\n      }\n\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/upload/sign/${_path}`,\n        {},\n        { headers }\n      )\n\n      const url = new URL(this.url + data.url)\n\n      const token = url.searchParams.get('token')\n\n      if (!token) {\n        throw new StorageError('No token returned by API')\n      }\n\n      return { data: { signedUrl: url.toString(), path, token }, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Replaces an existing file at the specified path with a new one.\n   *\n   * @category File Buckets\n   * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to update.\n   * @param fileBody The body of the file to be stored in the bucket.\n   * @param fileOptions Optional file upload options including cacheControl, contentType, upsert, and metadata.\n   * @returns Promise with response containing file path, id, and fullPath or error\n   *\n   * @example Update file\n   * ```js\n   * const avatarFile = event.target.files[0]\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .update('public/avatar1.png', avatarFile, {\n   *     cacheControl: '3600',\n   *     upsert: true\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"public/avatar1.png\",\n   *     \"fullPath\": \"avatars/public/avatar1.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Update file using `ArrayBuffer` from base64 file data\n   * ```js\n   * import {decode} from 'base64-arraybuffer'\n   *\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .update('public/avatar1.png', decode('base64FileData'), {\n   *     contentType: 'image/png'\n   *   })\n   * ```\n   */\n  async update(\n    path: string,\n    fileBody:\n      | ArrayBuffer\n      | ArrayBufferView\n      | Blob\n      | Buffer\n      | File\n      | FormData\n      | NodeJS.ReadableStream\n      | ReadableStream<Uint8Array>\n      | URLSearchParams\n      | string,\n    fileOptions?: FileOptions\n  ): Promise<\n    | {\n        data: { id: string; path: string; fullPath: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    return this.uploadOrUpdate('PUT', path, fileBody, fileOptions)\n  }\n\n  /**\n   * Moves an existing file to a new path in the same bucket.\n   *\n   * @category File Buckets\n   * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n   * @param toPath The new file path, including the new file name. For example `folder/image-new.png`.\n   * @param options The destination options.\n   * @returns Promise with response containing success message or error\n   *\n   * @example Move file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .move('public/avatar1.png', 'private/avatar2.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully moved\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async move(\n    fromPath: string,\n    toPath: string,\n    options?: DestinationOptions\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/move`,\n        {\n          bucketId: this.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options?.destinationBucket,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Copies an existing file to a new path in the same bucket.\n   *\n   * @category File Buckets\n   * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n   * @param toPath The new file path, including the new file name. For example `folder/image-copy.png`.\n   * @param options The destination options.\n   * @returns Promise with response containing copied file path or error\n   *\n   * @example Copy file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .copy('public/avatar1.png', 'private/avatar2.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"path\": \"avatars/private/avatar2.png\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async copy(\n    fromPath: string,\n    toPath: string,\n    options?: DestinationOptions\n  ): Promise<\n    | {\n        data: { path: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/copy`,\n        {\n          bucketId: this.bucketId,\n          sourceKey: fromPath,\n          destinationKey: toPath,\n          destinationBucket: options?.destinationBucket,\n        },\n        { headers: this.headers }\n      )\n      return { data: { path: data.Key }, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a signed URL. Use a signed URL to share a file for a fixed amount of time.\n   *\n   * @category File Buckets\n   * @param path The file path, including the current file name. For example `folder/image.png`.\n   * @param expiresIn The number of seconds until the signed URL expires. For example, `60` for a URL which is valid for one minute.\n   * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns Promise with response containing signed URL or error\n   *\n   * @example Create Signed URL\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Create a signed URL for an asset with transformations\n   * ```js\n   * const { data } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60, {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *     }\n   *   })\n   * ```\n   *\n   * @example Create a signed URL which triggers the download of the asset\n   * ```js\n   * const { data } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrl('folder/avatar1.png', 60, {\n   *     download: true,\n   *   })\n   * ```\n   */\n  async createSignedUrl(\n    path: string,\n    expiresIn: number,\n    options?: { download?: string | boolean; transform?: TransformOptions }\n  ): Promise<\n    | {\n        data: { signedUrl: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      let _path = this._getFinalPath(path)\n\n      let data = await post(\n        this.fetch,\n        `${this.url}/object/sign/${_path}`,\n        { expiresIn, ...(options?.transform ? { transform: options.transform } : {}) },\n        { headers: this.headers }\n      )\n      const downloadQueryParam = options?.download\n        ? `&download=${options.download === true ? '' : options.download}`\n        : ''\n      const signedUrl = encodeURI(`${this.url}${data.signedURL}${downloadQueryParam}`)\n      data = { signedUrl }\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates multiple signed URLs. Use a signed URL to share a file for a fixed amount of time.\n   *\n   * @category File Buckets\n   * @param paths The file paths to be downloaded, including the current file names. For example `['folder/image.png', 'folder2/image2.png']`.\n   * @param expiresIn The number of seconds until the signed URLs expire. For example, `60` for URLs which are valid for one minute.\n   * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @returns Promise with response containing array of objects with signedUrl, path, and error or error\n   *\n   * @example Create Signed URLs\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .createSignedUrls(['folder/avatar1.png', 'folder/avatar2.png'], 60)\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"error\": null,\n   *       \"path\": \"folder/avatar1.png\",\n   *       \"signedURL\": \"/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\",\n   *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar1.png?token=<TOKEN>\"\n   *     },\n   *     {\n   *       \"error\": null,\n   *       \"path\": \"folder/avatar2.png\",\n   *       \"signedURL\": \"/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\",\n   *       \"signedUrl\": \"https://example.supabase.co/storage/v1/object/sign/avatars/folder/avatar2.png?token=<TOKEN>\"\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createSignedUrls(\n    paths: string[],\n    expiresIn: number,\n    options?: { download: string | boolean }\n  ): Promise<\n    | {\n        data: { error: string | null; path: string | null; signedUrl: string }[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/sign/${this.bucketId}`,\n        { expiresIn, paths },\n        { headers: this.headers }\n      )\n\n      const downloadQueryParam = options?.download\n        ? `&download=${options.download === true ? '' : options.download}`\n        : ''\n      return {\n        data: data.map((datum: { signedURL: string }) => ({\n          ...datum,\n          signedUrl: datum.signedURL\n            ? encodeURI(`${this.url}${datum.signedURL}${downloadQueryParam}`)\n            : null,\n        })),\n        error: null,\n      }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Downloads a file from a private bucket. For public buckets, make a request to the URL returned from `getPublicUrl` instead.\n   *\n   * @category File Buckets\n   * @param path The full path and file name of the file to be downloaded. For example `folder/image.png`.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns BlobDownloadBuilder instance for downloading the file\n   *\n   * @example Download file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": <BLOB>,\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Download file with transformations\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .download('folder/avatar1.png', {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *       quality: 80\n   *     }\n   *   })\n   * ```\n   */\n  download<Options extends { transform?: TransformOptions }>(\n    path: string,\n    options?: Options\n  ): BlobDownloadBuilder {\n    const wantsTransformation = typeof options?.transform !== 'undefined'\n    const renderPath = wantsTransformation ? 'render/image/authenticated' : 'object'\n    const transformationQuery = this.transformOptsToQueryString(options?.transform || {})\n    const queryString = transformationQuery ? `?${transformationQuery}` : ''\n    const _path = this._getFinalPath(path)\n    const downloadFn = () =>\n      get(this.fetch, `${this.url}/${renderPath}/${_path}${queryString}`, {\n        headers: this.headers,\n        noResolveJson: true,\n      })\n    return new BlobDownloadBuilder(downloadFn, this.shouldThrowOnError)\n  }\n\n  /**\n   * Retrieves the details of an existing file.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. For example `folder/image.png`.\n   * @returns Promise with response containing file metadata or error\n   *\n   * @example Get file info\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .info('folder/avatar1.png')\n   * ```\n   */\n  async info(path: string): Promise<\n    | {\n        data: Camelize<FileObjectV2>\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    const _path = this._getFinalPath(path)\n\n    try {\n      const data = await get(this.fetch, `${this.url}/object/info/${_path}`, {\n        headers: this.headers,\n      })\n\n      return { data: recursiveToCamel(data) as Camelize<FileObjectV2>, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Checks the existence of a file.\n   *\n   * @category File Buckets\n   * @param path The file path, including the file name. For example `folder/image.png`.\n   * @returns Promise with response containing boolean indicating file existence or error\n   *\n   * @example Check file existence\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .exists('folder/avatar1.png')\n   * ```\n   */\n  async exists(path: string): Promise<\n    | {\n        data: boolean\n        error: null\n      }\n    | {\n        data: boolean\n        error: StorageError\n      }\n  > {\n    const _path = this._getFinalPath(path)\n\n    try {\n      await head(this.fetch, `${this.url}/object/${_path}`, {\n        headers: this.headers,\n      })\n\n      return { data: true, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error) && error instanceof StorageUnknownError) {\n        const originalError = error.originalError as unknown as { status: number }\n\n        if ([400, 404].includes(originalError?.status)) {\n          return { data: false, error }\n        }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * A simple convenience function to get the URL for an asset in a public bucket. If you do not want to use this function, you can construct the public URL by concatenating the bucket URL with the path to the asset.\n   * This function does not verify if the bucket is public. If a public URL is created for a bucket which is not public, you will not be able to download the asset.\n   *\n   * @category File Buckets\n   * @param path The path and name of the file to generate the public URL for. For example `folder/image.png`.\n   * @param options.download Triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n   * @param options.transform Transform the asset before serving it to the client.\n   * @returns Object with public URL\n   *\n   * @example Returns the URL for an asset in a public bucket\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"publicUrl\": \"https://example.supabase.co/storage/v1/object/public/public-bucket/folder/avatar1.png\"\n   *   }\n   * }\n   * ```\n   *\n   * @example Returns the URL for an asset in a public bucket with transformations\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png', {\n   *     transform: {\n   *       width: 100,\n   *       height: 100,\n   *     }\n   *   })\n   * ```\n   *\n   * @example Returns the URL which triggers the download of an asset in a public bucket\n   * ```js\n   * const { data } = supabase\n   *   .storage\n   *   .from('public-bucket')\n   *   .getPublicUrl('folder/avatar1.png', {\n   *     download: true,\n   *   })\n   * ```\n   */\n  getPublicUrl(\n    path: string,\n    options?: { download?: string | boolean; transform?: TransformOptions }\n  ): { data: { publicUrl: string } } {\n    const _path = this._getFinalPath(path)\n    const _queryString: string[] = []\n\n    const downloadQueryParam = options?.download\n      ? `download=${options.download === true ? '' : options.download}`\n      : ''\n\n    if (downloadQueryParam !== '') {\n      _queryString.push(downloadQueryParam)\n    }\n\n    const wantsTransformation = typeof options?.transform !== 'undefined'\n    const renderPath = wantsTransformation ? 'render/image' : 'object'\n    const transformationQuery = this.transformOptsToQueryString(options?.transform || {})\n\n    if (transformationQuery !== '') {\n      _queryString.push(transformationQuery)\n    }\n\n    let queryString = _queryString.join('&')\n    if (queryString !== '') {\n      queryString = `?${queryString}`\n    }\n\n    return {\n      data: { publicUrl: encodeURI(`${this.url}/${renderPath}/public/${_path}${queryString}`) },\n    }\n  }\n\n  /**\n   * Deletes files within the same bucket\n   *\n   * @category File Buckets\n   * @param paths An array of files to delete, including the path and file name. For example [`'folder/image.png'`].\n   * @returns Promise with response containing array of deleted file objects or error\n   *\n   * @example Delete file\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .remove(['folder/avatar1.png'])\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async remove(paths: string[]): Promise<\n    | {\n        data: FileObject[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await remove(\n        this.fetch,\n        `${this.url}/object/${this.bucketId}`,\n        { prefixes: paths },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Get file metadata\n   * @param id the file id to retrieve metadata\n   */\n  // async getMetadata(\n  //   id: string\n  // ): Promise<\n  //   | {\n  //       data: Metadata\n  //       error: null\n  //     }\n  //   | {\n  //       data: null\n  //       error: StorageError\n  //     }\n  // > {\n  //   try {\n  //     const data = await get(this.fetch, `${this.url}/metadata/${id}`, { headers: this.headers })\n  //     return { data, error: null }\n  //   } catch (error) {\n  //     if (isStorageError(error)) {\n  //       return { data: null, error }\n  //     }\n\n  //     throw error\n  //   }\n  // }\n\n  /**\n   * Update file metadata\n   * @param id the file id to update metadata\n   * @param meta the new file metadata\n   */\n  // async updateMetadata(\n  //   id: string,\n  //   meta: Metadata\n  // ): Promise<\n  //   | {\n  //       data: Metadata\n  //       error: null\n  //     }\n  //   | {\n  //       data: null\n  //       error: StorageError\n  //     }\n  // > {\n  //   try {\n  //     const data = await post(\n  //       this.fetch,\n  //       `${this.url}/metadata/${id}`,\n  //       { ...meta },\n  //       { headers: this.headers }\n  //     )\n  //     return { data, error: null }\n  //   } catch (error) {\n  //     if (isStorageError(error)) {\n  //       return { data: null, error }\n  //     }\n\n  //     throw error\n  //   }\n  // }\n\n  /**\n   * Lists all the files and folders within a path of the bucket.\n   *\n   * @category File Buckets\n   * @param path The folder path.\n   * @param options Search options including limit (defaults to 100), offset, sortBy, and search\n   * @param parameters Optional fetch parameters including signal for cancellation\n   * @returns Promise with response containing array of files or error\n   *\n   * @example List files in a bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .list('folder', {\n   *     limit: 100,\n   *     offset: 0,\n   *     sortBy: { column: 'name', order: 'asc' },\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"name\": \"avatar1.png\",\n   *       \"id\": \"e668cf7f-821b-4a2f-9dce-7dfa5dd1cfd2\",\n   *       \"updated_at\": \"2024-05-22T23:06:05.580Z\",\n   *       \"created_at\": \"2024-05-22T23:04:34.443Z\",\n   *       \"last_accessed_at\": \"2024-05-22T23:04:34.443Z\",\n   *       \"metadata\": {\n   *         \"eTag\": \"\\\"c5e8c553235d9af30ef4f6e280790b92\\\"\",\n   *         \"size\": 32175,\n   *         \"mimetype\": \"image/png\",\n   *         \"cacheControl\": \"max-age=3600\",\n   *         \"lastModified\": \"2024-05-22T23:06:05.574Z\",\n   *         \"contentLength\": 32175,\n   *         \"httpStatusCode\": 200\n   *       }\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   *\n   * @example Search files in a bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .from('avatars')\n   *   .list('folder', {\n   *     limit: 100,\n   *     offset: 0,\n   *     sortBy: { column: 'name', order: 'asc' },\n   *     search: 'jon'\n   *   })\n   * ```\n   */\n  async list(\n    path?: string,\n    options?: SearchOptions,\n    parameters?: FetchParameters\n  ): Promise<\n    | {\n        data: FileObject[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const body = { ...DEFAULT_SEARCH_OPTIONS, ...options, prefix: path || '' }\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/list/${this.bucketId}`,\n        body,\n        { headers: this.headers },\n        parameters\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @experimental this method signature might change in the future\n   *\n   * @category File Buckets\n   * @param options search options\n   * @param parameters\n   */\n  async listV2(\n    options?: SearchV2Options,\n    parameters?: FetchParameters\n  ): Promise<\n    | {\n        data: SearchV2Result\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const body = { ...options }\n      const data = await post(\n        this.fetch,\n        `${this.url}/object/list-v2/${this.bucketId}`,\n        body,\n        { headers: this.headers },\n        parameters\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  protected encodeMetadata(metadata: Record<string, any>) {\n    return JSON.stringify(metadata)\n  }\n\n  toBase64(data: string) {\n    if (typeof Buffer !== 'undefined') {\n      return Buffer.from(data).toString('base64')\n    }\n    return btoa(data)\n  }\n\n  private _getFinalPath(path: string) {\n    return `${this.bucketId}/${path.replace(/^\\/+/, '')}`\n  }\n\n  private _removeEmptyFolders(path: string) {\n    return path.replace(/^\\/|\\/$/g, '').replace(/\\/+/g, '/')\n  }\n\n  private transformOptsToQueryString(transform: TransformOptions) {\n    const params: string[] = []\n    if (transform.width) {\n      params.push(`width=${transform.width}`)\n    }\n\n    if (transform.height) {\n      params.push(`height=${transform.height}`)\n    }\n\n    if (transform.resize) {\n      params.push(`resize=${transform.resize}`)\n    }\n\n    if (transform.format) {\n      params.push(`format=${transform.format}`)\n    }\n\n    if (transform.quality) {\n      params.push(`quality=${transform.quality}`)\n    }\n\n    return params.join('&')\n  }\n}\n","import SupabaseClient from './SupabaseClient'\nimport type { SupabaseClientOptions } from './lib/types'\n\nexport * from '@supabase/auth-js'\nexport type { User as AuthUser, Session as AuthSession } from '@supabase/auth-js'\nexport type {\n  PostgrestResponse,\n  PostgrestSingleResponse,\n  PostgrestMaybeSingleResponse,\n} from '@supabase/postgrest-js'\nexport { PostgrestError } from '@supabase/postgrest-js'\nexport type { FunctionInvokeOptions } from '@supabase/functions-js'\nexport {\n  FunctionsHttpError,\n  FunctionsFetchError,\n  FunctionsRelayError,\n  FunctionsError,\n  FunctionRegion,\n} from '@supabase/functions-js'\nexport * from '@supabase/realtime-js'\nexport { default as SupabaseClient } from './SupabaseClient'\nexport type {\n  SupabaseClientOptions,\n  QueryResult,\n  QueryData,\n  QueryError,\n  DatabaseWithoutInternals,\n} from './lib/types'\n\n/**\n * Creates a new Supabase Client.\n *\n * @example\n * ```ts\n * import { createClient } from '@supabase/supabase-js'\n *\n * const supabase = createClient('https://xyzcompany.supabase.co', 'public-anon-key')\n * const { data, error } = await supabase.from('profiles').select('*')\n * ```\n */\nexport const createClient = <\n  Database = any,\n  SchemaNameOrClientOptions extends\n    | (string & keyof Omit<Database, '__InternalSupabase'>)\n    | { PostgrestVersion: string } = 'public' extends keyof Omit<Database, '__InternalSupabase'>\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = SchemaNameOrClientOptions extends string &\n    keyof Omit<Database, '__InternalSupabase'>\n    ? SchemaNameOrClientOptions\n    : 'public' extends keyof Omit<Database, '__InternalSupabase'>\n      ? 'public'\n      : string & keyof Omit<Omit<Database, '__InternalSupabase'>, '__InternalSupabase'>,\n>(\n  supabaseUrl: string,\n  supabaseKey: string,\n  options?: SupabaseClientOptions<SchemaName>\n): SupabaseClient<Database, SchemaNameOrClientOptions, SchemaName> => {\n  return new SupabaseClient<Database, SchemaNameOrClientOptions, SchemaName>(\n    supabaseUrl,\n    supabaseKey,\n    options\n  )\n}\n\n// Check for Node.js <= 18 deprecation\nfunction shouldShowDeprecationWarning(): boolean {\n  // Skip in browser environments\n  if (typeof window !== 'undefined') {\n    return false\n  }\n\n  // Skip if process is not available (e.g., Edge Runtime)\n  // Use dynamic property access to avoid Next.js Edge Runtime static analysis warnings\n  const _process = (globalThis as any)['process']\n  if (!_process) {\n    return false\n  }\n\n  const processVersion = _process['version']\n  if (processVersion === undefined || processVersion === null) {\n    return false\n  }\n\n  const versionMatch = processVersion.match(/^v(\\d+)\\./)\n  if (!versionMatch) {\n    return false\n  }\n\n  const majorVersion = parseInt(versionMatch[1], 10)\n  return majorVersion <= 18\n}\n\nif (shouldShowDeprecationWarning()) {\n  console.warn(\n    `âš ï¸  Node.js 18 and below are deprecated and will no longer be supported in future versions of @supabase/supabase-js. ` +\n      `Please upgrade to Node.js 20 or later. ` +\n      `For more information, visit: https://github.com/orgs/supabase/discussions/37217`\n  )\n}\n","import PostgrestTransformBuilder from './PostgrestTransformBuilder'\nimport { JsonPathToAccessor, JsonPathToType } from './select-query-parser/utils'\nimport { ClientServerOptions, GenericSchema } from './types/common/common'\n\ntype FilterOperator =\n  | 'eq'\n  | 'neq'\n  | 'gt'\n  | 'gte'\n  | 'lt'\n  | 'lte'\n  | 'like'\n  | 'ilike'\n  | 'is'\n  | 'isdistinct'\n  | 'in'\n  | 'cs'\n  | 'cd'\n  | 'sl'\n  | 'sr'\n  | 'nxl'\n  | 'nxr'\n  | 'adj'\n  | 'ov'\n  | 'fts'\n  | 'plfts'\n  | 'phfts'\n  | 'wfts'\n  | 'match'\n  | 'imatch'\n\nexport type IsStringOperator<Path extends string> = Path extends `${string}->>${string}`\n  ? true\n  : false\n\nconst PostgrestReservedCharsRegexp = new RegExp('[,()]')\n\n// Match relationship filters with `table.column` syntax and resolve underlying\n// column value. If not matched, fallback to generic type.\n// TODO: Validate the relationship itself ala select-query-parser. Currently we\n// assume that all tables have valid relationships to each other, despite\n// nonexistent foreign keys.\ntype ResolveFilterValue<\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  ColumnName extends string,\n> = ColumnName extends `${infer RelationshipTable}.${infer Remainder}`\n  ? Remainder extends `${infer _}.${infer _}`\n    ? ResolveFilterValue<Schema, Row, Remainder>\n    : ResolveFilterRelationshipValue<Schema, RelationshipTable, Remainder>\n  : ColumnName extends keyof Row\n    ? Row[ColumnName]\n    : // If the column selection is a jsonpath like `data->value` or `data->>value` we attempt to match\n      // the expected type with the parsed custom json type\n      IsStringOperator<ColumnName> extends true\n      ? string\n      : JsonPathToType<Row, JsonPathToAccessor<ColumnName>> extends infer JsonPathValue\n        ? JsonPathValue extends never\n          ? never\n          : JsonPathValue\n        : never\n\ntype ResolveFilterRelationshipValue<\n  Schema extends GenericSchema,\n  RelationshipTable extends string,\n  RelationshipColumn extends string,\n> = Schema['Tables'] & Schema['Views'] extends infer TablesAndViews\n  ? RelationshipTable extends keyof TablesAndViews\n    ? 'Row' extends keyof TablesAndViews[RelationshipTable]\n      ? RelationshipColumn extends keyof TablesAndViews[RelationshipTable]['Row']\n        ? TablesAndViews[RelationshipTable]['Row'][RelationshipColumn]\n        : unknown\n      : unknown\n    : unknown\n  : never\n\nexport type InvalidMethodError<S extends string> = { Error: S }\n\nexport default class PostgrestFilterBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Row extends Record<string, unknown>,\n  Result,\n  RelationName = unknown,\n  Relationships = unknown,\n  Method = unknown,\n> extends PostgrestTransformBuilder<\n  ClientOptions,\n  Schema,\n  Row,\n  Result,\n  RelationName,\n  Relationships,\n  Method\n> {\n  /**\n   * Match only rows where `column` is equal to `value`.\n   *\n   * To check if the value of `column` is NULL, you should use `.is()` instead.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  eq<ColumnName extends string>(\n    column: ColumnName,\n    value: ResolveFilterValue<Schema, Row, ColumnName> extends never\n      ? NonNullable<unknown>\n      : // We want to infer the type before wrapping it into a `NonNullable` to avoid too deep\n        // type resolution error\n        ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n        ? NonNullable<ResolvedFilterValue>\n        : // We should never enter this case as all the branches are covered above\n          never\n  ): this {\n    this.url.searchParams.append(column, `eq.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` is not equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  neq<ColumnName extends string>(\n    column: ColumnName,\n    value: ResolveFilterValue<Schema, Row, ColumnName> extends never\n      ? unknown\n      : ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n        ? ResolvedFilterValue\n        : never\n  ): this {\n    this.url.searchParams.append(column, `neq.${value}`)\n    return this\n  }\n\n  gt<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  gt(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is greater than `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  gt(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `gt.${value}`)\n    return this\n  }\n\n  gte<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  gte(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is greater than or equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  gte(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `gte.${value}`)\n    return this\n  }\n\n  lt<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  lt(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is less than `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  lt(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `lt.${value}`)\n    return this\n  }\n\n  lte<ColumnName extends string & keyof Row>(column: ColumnName, value: Row[ColumnName]): this\n  lte(column: string, value: unknown): this\n  /**\n   * Match only rows where `column` is less than or equal to `value`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  lte(column: string, value: unknown): this {\n    this.url.searchParams.append(column, `lte.${value}`)\n    return this\n  }\n\n  like<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  like(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches `pattern` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param pattern - The pattern to match with\n   */\n  like(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `like.${pattern}`)\n    return this\n  }\n\n  likeAllOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  likeAllOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches all of `patterns` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  likeAllOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `like(all).{${patterns.join(',')}}`)\n    return this\n  }\n\n  likeAnyOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  likeAnyOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches any of `patterns` case-sensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  likeAnyOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `like(any).{${patterns.join(',')}}`)\n    return this\n  }\n\n  ilike<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  ilike(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches `pattern` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param pattern - The pattern to match with\n   */\n  ilike(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `ilike.${pattern}`)\n    return this\n  }\n\n  ilikeAllOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  ilikeAllOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches all of `patterns` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  ilikeAllOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `ilike(all).{${patterns.join(',')}}`)\n    return this\n  }\n\n  ilikeAnyOf<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    patterns: readonly string[]\n  ): this\n  ilikeAnyOf(column: string, patterns: readonly string[]): this\n  /**\n   * Match only rows where `column` matches any of `patterns` case-insensitively.\n   *\n   * @param column - The column to filter on\n   * @param patterns - The patterns to match with\n   */\n  ilikeAnyOf(column: string, patterns: readonly string[]): this {\n    this.url.searchParams.append(column, `ilike(any).{${patterns.join(',')}}`)\n    return this\n  }\n\n  regexMatch<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  regexMatch(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches the PostgreSQL regex `pattern`\n   * case-sensitively (using the `~` operator).\n   *\n   * @param column - The column to filter on\n   * @param pattern - The PostgreSQL regular expression pattern to match with\n   */\n  regexMatch(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `match.${pattern}`)\n    return this\n  }\n\n  regexIMatch<ColumnName extends string & keyof Row>(column: ColumnName, pattern: string): this\n  regexIMatch(column: string, pattern: string): this\n  /**\n   * Match only rows where `column` matches the PostgreSQL regex `pattern`\n   * case-insensitively (using the `~*` operator).\n   *\n   * @param column - The column to filter on\n   * @param pattern - The PostgreSQL regular expression pattern to match with\n   */\n  regexIMatch(column: string, pattern: string): this {\n    this.url.searchParams.append(column, `imatch.${pattern}`)\n    return this\n  }\n\n  is<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: Row[ColumnName] & (boolean | null)\n  ): this\n  is(column: string, value: boolean | null): this\n  /**\n   * Match only rows where `column` IS `value`.\n   *\n   * For non-boolean columns, this is only relevant for checking if the value of\n   * `column` is NULL by setting `value` to `null`.\n   *\n   * For boolean columns, you can also set `value` to `true` or `false` and it\n   * will behave the same way as `.eq()`.\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  is(column: string, value: boolean | null): this {\n    this.url.searchParams.append(column, `is.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` IS DISTINCT FROM `value`.\n   *\n   * Unlike `.neq()`, this treats `NULL` as a comparable value. Two `NULL` values\n   * are considered equal (not distinct), and comparing `NULL` with any non-NULL\n   * value returns true (distinct).\n   *\n   * @param column - The column to filter on\n   * @param value - The value to filter with\n   */\n  isDistinct<ColumnName extends string>(\n    column: ColumnName,\n    value: ResolveFilterValue<Schema, Row, ColumnName> extends never\n      ? unknown\n      : ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n        ? ResolvedFilterValue\n        : never\n  ): this {\n    this.url.searchParams.append(column, `isdistinct.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` is included in the `values` array.\n   *\n   * @param column - The column to filter on\n   * @param values - The values array to filter with\n   */\n  in<ColumnName extends string>(\n    column: ColumnName,\n    values: ReadonlyArray<\n      ResolveFilterValue<Schema, Row, ColumnName> extends never\n        ? unknown\n        : // We want to infer the type before wrapping it into a `NonNullable` to avoid too deep\n          // type resolution error\n          ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n          ? ResolvedFilterValue\n          : // We should never enter this case as all the branches are covered above\n            never\n    >\n  ): this {\n    const cleanedValues = Array.from(new Set(values))\n      .map((s) => {\n        // handle postgrest reserved characters\n        // https://postgrest.org/en/v7.0.0/api.html#reserved-characters\n        if (typeof s === 'string' && PostgrestReservedCharsRegexp.test(s)) return `\"${s}\"`\n        else return `${s}`\n      })\n      .join(',')\n    this.url.searchParams.append(column, `in.(${cleanedValues})`)\n    return this\n  }\n\n  /**\n   * Match only rows where `column` is NOT included in the `values` array.\n   *\n   * @param column - The column to filter on\n   * @param values - The values array to filter with\n   */\n  notIn<ColumnName extends string>(\n    column: ColumnName,\n    values: ReadonlyArray<\n      ResolveFilterValue<Schema, Row, ColumnName> extends never\n        ? unknown\n        : ResolveFilterValue<Schema, Row, ColumnName> extends infer ResolvedFilterValue\n          ? ResolvedFilterValue\n          : never\n    >\n  ): this {\n    const cleanedValues = Array.from(new Set(values))\n      .map((s) => {\n        // handle postgrest reserved characters\n        // https://postgrest.org/en/v7.0.0/api.html#reserved-characters\n        if (typeof s === 'string' && PostgrestReservedCharsRegexp.test(s)) return `\"${s}\"`\n        else return `${s}`\n      })\n      .join(',')\n    this.url.searchParams.append(column, `not.in.(${cleanedValues})`)\n    return this\n  }\n\n  contains<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]> | Record<string, unknown>\n  ): this\n  contains(column: string, value: string | readonly unknown[] | Record<string, unknown>): this\n  /**\n   * Only relevant for jsonb, array, and range columns. Match only rows where\n   * `column` contains every element appearing in `value`.\n   *\n   * @param column - The jsonb, array, or range column to filter on\n   * @param value - The jsonb, array, or range value to filter with\n   */\n  contains(column: string, value: string | readonly unknown[] | Record<string, unknown>): this {\n    if (typeof value === 'string') {\n      // range types can be inclusive '[', ']' or exclusive '(', ')' so just\n      // keep it simple and accept a string\n      this.url.searchParams.append(column, `cs.${value}`)\n    } else if (Array.isArray(value)) {\n      // array\n      this.url.searchParams.append(column, `cs.{${value.join(',')}}`)\n    } else {\n      // json\n      this.url.searchParams.append(column, `cs.${JSON.stringify(value)}`)\n    }\n    return this\n  }\n\n  containedBy<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]> | Record<string, unknown>\n  ): this\n  containedBy(column: string, value: string | readonly unknown[] | Record<string, unknown>): this\n  /**\n   * Only relevant for jsonb, array, and range columns. Match only rows where\n   * every element appearing in `column` is contained by `value`.\n   *\n   * @param column - The jsonb, array, or range column to filter on\n   * @param value - The jsonb, array, or range value to filter with\n   */\n  containedBy(column: string, value: string | readonly unknown[] | Record<string, unknown>): this {\n    if (typeof value === 'string') {\n      // range\n      this.url.searchParams.append(column, `cd.${value}`)\n    } else if (Array.isArray(value)) {\n      // array\n      this.url.searchParams.append(column, `cd.{${value.join(',')}}`)\n    } else {\n      // json\n      this.url.searchParams.append(column, `cd.${JSON.stringify(value)}`)\n    }\n    return this\n  }\n\n  rangeGt<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeGt(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is greater than any element in `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeGt(column: string, range: string): this {\n    this.url.searchParams.append(column, `sr.${range}`)\n    return this\n  }\n\n  rangeGte<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeGte(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is either contained in `range` or greater than any element in\n   * `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeGte(column: string, range: string): this {\n    this.url.searchParams.append(column, `nxl.${range}`)\n    return this\n  }\n\n  rangeLt<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeLt(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is less than any element in `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeLt(column: string, range: string): this {\n    this.url.searchParams.append(column, `sl.${range}`)\n    return this\n  }\n\n  rangeLte<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeLte(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where every element in\n   * `column` is either contained in `range` or less than any element in\n   * `range`.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeLte(column: string, range: string): this {\n    this.url.searchParams.append(column, `nxr.${range}`)\n    return this\n  }\n\n  rangeAdjacent<ColumnName extends string & keyof Row>(column: ColumnName, range: string): this\n  rangeAdjacent(column: string, range: string): this\n  /**\n   * Only relevant for range columns. Match only rows where `column` is\n   * mutually exclusive to `range` and there can be no element between the two\n   * ranges.\n   *\n   * @param column - The range column to filter on\n   * @param range - The range to filter with\n   */\n  rangeAdjacent(column: string, range: string): this {\n    this.url.searchParams.append(column, `adj.${range}`)\n    return this\n  }\n\n  overlaps<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    value: string | ReadonlyArray<Row[ColumnName]>\n  ): this\n  overlaps(column: string, value: string | readonly unknown[]): this\n  /**\n   * Only relevant for array and range columns. Match only rows where\n   * `column` and `value` have an element in common.\n   *\n   * @param column - The array or range column to filter on\n   * @param value - The array or range value to filter with\n   */\n  overlaps(column: string, value: string | readonly unknown[]): this {\n    if (typeof value === 'string') {\n      // range\n      this.url.searchParams.append(column, `ov.${value}`)\n    } else {\n      // array\n      this.url.searchParams.append(column, `ov.{${value.join(',')}}`)\n    }\n    return this\n  }\n\n  textSearch<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    query: string,\n    options?: { config?: string; type?: 'plain' | 'phrase' | 'websearch' }\n  ): this\n  textSearch(\n    column: string,\n    query: string,\n    options?: { config?: string; type?: 'plain' | 'phrase' | 'websearch' }\n  ): this\n  /**\n   * Only relevant for text and tsvector columns. Match only rows where\n   * `column` matches the query string in `query`.\n   *\n   * @param column - The text or tsvector column to filter on\n   * @param query - The query text to match with\n   * @param options - Named parameters\n   * @param options.config - The text search configuration to use\n   * @param options.type - Change how the `query` text is interpreted\n   */\n  textSearch(\n    column: string,\n    query: string,\n    { config, type }: { config?: string; type?: 'plain' | 'phrase' | 'websearch' } = {}\n  ): this {\n    let typePart = ''\n    if (type === 'plain') {\n      typePart = 'pl'\n    } else if (type === 'phrase') {\n      typePart = 'ph'\n    } else if (type === 'websearch') {\n      typePart = 'w'\n    }\n    const configPart = config === undefined ? '' : `(${config})`\n    this.url.searchParams.append(column, `${typePart}fts${configPart}.${query}`)\n    return this\n  }\n\n  match<ColumnName extends string & keyof Row>(query: Record<ColumnName, Row[ColumnName]>): this\n  match(query: Record<string, unknown>): this\n  /**\n   * Match only rows where each column in `query` keys is equal to its\n   * associated value. Shorthand for multiple `.eq()`s.\n   *\n   * @param query - The object to filter with, with column names as keys mapped\n   * to their filter values\n   */\n  match(query: Record<string, unknown>): this {\n    Object.entries(query).forEach(([column, value]) => {\n      this.url.searchParams.append(column, `eq.${value}`)\n    })\n    return this\n  }\n\n  not<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    operator: FilterOperator,\n    value: Row[ColumnName]\n  ): this\n  not(column: string, operator: string, value: unknown): this\n  /**\n   * Match only rows which doesn't satisfy the filter.\n   *\n   * Unlike most filters, `opearator` and `value` are used as-is and need to\n   * follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure they are properly sanitized.\n   *\n   * @param column - The column to filter on\n   * @param operator - The operator to be negated to filter with, following\n   * PostgREST syntax\n   * @param value - The value to filter with, following PostgREST syntax\n   */\n  not(column: string, operator: string, value: unknown): this {\n    this.url.searchParams.append(column, `not.${operator}.${value}`)\n    return this\n  }\n\n  /**\n   * Match only rows which satisfy at least one of the filters.\n   *\n   * Unlike most filters, `filters` is used as-is and needs to follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure it's properly sanitized.\n   *\n   * It's currently not possible to do an `.or()` filter across multiple tables.\n   *\n   * @param filters - The filters to use, following PostgREST syntax\n   * @param options - Named parameters\n   * @param options.referencedTable - Set this to filter on referenced tables\n   * instead of the parent table\n   * @param options.foreignTable - Deprecated, use `referencedTable` instead\n   */\n  or(\n    filters: string,\n    {\n      foreignTable,\n      referencedTable = foreignTable,\n    }: { foreignTable?: string; referencedTable?: string } = {}\n  ): this {\n    const key = referencedTable ? `${referencedTable}.or` : 'or'\n    this.url.searchParams.append(key, `(${filters})`)\n    return this\n  }\n\n  filter<ColumnName extends string & keyof Row>(\n    column: ColumnName,\n    operator: `${'' | 'not.'}${FilterOperator}`,\n    value: unknown\n  ): this\n  filter(column: string, operator: string, value: unknown): this\n  /**\n   * Match only rows which satisfy the filter. This is an escape hatch - you\n   * should use the specific filter methods wherever possible.\n   *\n   * Unlike most filters, `opearator` and `value` are used as-is and need to\n   * follow [PostgREST\n   * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n   * to make sure they are properly sanitized.\n   *\n   * @param column - The column to filter on\n   * @param operator - The operator to filter with, following PostgREST syntax\n   * @param value - The value to filter with, following PostgREST syntax\n   */\n  filter(column: string, operator: string, value: unknown): this {\n    this.url.searchParams.append(column, `${operator}.${value}`)\n    return this\n  }\n}\n","export interface NamespaceIdentifier {\n  namespace: string[]\n}\n\nexport interface NamespaceMetadata {\n  properties: Record<string, string>\n}\n\nexport interface TableIdentifier {\n  namespace: string[]\n  name: string\n}\n\n/**\n * Primitive types in Iceberg - all represented as strings.\n * Parameterized types use string format: decimal(precision,scale) and fixed[length]\n *\n * Note: The OpenAPI spec defines PrimitiveType as `type: string`, so any string is valid.\n * We include known types for autocomplete, plus a catch-all for flexibility.\n */\nexport type PrimitiveType =\n  | 'boolean'\n  | 'int'\n  | 'long'\n  | 'float'\n  | 'double'\n  | 'string'\n  | 'timestamp'\n  | 'date'\n  | 'time'\n  | 'timestamptz'\n  | 'uuid'\n  | 'binary'\n  | `decimal(${number},${number})`\n  | `fixed[${number}]`\n  | (string & {}) // catch-all for any format (e.g., \"decimal(10, 2)\" with spaces) and future types\n\n/**\n * Regex patterns for parsing parameterized types.\n * These allow flexible whitespace matching.\n */\nconst DECIMAL_REGEX = /^decimal\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)$/\nconst FIXED_REGEX = /^fixed\\s*\\[\\s*(\\d+)\\s*\\]$/\n\n/**\n * Parse a decimal type string into its components.\n * Handles any whitespace formatting (e.g., \"decimal(10,2)\", \"decimal(10, 2)\", \"decimal( 10 , 2 )\").\n *\n * @param type - The type string to parse\n * @returns Object with precision and scale, or null if not a valid decimal type\n */\nexport function parseDecimalType(type: string): { precision: number; scale: number } | null {\n  const match = type.match(DECIMAL_REGEX)\n  if (!match) return null\n  return {\n    precision: parseInt(match[1], 10),\n    scale: parseInt(match[2], 10),\n  }\n}\n\n/**\n * Parse a fixed type string into its length.\n * Handles any whitespace formatting (e.g., \"fixed[16]\", \"fixed[ 16 ]\").\n *\n * @param type - The type string to parse\n * @returns Object with length, or null if not a valid fixed type\n */\nexport function parseFixedType(type: string): { length: number } | null {\n  const match = type.match(FIXED_REGEX)\n  if (!match) return null\n  return {\n    length: parseInt(match[1], 10),\n  }\n}\n\n/**\n * Check if a type string is a decimal type.\n */\nexport function isDecimalType(type: string): boolean {\n  return DECIMAL_REGEX.test(type)\n}\n\n/**\n * Check if a type string is a fixed type.\n */\nexport function isFixedType(type: string): boolean {\n  return FIXED_REGEX.test(type)\n}\n\n/**\n * Compare two Iceberg type strings for equality, ignoring whitespace differences.\n * This is useful when comparing types from user input vs catalog responses,\n * as catalogs may normalize whitespace differently.\n *\n * @param a - First type string\n * @param b - Second type string\n * @returns true if the types are equivalent\n */\nexport function typesEqual(a: string, b: string): boolean {\n  // For decimal types, compare parsed values\n  const decimalA = parseDecimalType(a)\n  const decimalB = parseDecimalType(b)\n  if (decimalA && decimalB) {\n    return decimalA.precision === decimalB.precision && decimalA.scale === decimalB.scale\n  }\n\n  // For fixed types, compare parsed values\n  const fixedA = parseFixedType(a)\n  const fixedB = parseFixedType(b)\n  if (fixedA && fixedB) {\n    return fixedA.length === fixedB.length\n  }\n\n  // For other types, direct string comparison\n  return a === b\n}\n\n/**\n * Struct type - a nested structure containing fields.\n * Used for nested records within a field.\n */\nexport interface StructType {\n  type: 'struct'\n  fields: StructField[]\n}\n\n/**\n * List type - an array of elements.\n */\nexport interface ListType {\n  type: 'list'\n  'element-id': number\n  element: IcebergType\n  'element-required': boolean\n}\n\n/**\n * Map type - a key-value mapping.\n */\nexport interface MapType {\n  type: 'map'\n  'key-id': number\n  key: IcebergType\n  'value-id': number\n  value: IcebergType\n  'value-required': boolean\n}\n\n/**\n * Union of all Iceberg types.\n * Can be a primitive type (string) or a complex type (struct, list, map).\n */\nexport type IcebergType = PrimitiveType | StructType | ListType | MapType\n\n/**\n * Primitive type values for default values.\n * Represents the possible values for initial-default and write-default.\n */\nexport type PrimitiveTypeValue = boolean | number | string\n\n/**\n * A field within a struct (used in nested StructType).\n */\nexport interface StructField {\n  id: number\n  name: string\n  type: IcebergType\n  required: boolean\n  doc?: string\n  'initial-default'?: PrimitiveTypeValue\n  'write-default'?: PrimitiveTypeValue\n}\n\n/**\n * A field within a table schema (top-level).\n * Equivalent to StructField but kept for backwards compatibility.\n */\nexport interface TableField {\n  id: number\n  name: string\n  type: IcebergType\n  required: boolean\n  doc?: string\n  'initial-default'?: PrimitiveTypeValue\n  'write-default'?: PrimitiveTypeValue\n}\n\nexport interface TableSchema {\n  type: 'struct'\n  fields: TableField[]\n  'schema-id'?: number\n  'identifier-field-ids'?: number[]\n}\n\nexport interface PartitionField {\n  source_id: number\n  field_id: number\n  name: string\n  transform: string\n}\n\nexport interface PartitionSpec {\n  'spec-id': number\n  fields: PartitionField[]\n}\n\nexport interface SortField {\n  source_id: number\n  transform: string\n  direction: 'asc' | 'desc'\n  null_order: 'nulls-first' | 'nulls-last'\n}\n\nexport interface SortOrder {\n  'order-id': number\n  fields: SortField[]\n}\n\nexport interface CreateTableRequest {\n  name: string\n  schema: TableSchema\n  'partition-spec'?: PartitionSpec\n  'write-order'?: SortOrder\n  properties?: Record<string, string>\n  'stage-create'?: boolean\n}\n\nexport interface UpdateTableRequest {\n  schema?: TableSchema\n  'partition-spec'?: PartitionSpec\n  properties?: Record<string, string>\n}\n\nexport interface DropTableRequest {\n  purge?: boolean\n}\n\nexport interface TableMetadata {\n  name?: string\n  location: string\n  schemas: TableSchema[]\n  'current-schema-id': number\n  'partition-specs': PartitionSpec[]\n  'default-spec-id'?: number\n  'sort-orders': SortOrder[]\n  'default-sort-order-id'?: number\n  properties: Record<string, string>\n  'metadata-location'?: string\n  'current-snapshot-id'?: number\n  snapshots?: unknown[]\n  'snapshot-log'?: unknown[]\n  'metadata-log'?: unknown[]\n  refs?: Record<string, unknown>\n  'last-updated-ms'?: number\n  'last-column-id'?: number\n  'last-sequence-number'?: number\n  'table-uuid'?: string\n  'format-version'?: number\n  'last-partition-id'?: number\n}\n\nexport interface CreateNamespaceRequest {\n  namespace: string[]\n  properties?: Record<string, string>\n}\n\nexport interface CreateNamespaceResponse {\n  namespace: string[]\n  properties?: Record<string, string>\n}\n\nexport interface GetNamespaceResponse {\n  namespace: string[]\n  properties: Record<string, string>\n}\n\nexport interface ListNamespacesResponse {\n  namespaces: string[][]\n  'next-page-token'?: string\n}\n\nexport interface ListTablesResponse {\n  identifiers: TableIdentifier[]\n  'next-page-token'?: string\n}\n\nexport interface LoadTableResponse {\n  'metadata-location': string\n  metadata: TableMetadata\n  config?: Record<string, string>\n}\n\nexport interface CommitTableResponse {\n  'metadata-location': string\n  metadata: TableMetadata\n}\n\n/**\n * Gets the current (active) schema from table metadata.\n *\n * @param metadata - Table metadata containing schemas array and current-schema-id\n * @returns The current table schema, or undefined if not found\n */\nexport function getCurrentSchema(metadata: TableMetadata): TableSchema | undefined {\n  return metadata.schemas.find((s) => s['schema-id'] === metadata['current-schema-id'])\n}\n","import PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport { GetResult } from './select-query-parser/result'\nimport {\n  ClientServerOptions,\n  Fetch,\n  GenericSchema,\n  GenericTable,\n  GenericView,\n} from './types/common/common'\n\nexport default class PostgrestQueryBuilder<\n  ClientOptions extends ClientServerOptions,\n  Schema extends GenericSchema,\n  Relation extends GenericTable | GenericView,\n  RelationName = unknown,\n  Relationships = Relation extends { Relationships: infer R } ? R : unknown,\n> {\n  url: URL\n  headers: Headers\n  schema?: string\n  signal?: AbortSignal\n  fetch?: Fetch\n\n  /**\n   * Creates a query builder scoped to a Postgres table or view.\n   *\n   * @example\n   * ```ts\n   * import PostgrestQueryBuilder from '@supabase/postgrest-js'\n   *\n   * const query = new PostgrestQueryBuilder(\n   *   new URL('https://xyzcompany.supabase.co/rest/v1/users'),\n   *   { headers: { apikey: 'public-anon-key' } }\n   * )\n   * ```\n   */\n  constructor(\n    url: URL,\n    {\n      headers = {},\n      schema,\n      fetch,\n    }: {\n      headers?: HeadersInit\n      schema?: string\n      fetch?: Fetch\n    }\n  ) {\n    this.url = url\n    this.headers = new Headers(headers)\n    this.schema = schema\n    this.fetch = fetch\n  }\n\n  /**\n   * Clone URL and headers to prevent shared state between operations.\n   */\n  private cloneRequestState(): { url: URL; headers: Headers } {\n    return {\n      url: new URL(this.url.toString()),\n      headers: new Headers(this.headers),\n    }\n  }\n\n  /**\n   * Perform a SELECT query on the table or view.\n   *\n   * @param columns - The columns to retrieve, separated by commas. Columns can be renamed when returned with `customName:columnName`\n   *\n   * @param options - Named parameters\n   *\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   *\n   * @param options.count - Count algorithm to use to count rows in the table or view.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  select<\n    Query extends string = '*',\n    ResultOne = GetResult<\n      Schema,\n      Relation['Row'],\n      RelationName,\n      Relationships,\n      Query,\n      ClientOptions\n    >,\n  >(\n    columns?: Query,\n    options?: {\n      head?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    ResultOne[],\n    RelationName,\n    Relationships,\n    'GET'\n  > {\n    const { head = false, count } = options ?? {}\n\n    const method = head ? 'HEAD' : 'GET'\n    // Remove whitespaces except when quoted\n    let quoted = false\n    const cleanedColumns = (columns ?? '*')\n      .split('')\n      .map((c) => {\n        if (/\\s/.test(c) && !quoted) {\n          return ''\n        }\n        if (c === '\"') {\n          quoted = !quoted\n        }\n        return c\n      })\n      .join('')\n\n    const { url, headers } = this.cloneRequestState()\n    url.searchParams.set('select', cleanedColumns)\n\n    if (count) {\n      headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schema,\n      fetch: this.fetch,\n    })\n  }\n\n  // TODO(v3): Make `defaultToNull` consistent for both single & bulk inserts.\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row,\n    options?: {\n      count?: 'exact' | 'planned' | 'estimated'\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row[],\n    options?: {\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  /**\n   * Perform an INSERT into the table or view.\n   *\n   * By default, inserted rows are not returned. To return it, chain the call\n   * with `.select()`.\n   *\n   * @param values - The values to insert. Pass an object to insert a single row\n   * or an array to insert multiple rows.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count inserted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @param options.defaultToNull - Make missing fields default to `null`.\n   * Otherwise, use the default value for the column. Only applies for bulk\n   * inserts.\n   */\n  insert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row | Row[],\n    {\n      count,\n      defaultToNull = true,\n    }: {\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  > {\n    const method = 'POST'\n    const { url, headers } = this.cloneRequestState()\n\n    if (count) {\n      headers.append('Prefer', `count=${count}`)\n    }\n    if (!defaultToNull) {\n      headers.append('Prefer', `missing=default`)\n    }\n\n    if (Array.isArray(values)) {\n      const columns = values.reduce((acc, x) => acc.concat(Object.keys(x)), [] as string[])\n      if (columns.length > 0) {\n        const uniqueColumns = [...new Set(columns)].map((column) => `\"${column}\"`)\n        url.searchParams.set('columns', uniqueColumns.join(','))\n      }\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n\n  // TODO(v3): Make `defaultToNull` consistent for both single & bulk upserts.\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row,\n    options?: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row[],\n    options?: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    }\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  >\n  /**\n   * Perform an UPSERT on the table or view. Depending on the column(s) passed\n   * to `onConflict`, `.upsert()` allows you to perform the equivalent of\n   * `.insert()` if a row with the corresponding `onConflict` columns doesn't\n   * exist, or if it does exist, perform an alternative action depending on\n   * `ignoreDuplicates`.\n   *\n   * By default, upserted rows are not returned. To return it, chain the call\n   * with `.select()`.\n   *\n   * @param values - The values to upsert with. Pass an object to upsert a\n   * single row or an array to upsert multiple rows.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.onConflict - Comma-separated UNIQUE column(s) to specify how\n   * duplicate rows are determined. Two rows are duplicates if all the\n   * `onConflict` columns are equal.\n   *\n   * @param options.ignoreDuplicates - If `true`, duplicate rows are ignored. If\n   * `false`, duplicate rows are merged with existing rows.\n   *\n   * @param options.count - Count algorithm to use to count upserted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @param options.defaultToNull - Make missing fields default to `null`.\n   * Otherwise, use the default value for the column. This only applies when\n   * inserting new rows, not when merging with existing rows under\n   * `ignoreDuplicates: false`. This also only applies when doing bulk upserts.\n   *\n   * @example Upsert a single row using a unique key\n   * ```ts\n   * // Upserting a single row, overwriting based on the 'username' unique column\n   * const { data, error } = await supabase\n   *   .from('users')\n   *   .upsert({ username: 'supabot' }, { onConflict: 'username' })\n   *\n   * // Example response:\n   * // {\n   * //   data: [\n   * //     { id: 4, message: 'bar', username: 'supabot' }\n   * //   ],\n   * //   error: null\n   * // }\n   * ```\n   *\n   * @example Upsert with conflict resolution and exact row counting\n   * ```ts\n   * // Upserting and returning exact count\n   * const { data, error, count } = await supabase\n   *   .from('users')\n   *   .upsert(\n   *     {\n   *       id: 3,\n   *       message: 'foo',\n   *       username: 'supabot'\n   *     },\n   *     {\n   *       onConflict: 'username',\n   *       count: 'exact'\n   *     }\n   *   )\n   *\n   * // Example response:\n   * // {\n   * //   data: [\n   * //     {\n   * //       id: 42,\n   * //       handle: \"saoirse\",\n   * //       display_name: \"Saoirse\"\n   * //     }\n   * //   ],\n   * //   count: 1,\n   * //   error: null\n   * // }\n   * ```\n   */\n\n  upsert<Row extends Relation extends { Insert: unknown } ? Relation['Insert'] : never>(\n    values: Row | Row[],\n    {\n      onConflict,\n      ignoreDuplicates = false,\n      count,\n      defaultToNull = true,\n    }: {\n      onConflict?: string\n      ignoreDuplicates?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n      defaultToNull?: boolean\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'POST'\n  > {\n    const method = 'POST'\n    const { url, headers } = this.cloneRequestState()\n\n    headers.append('Prefer', `resolution=${ignoreDuplicates ? 'ignore' : 'merge'}-duplicates`)\n\n    if (onConflict !== undefined) url.searchParams.set('on_conflict', onConflict)\n    if (count) {\n      headers.append('Prefer', `count=${count}`)\n    }\n    if (!defaultToNull) {\n      headers.append('Prefer', 'missing=default')\n    }\n\n    if (Array.isArray(values)) {\n      const columns = values.reduce((acc, x) => acc.concat(Object.keys(x)), [] as string[])\n      if (columns.length > 0) {\n        const uniqueColumns = [...new Set(columns)].map((column) => `\"${column}\"`)\n        url.searchParams.set('columns', uniqueColumns.join(','))\n      }\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n\n  /**\n   * Perform an UPDATE on the table or view.\n   *\n   * By default, updated rows are not returned. To return it, chain the call\n   * with `.select()` after filters.\n   *\n   * @param values - The values to update with\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count updated rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  update<Row extends Relation extends { Update: unknown } ? Relation['Update'] : never>(\n    values: Row,\n    {\n      count,\n    }: {\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'PATCH'\n  > {\n    const method = 'PATCH'\n    const { url, headers } = this.cloneRequestState()\n\n    if (count) {\n      headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schema,\n      body: values,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n\n  /**\n   * Perform a DELETE on the table or view.\n   *\n   * By default, deleted rows are not returned. To return it, chain the call\n   * with `.select()` after filters.\n   *\n   * @param options - Named parameters\n   *\n   * @param options.count - Count algorithm to use to count deleted rows.\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   */\n  delete({\n    count,\n  }: {\n    count?: 'exact' | 'planned' | 'estimated'\n  } = {}): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    Relation['Row'],\n    null,\n    RelationName,\n    Relationships,\n    'DELETE'\n  > {\n    const method = 'DELETE'\n    const { url, headers } = this.cloneRequestState()\n\n    if (count) {\n      headers.append('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schema,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n}\n","import PostgrestQueryBuilder from './PostgrestQueryBuilder'\nimport PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport { Fetch, GenericSchema, ClientServerOptions } from './types/common/common'\nimport { GetRpcFunctionFilterBuilderByArgs } from './types/common/rpc'\n\n/**\n * PostgREST client.\n *\n * @typeParam Database - Types for the schema from the [type\n * generator](https://supabase.com/docs/reference/javascript/next/typescript-support)\n *\n * @typeParam SchemaName - Postgres schema to switch to. Must be a string\n * literal, the same one passed to the constructor. If the schema is not\n * `\"public\"`, this must be supplied manually.\n */\nexport default class PostgrestClient<\n  Database = any,\n  ClientOptions extends ClientServerOptions = Database extends {\n    __InternalSupabase: infer I extends ClientServerOptions\n  }\n    ? I\n    : {},\n  SchemaName extends string &\n    keyof Omit<Database, '__InternalSupabase'> = 'public' extends keyof Omit<\n    Database,\n    '__InternalSupabase'\n  >\n    ? 'public'\n    : string & keyof Omit<Database, '__InternalSupabase'>,\n  Schema extends GenericSchema = Omit<\n    Database,\n    '__InternalSupabase'\n  >[SchemaName] extends GenericSchema\n    ? Omit<Database, '__InternalSupabase'>[SchemaName]\n    : any,\n> {\n  url: string\n  headers: Headers\n  schemaName?: SchemaName\n  fetch?: Fetch\n\n  // TODO: Add back shouldThrowOnError once we figure out the typings\n  /**\n   * Creates a PostgREST client.\n   *\n   * @param url - URL of the PostgREST endpoint\n   * @param options - Named parameters\n   * @param options.headers - Custom headers\n   * @param options.schema - Postgres schema to switch to\n   * @param options.fetch - Custom fetch\n   * @example\n   * ```ts\n   * import PostgrestClient from '@supabase/postgrest-js'\n   *\n   * const postgrest = new PostgrestClient('https://xyzcompany.supabase.co/rest/v1', {\n   *   headers: { apikey: 'public-anon-key' },\n   *   schema: 'public',\n   * })\n   * ```\n   */\n  constructor(\n    url: string,\n    {\n      headers = {},\n      schema,\n      fetch,\n    }: {\n      headers?: HeadersInit\n      schema?: SchemaName\n      fetch?: Fetch\n    } = {}\n  ) {\n    this.url = url\n    this.headers = new Headers(headers)\n    this.schemaName = schema\n    this.fetch = fetch\n  }\n  from<\n    TableName extends string & keyof Schema['Tables'],\n    Table extends Schema['Tables'][TableName],\n  >(relation: TableName): PostgrestQueryBuilder<ClientOptions, Schema, Table, TableName>\n  from<ViewName extends string & keyof Schema['Views'], View extends Schema['Views'][ViewName]>(\n    relation: ViewName\n  ): PostgrestQueryBuilder<ClientOptions, Schema, View, ViewName>\n  /**\n   * Perform a query on a table or a view.\n   *\n   * @param relation - The table or view name to query\n   */\n  from(relation: string): PostgrestQueryBuilder<ClientOptions, Schema, any, any> {\n    if (!relation || typeof relation !== 'string' || relation.trim() === '') {\n      throw new Error('Invalid relation name: relation must be a non-empty string.')\n    }\n\n    const url = new URL(`${this.url}/${relation}`)\n    return new PostgrestQueryBuilder(url, {\n      headers: new Headers(this.headers),\n      schema: this.schemaName,\n      fetch: this.fetch,\n    })\n  }\n\n  /**\n   * Select a schema to query or perform an function (rpc) call.\n   *\n   * The schema needs to be on the list of exposed schemas inside Supabase.\n   *\n   * @param schema - The schema to query\n   */\n  schema<DynamicSchema extends string & keyof Omit<Database, '__InternalSupabase'>>(\n    schema: DynamicSchema\n  ): PostgrestClient<\n    Database,\n    ClientOptions,\n    DynamicSchema,\n    Database[DynamicSchema] extends GenericSchema ? Database[DynamicSchema] : any\n  > {\n    return new PostgrestClient(this.url, {\n      headers: this.headers,\n      schema,\n      fetch: this.fetch,\n    })\n  }\n\n  /**\n   * Perform a function call.\n   *\n   * @param fn - The function name to call\n   * @param args - The arguments to pass to the function call\n   * @param options - Named parameters\n   * @param options.head - When set to `true`, `data` will not be returned.\n   * Useful if you only need the count.\n   * @param options.get - When set to `true`, the function will be called with\n   * read-only access mode.\n   * @param options.count - Count algorithm to use to count rows returned by the\n   * function. Only applicable for [set-returning\n   * functions](https://www.postgresql.org/docs/current/functions-srf.html).\n   *\n   * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n   * hood.\n   *\n   * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n   * statistics under the hood.\n   *\n   * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n   * numbers.\n   *\n   * @example\n   * ```ts\n   * // For cross-schema functions where type inference fails, use overrideTypes:\n   * const { data } = await supabase\n   *   .schema('schema_b')\n   *   .rpc('function_a', {})\n   *   .overrideTypes<{ id: string; user_id: string }[]>()\n   * ```\n   */\n  rpc<\n    FnName extends string & keyof Schema['Functions'],\n    Args extends Schema['Functions'][FnName]['Args'] = never,\n    FilterBuilder extends GetRpcFunctionFilterBuilderByArgs<\n      Schema,\n      FnName,\n      Args\n    > = GetRpcFunctionFilterBuilderByArgs<Schema, FnName, Args>,\n  >(\n    fn: FnName,\n    args: Args = {} as Args,\n    {\n      head = false,\n      get = false,\n      count,\n    }: {\n      head?: boolean\n      get?: boolean\n      count?: 'exact' | 'planned' | 'estimated'\n    } = {}\n  ): PostgrestFilterBuilder<\n    ClientOptions,\n    Schema,\n    FilterBuilder['Row'],\n    FilterBuilder['Result'],\n    FilterBuilder['RelationName'],\n    FilterBuilder['Relationships'],\n    'RPC'\n  > {\n    let method: 'HEAD' | 'GET' | 'POST'\n    const url = new URL(`${this.url}/rpc/${fn}`)\n    let body: unknown | undefined\n    // objects/arrays-of-objects can't be serialized to URL params, use POST + return=minimal instead\n    const _isObject = (v: unknown): boolean =>\n      v !== null && typeof v === 'object' && (!Array.isArray(v) || v.some(_isObject))\n    const _hasObjectArg = head && Object.values(args as object).some(_isObject)\n    if (_hasObjectArg) {\n      method = 'POST'\n      body = args\n    } else if (head || get) {\n      method = head ? 'HEAD' : 'GET'\n      Object.entries(args)\n        // params with undefined value needs to be filtered out, otherwise it'll\n        // show up as `?param=undefined`\n        .filter(([_, value]) => value !== undefined)\n        // array values need special syntax\n        .map(([name, value]) => [name, Array.isArray(value) ? `{${value.join(',')}}` : `${value}`])\n        .forEach(([name, value]) => {\n          url.searchParams.append(name, value)\n        })\n    } else {\n      method = 'POST'\n      body = args\n    }\n\n    const headers = new Headers(this.headers)\n    if (_hasObjectArg) {\n      headers.set('Prefer', count ? `count=${count},return=minimal` : 'return=minimal')\n    } else if (count) {\n      headers.set('Prefer', `count=${count}`)\n    }\n\n    return new PostgrestFilterBuilder({\n      method,\n      url,\n      headers,\n      schema: this.schemaName,\n      body,\n      fetch: this.fetch ?? fetch,\n    })\n  }\n}\n","// Generated automatically during releases by scripts/update-version-files.ts\n// This file provides runtime access to the package version for:\n// - HTTP request headers (e.g., X-Client-Info header for API requests)\n// - Debugging and support (identifying which version is running)\n// - Telemetry and logging (version reporting in errors/analytics)\n// - Ensuring build artifacts match the published package version\nexport const version = '2.90.1'\n","import { version } from './version'\nexport const DEFAULT_HEADERS = {\n  'X-Client-Info': `storage-js/${version}`,\n}\n","import { DEFAULT_HEADERS } from '../lib/constants'\nimport { isStorageError, StorageError } from '../lib/errors'\nimport { Fetch, get, post, put, remove } from '../lib/fetch'\nimport { resolveFetch } from '../lib/helpers'\nimport { Bucket, BucketType, ListBucketOptions } from '../lib/types'\nimport { StorageClientOptions } from '../StorageClient'\n\nexport default class StorageBucketApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    opts?: StorageClientOptions\n  ) {\n    const baseUrl = new URL(url)\n\n    // if legacy uri is used, replace with new storage host (disables request buffering to allow > 50GB uploads)\n    // \"project-ref.supabase.co\" becomes \"project-ref.storage.supabase.co\"\n    if (opts?.useNewHostname) {\n      const isSupabaseHost = /supabase\\.(co|in|red)$/.test(baseUrl.hostname)\n      if (isSupabaseHost && !baseUrl.hostname.includes('storage.supabase.')) {\n        baseUrl.hostname = baseUrl.hostname.replace('supabase.', 'storage.supabase.')\n      }\n    }\n\n    this.url = baseUrl.href.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /**\n   * Enable throwing errors instead of returning them.\n   *\n   * @category File Buckets\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * Retrieves the details of all Storage buckets within an existing project.\n   *\n   * @category File Buckets\n   * @param options Query parameters for listing buckets\n   * @param options.limit Maximum number of buckets to return\n   * @param options.offset Number of buckets to skip\n   * @param options.sortColumn Column to sort by ('id', 'name', 'created_at', 'updated_at')\n   * @param options.sortOrder Sort order ('asc' or 'desc')\n   * @param options.search Search term to filter bucket names\n   * @returns Promise with response containing array of buckets or error\n   *\n   * @example List buckets\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .listBuckets()\n   * ```\n   *\n   * @example List buckets with options\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .listBuckets({\n   *     limit: 10,\n   *     offset: 0,\n   *     sortColumn: 'created_at',\n   *     sortOrder: 'desc',\n   *     search: 'prod'\n   *   })\n   * ```\n   */\n  async listBuckets(options?: ListBucketOptions): Promise<\n    | {\n        data: Bucket[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const queryString = this.listBucketOptionsToQueryString(options)\n      const data = await get(this.fetch, `${this.url}/bucket${queryString}`, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Retrieves the details of an existing Storage bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to retrieve.\n   * @returns Promise with response containing bucket details or error\n   *\n   * @example Get bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .getBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"id\": \"avatars\",\n   *     \"name\": \"avatars\",\n   *     \"owner\": \"\",\n   *     \"public\": false,\n   *     \"file_size_limit\": 1024,\n   *     \"allowed_mime_types\": [\n   *       \"image/png\"\n   *     ],\n   *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async getBucket(id: string): Promise<\n    | {\n        data: Bucket\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await get(this.fetch, `${this.url}/bucket/${id}`, { headers: this.headers })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Creates a new Storage bucket\n   *\n   * @category File Buckets\n   * @param id A unique identifier for the bucket you are creating.\n   * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations. By default, buckets are private.\n   * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n   * The global file size limit takes precedence over this value.\n   * The default value is null, which doesn't set a per bucket file size limit.\n   * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n   * The default value is null, which allows files with all mime types to be uploaded.\n   * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n   * @param options.type (private-beta) specifies the bucket type. see `BucketType` for more details.\n   *   - default bucket type is `STANDARD`\n   * @returns Promise with response containing newly created bucket name or error\n   *\n   * @example Create bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .createBucket('avatars', {\n   *     public: false,\n   *     allowedMimeTypes: ['image/png'],\n   *     fileSizeLimit: 1024\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"name\": \"avatars\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createBucket(\n    id: string,\n    options: {\n      public: boolean\n      fileSizeLimit?: number | string | null\n      allowedMimeTypes?: string[] | null\n      type?: BucketType\n    } = {\n      public: false,\n    }\n  ): Promise<\n    | {\n        data: Pick<Bucket, 'name'>\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/bucket`,\n        {\n          id,\n          name: id,\n          type: options.type,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Updates a Storage bucket\n   *\n   * @category File Buckets\n   * @param id A unique identifier for the bucket you are updating.\n   * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations.\n   * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n   * The global file size limit takes precedence over this value.\n   * The default value is null, which doesn't set a per bucket file size limit.\n   * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n   * The default value is null, which allows files with all mime types to be uploaded.\n   * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n   * @returns Promise with response containing success message or error\n   *\n   * @example Update bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .updateBucket('avatars', {\n   *     public: false,\n   *     allowedMimeTypes: ['image/png'],\n   *     fileSizeLimit: 1024\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully updated\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async updateBucket(\n    id: string,\n    options: {\n      public: boolean\n      fileSizeLimit?: number | string | null\n      allowedMimeTypes?: string[] | null\n    }\n  ): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await put(\n        this.fetch,\n        `${this.url}/bucket/${id}`,\n        {\n          id,\n          name: id,\n          public: options.public,\n          file_size_limit: options.fileSizeLimit,\n          allowed_mime_types: options.allowedMimeTypes,\n        },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Removes all objects inside a single bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to empty.\n   * @returns Promise with success message or error\n   *\n   * @example Empty bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .emptyBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully emptied\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async emptyBucket(id: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/bucket/${id}/empty`,\n        {},\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * Deletes an existing bucket. A bucket can't be deleted with existing objects inside it.\n   * You must first `empty()` the bucket.\n   *\n   * @category File Buckets\n   * @param id The unique identifier of the bucket you would like to delete.\n   * @returns Promise with success message or error\n   *\n   * @example Delete bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .deleteBucket('avatars')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully deleted\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async deleteBucket(id: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await remove(\n        this.fetch,\n        `${this.url}/bucket/${id}`,\n        {},\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  private listBucketOptionsToQueryString(options?: ListBucketOptions): string {\n    const params: Record<string, string> = {}\n    if (options) {\n      if ('limit' in options) {\n        params.limit = String(options.limit)\n      }\n      if ('offset' in options) {\n        params.offset = String(options.offset)\n      }\n      if (options.search) {\n        params.search = options.search\n      }\n      if (options.sortColumn) {\n        params.sortColumn = options.sortColumn\n      }\n      if (options.sortOrder) {\n        params.sortOrder = options.sortOrder\n      }\n    }\n    return Object.keys(params).length > 0 ? '?' + new URLSearchParams(params).toString() : ''\n  }\n}\n","import PostgrestClient from './PostgrestClient'\nimport PostgrestQueryBuilder from './PostgrestQueryBuilder'\nimport PostgrestFilterBuilder from './PostgrestFilterBuilder'\nimport PostgrestTransformBuilder from './PostgrestTransformBuilder'\nimport PostgrestBuilder from './PostgrestBuilder'\nimport PostgrestError from './PostgrestError'\n\nexport {\n  PostgrestClient,\n  PostgrestQueryBuilder,\n  PostgrestFilterBuilder,\n  PostgrestTransformBuilder,\n  PostgrestBuilder,\n  PostgrestError,\n}\nexport default {\n  PostgrestClient,\n  PostgrestQueryBuilder,\n  PostgrestFilterBuilder,\n  PostgrestTransformBuilder,\n  PostgrestBuilder,\n  PostgrestError,\n}\nexport type {\n  PostgrestResponse,\n  PostgrestResponseFailure,\n  PostgrestResponseSuccess,\n  PostgrestSingleResponse,\n  PostgrestMaybeSingleResponse,\n} from './types/types'\nexport type { ClientServerOptions as PostgrestClientOptions } from './types/common/common'\n// https://github.com/supabase/postgrest-js/issues/551\n// To be replaced with a helper type that only uses public types\nexport type { GetResult as UnstableGetResult } from './select-query-parser/result'\n","import { IcebergRestCatalog, IcebergError } from 'iceberg-js'\nimport { DEFAULT_HEADERS } from '../lib/constants'\nimport { isStorageError, StorageError } from '../lib/errors'\nimport { Fetch, get, post, remove } from '../lib/fetch'\nimport { isValidBucketName, resolveFetch } from '../lib/helpers'\nimport { AnalyticBucket } from '../lib/types'\n\ntype WrapAsyncMethod<T> = T extends (...args: infer A) => Promise<infer R>\n  ? (...args: A) => Promise<{ data: R; error: null } | { data: null; error: IcebergError }>\n  : T\n\nexport type WrappedIcebergRestCatalog = {\n  [K in keyof IcebergRestCatalog]: WrapAsyncMethod<IcebergRestCatalog[K]>\n}\n\n/**\n * Client class for managing Analytics Buckets using Iceberg tables\n * Provides methods for creating, listing, and deleting analytics buckets\n */\nexport default class StorageAnalyticsClient {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /**\n   * @alpha\n   *\n   * Creates a new StorageAnalyticsClient instance\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param url - The base URL for the storage API\n   * @param headers - HTTP headers to include in requests\n   * @param fetch - Optional custom fetch implementation\n   *\n   * @example\n   * ```typescript\n   * const client = new StorageAnalyticsClient(url, headers)\n   * ```\n   */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /**\n   * @alpha\n   *\n   * Enable throwing errors instead of returning them in the response\n   * When enabled, failed operations will throw instead of returning { data: null, error }\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @returns This instance for method chaining\n   */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /**\n   * @alpha\n   *\n   * Creates a new analytics bucket using Iceberg tables\n   * Analytics buckets are optimized for analytical queries and data processing\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param name A unique name for the bucket you are creating\n   * @returns Promise with response containing newly created analytics bucket or error\n   *\n   * @example Create analytics bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .createBucket('analytics-data')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"name\": \"analytics-data\",\n   *     \"type\": \"ANALYTICS\",\n   *     \"format\": \"iceberg\",\n   *     \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *     \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async createBucket(name: string): Promise<\n    | {\n        data: AnalyticBucket\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await post(this.fetch, `${this.url}/bucket`, { name }, { headers: this.headers })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @alpha\n   *\n   * Retrieves the details of all Analytics Storage buckets within an existing project\n   * Only returns buckets of type 'ANALYTICS'\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param options Query parameters for listing buckets\n   * @param options.limit Maximum number of buckets to return\n   * @param options.offset Number of buckets to skip\n   * @param options.sortColumn Column to sort by ('name', 'created_at', 'updated_at')\n   * @param options.sortOrder Sort order ('asc' or 'desc')\n   * @param options.search Search term to filter bucket names\n   * @returns Promise with response containing array of analytics buckets or error\n   *\n   * @example List analytics buckets\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .listBuckets({\n   *     limit: 10,\n   *     offset: 0,\n   *     sortColumn: 'created_at',\n   *     sortOrder: 'desc'\n   *   })\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": [\n   *     {\n   *       \"name\": \"analytics-data\",\n   *       \"type\": \"ANALYTICS\",\n   *       \"format\": \"iceberg\",\n   *       \"created_at\": \"2024-05-22T22:26:05.100Z\",\n   *       \"updated_at\": \"2024-05-22T22:26:05.100Z\"\n   *     }\n   *   ],\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async listBuckets(options?: {\n    limit?: number\n    offset?: number\n    sortColumn?: 'name' | 'created_at' | 'updated_at'\n    sortOrder?: 'asc' | 'desc'\n    search?: string\n  }): Promise<\n    | {\n        data: AnalyticBucket[]\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      // Build query string from options\n      const queryParams = new URLSearchParams()\n      if (options?.limit !== undefined) queryParams.set('limit', options.limit.toString())\n      if (options?.offset !== undefined) queryParams.set('offset', options.offset.toString())\n      if (options?.sortColumn) queryParams.set('sortColumn', options.sortColumn)\n      if (options?.sortOrder) queryParams.set('sortOrder', options.sortOrder)\n      if (options?.search) queryParams.set('search', options.search)\n\n      const queryString = queryParams.toString()\n      const url = queryString ? `${this.url}/bucket?${queryString}` : `${this.url}/bucket`\n\n      const data = await get(this.fetch, url, { headers: this.headers })\n\n      return { data: data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @alpha\n   *\n   * Deletes an existing analytics bucket\n   * A bucket can't be deleted with existing objects inside it\n   * You must first empty the bucket before deletion\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param bucketName The unique identifier of the bucket you would like to delete\n   * @returns Promise with response containing success message or error\n   *\n   * @example Delete analytics bucket\n   * ```js\n   * const { data, error } = await supabase\n   *   .storage\n   *   .analytics\n   *   .deleteBucket('analytics-data')\n   * ```\n   *\n   * Response:\n   * ```json\n   * {\n   *   \"data\": {\n   *     \"message\": \"Successfully deleted\"\n   *   },\n   *   \"error\": null\n   * }\n   * ```\n   */\n  async deleteBucket(bucketName: string): Promise<\n    | {\n        data: { message: string }\n        error: null\n      }\n    | {\n        data: null\n        error: StorageError\n      }\n  > {\n    try {\n      const data = await remove(\n        this.fetch,\n        `${this.url}/bucket/${bucketName}`,\n        {},\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageError(error)) {\n        return { data: null, error }\n      }\n\n      throw error\n    }\n  }\n\n  /**\n   * @alpha\n   *\n   * Get an Iceberg REST Catalog client configured for a specific analytics bucket\n   * Use this to perform advanced table and namespace operations within the bucket\n   * The returned client provides full access to the Apache Iceberg REST Catalog API\n   * with the Supabase `{ data, error }` pattern for consistent error handling on all operations.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @param bucketName - The name of the analytics bucket (warehouse) to connect to\n   * @returns The wrapped Iceberg catalog client\n   * @throws {StorageError} If the bucket name is invalid\n   *\n   * @example Get catalog and create table\n   * ```js\n   * // First, create an analytics bucket\n   * const { data: bucket, error: bucketError } = await supabase\n   *   .storage\n   *   .analytics\n   *   .createBucket('analytics-data')\n   *\n   * // Get the Iceberg catalog for that bucket\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // Create a namespace\n   * const { error: nsError } = await catalog.createNamespace({ namespace: ['default'] })\n   *\n   * // Create a table with schema\n   * const { data: tableMetadata, error: tableError } = await catalog.createTable(\n   *   { namespace: ['default'] },\n   *   {\n   *     name: 'events',\n   *     schema: {\n   *       type: 'struct',\n   *       fields: [\n   *         { id: 1, name: 'id', type: 'long', required: true },\n   *         { id: 2, name: 'timestamp', type: 'timestamp', required: true },\n   *         { id: 3, name: 'user_id', type: 'string', required: false }\n   *       ],\n   *       'schema-id': 0,\n   *       'identifier-field-ids': [1]\n   *     },\n   *     'partition-spec': {\n   *       'spec-id': 0,\n   *       fields: []\n   *     },\n   *     'write-order': {\n   *       'order-id': 0,\n   *       fields: []\n   *     },\n   *     properties: {\n   *       'write.format.default': 'parquet'\n   *     }\n   *   }\n   * )\n   * ```\n   *\n   * @example List tables in namespace\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // List all tables in the default namespace\n   * const { data: tables, error: listError } = await catalog.listTables({ namespace: ['default'] })\n   * if (listError) {\n   *   if (listError.isNotFound()) {\n   *     console.log('Namespace not found')\n   *   }\n   *   return\n   * }\n   * console.log(tables) // [{ namespace: ['default'], name: 'events' }]\n   * ```\n   *\n   * @example Working with namespaces\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // List all namespaces\n   * const { data: namespaces } = await catalog.listNamespaces()\n   *\n   * // Create namespace with properties\n   * await catalog.createNamespace(\n   *   { namespace: ['production'] },\n   *   { properties: { owner: 'data-team', env: 'prod' } }\n   * )\n   * ```\n   *\n   * @example Cleanup operations\n   * ```js\n   * const catalog = supabase.storage.analytics.from('analytics-data')\n   *\n   * // Drop table with purge option (removes all data)\n   * const { error: dropError } = await catalog.dropTable(\n   *   { namespace: ['default'], name: 'events' },\n   *   { purge: true }\n   * )\n   *\n   * if (dropError?.isNotFound()) {\n   *   console.log('Table does not exist')\n   * }\n   *\n   * // Drop namespace (must be empty)\n   * await catalog.dropNamespace({ namespace: ['default'] })\n   * ```\n   *\n   * @remarks\n   * This method provides a bridge between Supabase's bucket management and the standard\n   * Apache Iceberg REST Catalog API. The bucket name maps to the Iceberg warehouse parameter.\n   * All authentication and configuration is handled automatically using your Supabase credentials.\n   *\n   * **Error Handling**: Invalid bucket names throw immediately. All catalog\n   * operations return `{ data, error }` where errors are `IcebergError` instances from iceberg-js.\n   * Use helper methods like `error.isNotFound()` or check `error.status` for specific error handling.\n   * Use `.throwOnError()` on the analytics client if you prefer exceptions for catalog operations.\n   *\n   * **Cleanup Operations**: When using `dropTable`, the `purge: true` option permanently\n   * deletes all table data. Without it, the table is marked as deleted but data remains.\n   *\n   * **Library Dependency**: The returned catalog wraps `IcebergRestCatalog` from iceberg-js.\n   * For complete API documentation and advanced usage, refer to the\n   * [iceberg-js documentation](https://supabase.github.io/iceberg-js/).\n   */\n  from(bucketName: string): WrappedIcebergRestCatalog {\n    // Validate bucket name using same rules as Supabase Storage API backend\n    if (!isValidBucketName(bucketName)) {\n      throw new StorageError(\n        'Invalid bucket name: File, folder, and bucket names must follow AWS object key naming guidelines ' +\n          'and should avoid the use of any other characters.'\n      )\n    }\n\n    // Construct the Iceberg REST Catalog URL\n    // The base URL is /storage/v1/iceberg\n    // Note: IcebergRestCatalog from iceberg-js automatically adds /v1/ prefix to API paths\n    // so we should NOT append /v1 here (it would cause double /v1/v1/ in the URL)\n    const catalog = new IcebergRestCatalog({\n      baseUrl: this.url,\n      catalogName: bucketName, // Maps to the warehouse parameter in Supabase's implementation\n      auth: {\n        type: 'custom',\n        getHeaders: async () => this.headers,\n      },\n      fetch: this.fetch,\n    })\n\n    const shouldThrowOnError = this.shouldThrowOnError\n\n    const wrappedCatalog = new Proxy(catalog, {\n      get(target, prop: keyof IcebergRestCatalog) {\n        const value = target[prop]\n        if (typeof value !== 'function') {\n          return value\n        }\n\n        return async (...args: unknown[]) => {\n          try {\n            const data = await (value as Function).apply(target, args)\n            return { data, error: null }\n          } catch (error) {\n            if (shouldThrowOnError) {\n              throw error\n            }\n            return { data: null, error: error as IcebergError }\n          }\n        }\n      },\n    }) as unknown as WrappedIcebergRestCatalog\n\n    return wrappedCatalog\n  }\n}\n","import { version } from '../version'\nexport const DEFAULT_HEADERS = {\n  'X-Client-Info': `storage-js/${version}`,\n  'Content-Type': 'application/json',\n}\n","/**\n * Base error class for all Storage Vectors errors\n */\nexport class StorageVectorsError extends Error {\n  protected __isStorageVectorsError = true\n\n  constructor(message: string) {\n    super(message)\n    this.name = 'StorageVectorsError'\n  }\n}\n\n/**\n * Type guard to check if an error is a StorageVectorsError\n * @param error - The error to check\n * @returns True if the error is a StorageVectorsError\n */\nexport function isStorageVectorsError(error: unknown): error is StorageVectorsError {\n  return typeof error === 'object' && error !== null && '__isStorageVectorsError' in error\n}\n\n/**\n * API error returned from S3 Vectors service\n * Includes HTTP status code and service-specific error code\n */\nexport class StorageVectorsApiError extends StorageVectorsError {\n  status: number\n  statusCode: string\n\n  constructor(message: string, status: number, statusCode: string) {\n    super(message)\n    this.name = 'StorageVectorsApiError'\n    this.status = status\n    this.statusCode = statusCode\n  }\n\n  toJSON() {\n    return {\n      name: this.name,\n      message: this.message,\n      status: this.status,\n      statusCode: this.statusCode,\n    }\n  }\n}\n\n/**\n * Unknown error that doesn't match expected error patterns\n * Wraps the original error for debugging\n */\nexport class StorageVectorsUnknownError extends StorageVectorsError {\n  originalError: unknown\n\n  constructor(message: string, originalError: unknown) {\n    super(message)\n    this.name = 'StorageVectorsUnknownError'\n    this.originalError = originalError\n  }\n}\n\n/**\n * Error codes specific to S3 Vectors API\n * Maps AWS service errors to application-friendly error codes\n */\nexport enum StorageVectorsErrorCode {\n  /** Internal server fault (HTTP 500) */\n  InternalError = 'InternalError',\n  /** Resource already exists / conflict (HTTP 409) */\n  S3VectorConflictException = 'S3VectorConflictException',\n  /** Resource not found (HTTP 404) */\n  S3VectorNotFoundException = 'S3VectorNotFoundException',\n  /** Delete bucket while not empty (HTTP 400) */\n  S3VectorBucketNotEmpty = 'S3VectorBucketNotEmpty',\n  /** Exceeds bucket quota/limit (HTTP 400) */\n  S3VectorMaxBucketsExceeded = 'S3VectorMaxBucketsExceeded',\n  /** Exceeds index quota/limit (HTTP 400) */\n  S3VectorMaxIndexesExceeded = 'S3VectorMaxIndexesExceeded',\n}\n","type Fetch = typeof fetch\n\n/**\n * Resolves the fetch implementation to use\n * Uses custom fetch if provided, otherwise uses native fetch\n *\n * @param customFetch - Optional custom fetch implementation\n * @returns Resolved fetch function\n */\nexport const resolveFetch = (customFetch?: Fetch): Fetch => {\n  if (customFetch) {\n    return (...args) => customFetch(...args)\n  }\n  return (...args) => fetch(...args)\n}\n\n/**\n * Resolves the Response constructor to use\n * Returns native Response constructor\n *\n * @returns Response constructor\n */\nexport const resolveResponse = (): typeof Response => {\n  return Response\n}\n\n/**\n * Determine if input is a plain object\n * An object is plain if it's created by either {}, new Object(), or Object.create(null)\n *\n * @param value - Value to check\n * @returns True if value is a plain object\n * @source https://github.com/sindresorhus/is-plain-obj\n */\nexport const isPlainObject = (value: object): boolean => {\n  if (typeof value !== 'object' || value === null) {\n    return false\n  }\n\n  const prototype = Object.getPrototypeOf(value)\n  return (\n    (prototype === null ||\n      prototype === Object.prototype ||\n      Object.getPrototypeOf(prototype) === null) &&\n    !(Symbol.toStringTag in value) &&\n    !(Symbol.iterator in value)\n  )\n}\n\n/**\n * Normalizes a number array to float32 format\n * Ensures all vector values are valid 32-bit floats\n *\n * @param values - Array of numbers to normalize\n * @returns Normalized float32 array\n */\nexport const normalizeToFloat32 = (values: number[]): number[] => {\n  // Use Float32Array to ensure proper precision\n  return Array.from(new Float32Array(values))\n}\n\n/**\n * Validates vector dimensions match expected dimension\n * Throws error if dimensions don't match\n *\n * @param vector - Vector data to validate\n * @param expectedDimension - Expected vector dimension\n * @throws Error if dimensions don't match\n */\nexport const validateVectorDimension = (\n  vector: { float32: number[] },\n  expectedDimension?: number\n): void => {\n  if (expectedDimension !== undefined && vector.float32.length !== expectedDimension) {\n    throw new Error(\n      `Vector dimension mismatch: expected ${expectedDimension}, got ${vector.float32.length}`\n    )\n  }\n}\n","import { StorageVectorsApiError, StorageVectorsUnknownError } from './errors'\nimport { isPlainObject, resolveResponse } from './helpers'\nimport { VectorFetchParameters } from './types'\n\nexport type Fetch = typeof fetch\n\n/**\n * Options for fetch requests\n * @property headers - Custom HTTP headers\n * @property noResolveJson - If true, return raw Response instead of parsing JSON\n */\nexport interface FetchOptions {\n  headers?: {\n    [key: string]: string\n  }\n  noResolveJson?: boolean\n}\n\n/**\n * HTTP methods supported by the API\n */\nexport type RequestMethodType = 'GET' | 'POST' | 'PUT' | 'DELETE'\n\n/**\n * Extracts error message from various error response formats\n * @param err - Error object from API\n * @returns Human-readable error message\n */\nconst _getErrorMessage = (err: any): string =>\n  err.msg || err.message || err.error_description || err.error || JSON.stringify(err)\n\n/**\n * Handles fetch errors and converts them to StorageVectors error types\n * @param error - The error caught from fetch\n * @param reject - Promise rejection function\n * @param options - Fetch options that may affect error handling\n */\nconst handleError = async (\n  error: unknown,\n  reject: (reason?: any) => void,\n  options?: FetchOptions\n) => {\n  // Check if error is a Response-like object (has status and ok properties)\n  // This is more reliable than instanceof which can fail across realms\n  const isResponseLike =\n    error &&\n    typeof error === 'object' &&\n    'status' in error &&\n    'ok' in error &&\n    typeof (error as any).status === 'number'\n\n  if (isResponseLike && !options?.noResolveJson) {\n    const status = (error as any).status || 500\n    const responseError = error as any\n\n    // Try to parse JSON body if available\n    if (typeof responseError.json === 'function') {\n      responseError\n        .json()\n        .then((err: any) => {\n          const statusCode = err?.statusCode || err?.code || status + ''\n          reject(new StorageVectorsApiError(_getErrorMessage(err), status, statusCode))\n        })\n        .catch(() => {\n          // If JSON parsing fails, create an ApiError with the HTTP status code\n          const statusCode = status + ''\n          const message = responseError.statusText || `HTTP ${status} error`\n          reject(new StorageVectorsApiError(message, status, statusCode))\n        })\n    } else {\n      // No json() method available, create error from status\n      const statusCode = status + ''\n      const message = responseError.statusText || `HTTP ${status} error`\n      reject(new StorageVectorsApiError(message, status, statusCode))\n    }\n  } else {\n    reject(new StorageVectorsUnknownError(_getErrorMessage(error), error))\n  }\n}\n\n/**\n * Builds request parameters for fetch calls\n * @param method - HTTP method\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters like AbortSignal\n * @param body - Request body (will be JSON stringified if plain object)\n * @returns Complete fetch request parameters\n */\nconst _getRequestParams = (\n  method: RequestMethodType,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters,\n  body?: object\n) => {\n  const params: { [k: string]: any } = { method, headers: options?.headers || {} }\n\n  if (method === 'GET' || !body) {\n    return params\n  }\n\n  if (isPlainObject(body)) {\n    params.headers = { 'Content-Type': 'application/json', ...options?.headers }\n    params.body = JSON.stringify(body)\n  } else {\n    params.body = body\n  }\n\n  return { ...params, ...parameters }\n}\n\n/**\n * Internal request handler that wraps fetch with error handling\n * @param fetcher - Fetch function to use\n * @param method - HTTP method\n * @param url - Request URL\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @param body - Request body\n * @returns Promise with parsed response or error\n */\nasync function _handleRequest(\n  fetcher: Fetch,\n  method: RequestMethodType,\n  url: string,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters,\n  body?: object\n): Promise<any> {\n  return new Promise((resolve, reject) => {\n    fetcher(url, _getRequestParams(method, options, parameters, body))\n      .then((result) => {\n        if (!result.ok) throw result\n        if (options?.noResolveJson) return result\n        // Handle empty responses (204, empty body)\n        const contentType = result.headers.get('content-type')\n        if (!contentType || !contentType.includes('application/json')) {\n          return {}\n        }\n        return result.json()\n      })\n      .then((data) => resolve(data))\n      .catch((error) => handleError(error, reject, options))\n  })\n}\n\n/**\n * Performs a GET request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function get(\n  fetcher: Fetch,\n  url: string,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'GET', url, options, parameters)\n}\n\n/**\n * Performs a POST request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param body - Request body to be JSON stringified\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function post(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'POST', url, options, parameters, body)\n}\n\n/**\n * Performs a PUT request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param body - Request body to be JSON stringified\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function put(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'PUT', url, options, parameters, body)\n}\n\n/**\n * Performs a DELETE request\n * @param fetcher - Fetch function to use\n * @param url - Request URL\n * @param body - Request body to be JSON stringified\n * @param options - Custom fetch options\n * @param parameters - Additional fetch parameters\n * @returns Promise with parsed response\n */\nexport async function remove(\n  fetcher: Fetch,\n  url: string,\n  body: object,\n  options?: FetchOptions,\n  parameters?: VectorFetchParameters\n): Promise<any> {\n  return _handleRequest(fetcher, 'DELETE', url, options, parameters, body)\n}\n","import { DEFAULT_HEADERS } from './constants'\nimport { isStorageVectorsError } from './errors'\nimport { Fetch, post } from './fetch'\nimport { resolveFetch } from './helpers'\nimport {\n  ApiResponse,\n  VectorIndex,\n  ListIndexesOptions,\n  ListIndexesResponse,\n  VectorDataType,\n  DistanceMetric,\n  MetadataConfiguration,\n} from './types'\n\n/**\n * @alpha\n *\n * Options for creating a vector index\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport interface CreateIndexOptions {\n  vectorBucketName: string\n  indexName: string\n  dataType: VectorDataType\n  dimension: number\n  distanceMetric: DistanceMetric\n  metadataConfiguration?: MetadataConfiguration\n}\n\n/**\n * @hidden\n * Base implementation for vector index operations.\n * Use {@link VectorBucketScope} via `supabase.storage.vectors.from('bucket')` instead.\n */\nexport default class VectorIndexApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /** Creates a new VectorIndexApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /** Enable throwing errors instead of returning them in the response */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /** Creates a new vector index within a bucket */\n  async createIndex(options: CreateIndexOptions): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/CreateIndex`, options, {\n        headers: this.headers,\n      })\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Retrieves metadata for a specific vector index */\n  async getIndex(\n    vectorBucketName: string,\n    indexName: string\n  ): Promise<ApiResponse<{ index: VectorIndex }>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/GetIndex`,\n        { vectorBucketName, indexName },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Lists vector indexes within a bucket with optional filtering and pagination */\n  async listIndexes(options: ListIndexesOptions): Promise<ApiResponse<ListIndexesResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/ListIndexes`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Deletes a vector index and all its data */\n  async deleteIndex(vectorBucketName: string, indexName: string): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/DeleteIndex`,\n        { vectorBucketName, indexName },\n        { headers: this.headers }\n      )\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n}\n","import { DEFAULT_HEADERS } from './constants'\nimport { isStorageVectorsError } from './errors'\nimport { Fetch, post } from './fetch'\nimport { resolveFetch } from './helpers'\nimport {\n  ApiResponse,\n  PutVectorsOptions,\n  GetVectorsOptions,\n  GetVectorsResponse,\n  DeleteVectorsOptions,\n  ListVectorsOptions,\n  ListVectorsResponse,\n  QueryVectorsOptions,\n  QueryVectorsResponse,\n} from './types'\n\n/**\n * @hidden\n * Base implementation for vector data operations.\n * Use {@link VectorIndexScope} via `supabase.storage.vectors.from('bucket').index('idx')` instead.\n */\nexport default class VectorDataApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /** Creates a new VectorDataApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /** Enable throwing errors instead of returning them in the response */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /** Inserts or updates vectors in batch (1-500 per request) */\n  async putVectors(options: PutVectorsOptions): Promise<ApiResponse<undefined>> {\n    try {\n      // Validate batch size\n      if (options.vectors.length < 1 || options.vectors.length > 500) {\n        throw new Error('Vector batch size must be between 1 and 500 items')\n      }\n\n      const data = await post(this.fetch, `${this.url}/PutVectors`, options, {\n        headers: this.headers,\n      })\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Retrieves vectors by their keys in batch */\n  async getVectors(options: GetVectorsOptions): Promise<ApiResponse<GetVectorsResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/GetVectors`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Lists vectors in an index with pagination */\n  async listVectors(options: ListVectorsOptions): Promise<ApiResponse<ListVectorsResponse>> {\n    try {\n      // Validate segment configuration\n      if (options.segmentCount !== undefined) {\n        if (options.segmentCount < 1 || options.segmentCount > 16) {\n          throw new Error('segmentCount must be between 1 and 16')\n        }\n        if (options.segmentIndex !== undefined) {\n          if (options.segmentIndex < 0 || options.segmentIndex >= options.segmentCount) {\n            throw new Error(`segmentIndex must be between 0 and ${options.segmentCount - 1}`)\n          }\n        }\n      }\n\n      const data = await post(this.fetch, `${this.url}/ListVectors`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Queries for similar vectors using approximate nearest neighbor search */\n  async queryVectors(options: QueryVectorsOptions): Promise<ApiResponse<QueryVectorsResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/QueryVectors`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Deletes vectors by their keys in batch (1-500 per request) */\n  async deleteVectors(options: DeleteVectorsOptions): Promise<ApiResponse<undefined>> {\n    try {\n      // Validate batch size\n      if (options.keys.length < 1 || options.keys.length > 500) {\n        throw new Error('Keys batch size must be between 1 and 500 items')\n      }\n\n      const data = await post(this.fetch, `${this.url}/DeleteVectors`, options, {\n        headers: this.headers,\n      })\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n}\n","import { DEFAULT_HEADERS } from './constants'\nimport { isStorageVectorsError } from './errors'\nimport { Fetch, post } from './fetch'\nimport { resolveFetch } from './helpers'\nimport {\n  ApiResponse,\n  VectorBucket,\n  ListVectorBucketsOptions,\n  ListVectorBucketsResponse,\n} from './types'\n\n/**\n * @hidden\n * Base implementation for vector bucket operations.\n * Use {@link StorageVectorsClient} via `supabase.storage.vectors` instead.\n */\nexport default class VectorBucketApi {\n  protected url: string\n  protected headers: { [key: string]: string }\n  protected fetch: Fetch\n  protected shouldThrowOnError = false\n\n  /** Creates a new VectorBucketApi instance */\n  constructor(url: string, headers: { [key: string]: string } = {}, fetch?: Fetch) {\n    this.url = url.replace(/\\/$/, '')\n    this.headers = { ...DEFAULT_HEADERS, ...headers }\n    this.fetch = resolveFetch(fetch)\n  }\n\n  /** Enable throwing errors instead of returning them in the response */\n  public throwOnError(): this {\n    this.shouldThrowOnError = true\n    return this\n  }\n\n  /** Creates a new vector bucket */\n  async createBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/CreateVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Retrieves metadata for a specific vector bucket */\n  async getBucket(vectorBucketName: string): Promise<ApiResponse<{ vectorBucket: VectorBucket }>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/GetVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Lists vector buckets with optional filtering and pagination */\n  async listBuckets(\n    options: ListVectorBucketsOptions = {}\n  ): Promise<ApiResponse<ListVectorBucketsResponse>> {\n    try {\n      const data = await post(this.fetch, `${this.url}/ListVectorBuckets`, options, {\n        headers: this.headers,\n      })\n      return { data, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n\n  /** Deletes a vector bucket (must be empty first) */\n  async deleteBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    try {\n      const data = await post(\n        this.fetch,\n        `${this.url}/DeleteVectorBucket`,\n        { vectorBucketName },\n        { headers: this.headers }\n      )\n      return { data: data || {}, error: null }\n    } catch (error) {\n      if (this.shouldThrowOnError) {\n        throw error\n      }\n      if (isStorageVectorsError(error)) {\n        return { data: null, error }\n      }\n      throw error\n    }\n  }\n}\n","import VectorIndexApi, { CreateIndexOptions } from './VectorIndexApi'\nimport VectorDataApi from './VectorDataApi'\nimport { Fetch } from './fetch'\nimport VectorBucketApi from './VectorBucketApi'\nimport {\n  ApiResponse,\n  DeleteVectorsOptions,\n  GetVectorsOptions,\n  ListIndexesOptions,\n  ListVectorsOptions,\n  ListVectorBucketsOptions,\n  ListVectorBucketsResponse,\n  PutVectorsOptions,\n  QueryVectorsOptions,\n  VectorBucket,\n} from './types'\n\n/**\n *\n * @alpha\n *\n * Configuration options for the Storage Vectors client\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport interface StorageVectorsClientOptions {\n  /**\n   * Custom headers to include in all requests\n   */\n  headers?: { [key: string]: string }\n  /**\n   * Custom fetch implementation (optional)\n   * Useful for testing or custom request handling\n   */\n  fetch?: Fetch\n}\n\n/**\n *\n * @alpha\n *\n * Main client for interacting with S3 Vectors API\n * Provides access to bucket, index, and vector data operations\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n *\n * **Usage Patterns:**\n *\n * ```typescript\n * const { data, error } = await supabase\n *  .storage\n *  .vectors\n *  .createBucket('embeddings-prod')\n *\n * // Access index operations via buckets\n * const bucket = supabase.storage.vectors.from('embeddings-prod')\n * await bucket.createIndex({\n *   indexName: 'documents',\n *   dataType: 'float32',\n *   dimension: 1536,\n *   distanceMetric: 'cosine'\n * })\n *\n * // Access vector operations via index\n * const index = bucket.index('documents')\n * await index.putVectors({\n *   vectors: [\n *     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n *   ]\n * })\n *\n * // Query similar vectors\n * const { data } = await index.queryVectors({\n *   queryVector: { float32: [...] },\n *   topK: 5,\n *   returnDistance: true\n * })\n * ```\n */\nexport class StorageVectorsClient extends VectorBucketApi {\n  /**\n   * @alpha\n   *\n   * Creates a StorageVectorsClient that can manage buckets, indexes, and vectors.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param url - Base URL of the Storage Vectors REST API.\n   * @param options.headers - Optional headers (for example `Authorization`) applied to every request.\n   * @param options.fetch - Optional custom `fetch` implementation for non-browser runtimes.\n   *\n   * @example\n   * ```typescript\n   * const client = new StorageVectorsClient(url, options)\n   * ```\n   */\n  constructor(url: string, options: StorageVectorsClientOptions = {}) {\n    super(url, options.headers || {}, options.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access operations for a specific vector bucket\n   * Returns a scoped client for index and vector operations within the bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket\n   * @returns Bucket-scoped client with index and vector operations\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * ```\n   */\n  from(vectorBucketName: string): VectorBucketScope {\n    return new VectorBucketScope(this.url, this.headers, vectorBucketName, this.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a new vector bucket\n   * Vector buckets are containers for vector indexes and their data\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Unique name for the vector bucket\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .createBucket('embeddings-prod')\n   * ```\n   */\n  async createBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return super.createBucket(vectorBucketName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves metadata for a specific vector bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket\n   * @returns Promise with bucket metadata or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .getBucket('embeddings-prod')\n   *\n   * console.log('Bucket created:', data?.vectorBucket.creationTime)\n   * ```\n   */\n  async getBucket(vectorBucketName: string): Promise<ApiResponse<{ vectorBucket: VectorBucket }>> {\n    return super.getBucket(vectorBucketName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists all vector buckets with optional filtering and pagination\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Optional filters (prefix, maxResults, nextToken)\n   * @returns Promise with list of buckets or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .listBuckets({ prefix: 'embeddings-' })\n   *\n   * data?.vectorBuckets.forEach(bucket => {\n   *   console.log(bucket.vectorBucketName)\n   * })\n   * ```\n   */\n  async listBuckets(\n    options: ListVectorBucketsOptions = {}\n  ): Promise<ApiResponse<ListVectorBucketsResponse>> {\n    return super.listBuckets(options)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes a vector bucket (bucket must be empty)\n   * All indexes must be deleted before deleting the bucket\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param vectorBucketName - Name of the vector bucket to delete\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const { data, error } = await supabase\n   *   .storage\n   *   .vectors\n   *   .deleteBucket('embeddings-old')\n   * ```\n   */\n  async deleteBucket(vectorBucketName: string): Promise<ApiResponse<undefined>> {\n    return super.deleteBucket(vectorBucketName)\n  }\n}\n\n/**\n *\n * @alpha\n *\n * Scoped client for operations within a specific vector bucket\n * Provides index management and access to vector operations\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport class VectorBucketScope extends VectorIndexApi {\n  private vectorBucketName: string\n\n  /**\n   * @alpha\n   *\n   * Creates a helper that automatically scopes all index operations to the provided bucket.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string },\n    vectorBucketName: string,\n    fetch?: Fetch\n  ) {\n    super(url, headers, fetch)\n    this.vectorBucketName = vectorBucketName\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a new vector index in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Index configuration (vectorBucketName is automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * await bucket.createIndex({\n   *   indexName: 'documents-openai',\n   *   dataType: 'float32',\n   *   dimension: 1536,\n   *   distanceMetric: 'cosine',\n   *   metadataConfiguration: {\n   *     nonFilterableMetadataKeys: ['raw_text']\n   *   }\n   * })\n   * ```\n   */\n  override async createIndex(options: Omit<CreateIndexOptions, 'vectorBucketName'>) {\n    return super.createIndex({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists indexes in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Listing options (vectorBucketName is automatically set)\n   * @returns Promise with response containing indexes array and pagination token or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * const { data } = await bucket.listIndexes({ prefix: 'documents-' })\n   * ```\n   */\n  override async listIndexes(options: Omit<ListIndexesOptions, 'vectorBucketName'> = {}) {\n    return super.listIndexes({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves metadata for a specific index in this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index to retrieve\n   * @returns Promise with index metadata or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * const { data } = await bucket.getIndex('documents-openai')\n   * console.log('Dimension:', data?.index.dimension)\n   * ```\n   */\n  override async getIndex(indexName: string) {\n    return super.getIndex(this.vectorBucketName, indexName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes an index from this bucket\n   * Convenience method that automatically includes the bucket name\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index to delete\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const bucket = supabase.storage.vectors.from('embeddings-prod')\n   * await bucket.deleteIndex('old-index')\n   * ```\n   */\n  override async deleteIndex(indexName: string) {\n    return super.deleteIndex(this.vectorBucketName, indexName)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access operations for a specific index within this bucket\n   * Returns a scoped client for vector data operations\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param indexName - Name of the index\n   * @returns Index-scoped client with vector data operations\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   *\n   * // Insert vectors\n   * await index.putVectors({\n   *   vectors: [\n   *     { key: 'doc-1', data: { float32: [...] }, metadata: { title: 'Intro' } }\n   *   ]\n   * })\n   *\n   * // Query similar vectors\n   * const { data } = await index.queryVectors({\n   *   queryVector: { float32: [...] },\n   *   topK: 5\n   * })\n   * ```\n   */\n  index(indexName: string): VectorIndexScope {\n    return new VectorIndexScope(\n      this.url,\n      this.headers,\n      this.vectorBucketName,\n      indexName,\n      this.fetch\n    )\n  }\n}\n\n/**\n *\n * @alpha\n *\n * Scoped client for operations within a specific vector index\n * Provides vector data operations (put, get, list, query, delete)\n *\n * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n */\nexport class VectorIndexScope extends VectorDataApi {\n  private vectorBucketName: string\n  private indexName: string\n\n  /**\n   *\n   * @alpha\n   *\n   * Creates a helper that automatically scopes all vector operations to the provided bucket/index names.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string },\n    vectorBucketName: string,\n    indexName: string,\n    fetch?: Fetch\n  ) {\n    super(url, headers, fetch)\n    this.vectorBucketName = vectorBucketName\n    this.indexName = indexName\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Inserts or updates vectors in this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Vector insertion options (bucket and index names automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * await index.putVectors({\n   *   vectors: [\n   *     {\n   *       key: 'doc-1',\n   *       data: { float32: [0.1, 0.2, ...] },\n   *       metadata: { title: 'Introduction', page: 1 }\n   *     }\n   *   ]\n   * })\n   * ```\n   */\n  override async putVectors(options: Omit<PutVectorsOptions, 'vectorBucketName' | 'indexName'>) {\n    return super.putVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Retrieves vectors by keys from this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Vector retrieval options (bucket and index names automatically set)\n   * @returns Promise with response containing vectors array or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.getVectors({\n   *   keys: ['doc-1', 'doc-2'],\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async getVectors(options: Omit<GetVectorsOptions, 'vectorBucketName' | 'indexName'>) {\n    return super.getVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Lists vectors in this index with pagination\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Listing options (bucket and index names automatically set)\n   * @returns Promise with response containing vectors array and pagination token or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.listVectors({\n   *   maxResults: 500,\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async listVectors(\n    options: Omit<ListVectorsOptions, 'vectorBucketName' | 'indexName'> = {}\n  ) {\n    return super.listVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Queries for similar vectors in this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Query options (bucket and index names automatically set)\n   * @returns Promise with response containing matches array of similar vectors ordered by distance or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * const { data } = await index.queryVectors({\n   *   queryVector: { float32: [0.1, 0.2, ...] },\n   *   topK: 5,\n   *   filter: { category: 'technical' },\n   *   returnDistance: true,\n   *   returnMetadata: true\n   * })\n   * ```\n   */\n  override async queryVectors(\n    options: Omit<QueryVectorsOptions, 'vectorBucketName' | 'indexName'>\n  ) {\n    return super.queryVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Deletes vectors by keys from this index\n   * Convenience method that automatically includes bucket and index names\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @param options - Deletion options (bucket and index names automatically set)\n   * @returns Promise with empty response on success or error\n   *\n   * @example\n   * ```typescript\n   * const index = supabase.storage.vectors.from('embeddings-prod').index('documents-openai')\n   * await index.deleteVectors({\n   *   keys: ['doc-1', 'doc-2', 'doc-3']\n   * })\n   * ```\n   */\n  override async deleteVectors(\n    options: Omit<DeleteVectorsOptions, 'vectorBucketName' | 'indexName'>\n  ) {\n    return super.deleteVectors({\n      ...options,\n      vectorBucketName: this.vectorBucketName,\n      indexName: this.indexName,\n    })\n  }\n}\n","import StorageFileApi from './packages/StorageFileApi'\nimport StorageBucketApi from './packages/StorageBucketApi'\nimport StorageAnalyticsClient from './packages/StorageAnalyticsClient'\nimport { Fetch } from './lib/fetch'\nimport { StorageVectorsClient } from './lib/vectors'\n\nexport interface StorageClientOptions {\n  useNewHostname?: boolean\n}\n\nexport class StorageClient extends StorageBucketApi {\n  /**\n   * Creates a client for Storage buckets, files, analytics, and vectors.\n   *\n   * @category File Buckets\n   * @example\n   * ```ts\n   * import { StorageClient } from '@supabase/storage-js'\n   *\n   * const storage = new StorageClient('https://xyzcompany.supabase.co/storage/v1', {\n   *   apikey: 'public-anon-key',\n   * })\n   * const avatars = storage.from('avatars')\n   * ```\n   */\n  constructor(\n    url: string,\n    headers: { [key: string]: string } = {},\n    fetch?: Fetch,\n    opts?: StorageClientOptions\n  ) {\n    super(url, headers, fetch, opts)\n  }\n\n  /**\n   * Perform file operation in a bucket.\n   *\n   * @category File Buckets\n   * @param id The bucket id to operate on.\n   *\n   * @example\n   * ```typescript\n   * const avatars = supabase.storage.from('avatars')\n   * ```\n   */\n  from(id: string): StorageFileApi {\n    return new StorageFileApi(this.url, this.headers, id, this.fetch)\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access vector storage operations.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Vector Buckets\n   * @returns A StorageVectorsClient instance configured with the current storage settings.\n   */\n  get vectors(): StorageVectorsClient {\n    return new StorageVectorsClient(this.url + '/vector', {\n      headers: this.headers,\n      fetch: this.fetch,\n    })\n  }\n\n  /**\n   *\n   * @alpha\n   *\n   * Access analytics storage operations using Iceberg tables.\n   *\n   * **Public alpha:** This API is part of a public alpha release and may not be available to your account type.\n   *\n   * @category Analytics Buckets\n   * @returns A StorageAnalyticsClient instance configured with the current storage settings.\n   */\n  get analytics(): StorageAnalyticsClient {\n    return new StorageAnalyticsClient(this.url + '/iceberg', this.headers, this.fetch)\n  }\n}\n"],"names":["RouteKind","patchFetch","getRequestMeta","NodeNextResponse","signalFromNodeResponse","sendResponse","getCacheControlHeader","NEXT_CACHE_TAGS_HEADER","NoFallbackError","CachedRouteKind","userland","DEFAULT_AUTH_OPTIONS: SupabaseAuthClientOptions","DEFAULT_REALTIME_OPTIONS: RealtimeClientOptions","resolveFetch","resolveResponse","workUnitAsyncStorage","result: Record<string, any>","process","isPlainObject","count: number | null","res","this","fetch","DEFAULT_AUTH_OPTIONS","DEFAULT_REALTIME_OPTIONS","DEFAULT_GLOBAL_OPTIONS","result: Required<SupabaseClientOptions<SchemaName>>","DEFAULT_DB_OPTIONS","handleError","_getErrorMessage","_getRequestParams","params: { [k: string]: any }","namespaceToPath","_handleRequest","supabaseUrl: string","post","downloadFn: () => Promise<Response>","shouldThrowOnError: boolean","SupabaseStorageClient","DEFAULT_FILE_OPTIONS: FileOptions","headers: Record<string, string>","_queryString: string[]","params: string[]","DEFAULT_HEADERS","method: 'HEAD' | 'GET' | 'POST'","body: unknown | undefined","params: Record<string, string>"],"mappings":"6CwByDE,EvBzDF,IAAA,EAAA,EAAA,CAAA,CAAA,AuB0DsE,OvBzDtE,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,EAAA,CAAA,CAAA,OACA,EAAA,CAAA,CAAA,OAAA,IAAA,EAAA,EAAA,CAAA,CAAA,KDVA,EAAA,EAAA,CAAA,CAAA,qCKDA,cAA4C,kBAkB9B,CAAA,CAA2E,CACrF,KAAA,CAAM,EAAA,OAAA,OACD,IAAA,CAAA,sBACA,OAAA,CAAA,EAAA,OAAA,iBACe,MACf,IAAA,CAAO,EAAQ,IAAA,GGjBxB,EAAA,MAgCE,AAxBF,YAwBc,CAAA,CAAA,cAlBF,kBAAA,EAAqB,OA6BxB,MAAA,CAAA,EAAiB,MAAA,UACX,EAAQ,GAAA,MACd,OAAA,CAAU,IAAA,QAAA,EAAoB,OAAA,OAC9B,MAAA,CAAS,EAAQ,MAAA,MACjB,IAAA,CAAO,EAAQ,IAAA,EG7CJ,IH8CX,kBAAA,CAAA,MAAA,CAAA,EAAqB,EAAQ,kBAAA,GAAA,OAC7B,MAAA,CAAA,EAAiB,KLkCC,CAAA,EKnCiC,IAEnD,aAAA,CAAA,MAAA,CAAA,EAAgB,EAAQ,aAAA,GAAA,EAEzB,CAFyB,CAEjB,KAAA,CACV,CAH2B,GAG3B,CAAK,KAAA,CAAQ,EAAQ,CAHuB,IAGvB,CAErB,IAAA,CAAK,GALsB,EAKtB,CAAQ,EALc,IAe/B,cAAqE,QACnE,IAAA,CAAK,kBAAA,EAAqB,EACnB,IAAA,CAMT,UAAU,CAAA,CAAc,CAAA,CAAA,QACtB,IAAA,CAAK,OAAA,CAAU,IAAI,QAAQ,IAAA,CAAK,OAAA,OAC3B,OAAA,CAAQ,GAAA,CAAI,EAAM,MAAM,EAI/B,KAME,CAAA,CAQA,CAAA,CACkC,WAEd,GG1DH,GAAA,GH0Dc,CAA3B,AAA2B,IAA3B,CAAK,MAAA,GAEE,CAAC,MAAO,OAAO,CAAC,QAAA,CAAS,IAAA,CAAK,MAAA,CAAO,CAC9C,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,iBAAkB,IAAA,CAAK,MAAA,CAAO,MAE1C,OAAA,CAAQ,GAAA,CAAI,kBAAmB,IAAA,CAAK,MAAA,CAAO,EAE9B,aAAX,MAAA,EAAoC,OAC3C,EAD2B,IAAA,CAAK,MAAA,EAChC,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,eAAgB,mBAAmB,CAMtD,IAAA,EAAA,GADe,CGnEP,GAAA,CAAA,KAAA,EHoER,IAAA,CAAsB,CGnEP,EAAA,CHmEW,QAAA,GAAA,CACxB,OAAA,IAAA,CAAA,MAAA,CACA,QAAS,IAAA,CAAK,IGlEN,GAAA,CHmER,KAAM,KAAK,SAAA,CAAU,IAAA,CAAK,IAAA,CAAK,CGlET,AHmEtB,OAAQ,IAAA,CAAA,MAAA,GACP,IAAA,CAAA,MAAY,oBACT,EAAQ,KACZ,EAAA,KACImB,EAAuB,KACvB,EAASC,EAAI,MAAA,CACb,EAAaA,EAAI,UAAA,IAEjBA,EAAI,EAAA,CAAI,IACU,WAAX,MAAA,CAAmB,CAC1B,IAAM,EAAO,MAAMA,EAAI,IAAA,EAAM,CAChB,KAAT,IAGF,EADwC,KACjC,MAAP,EADSC,EAAK,EIxIkC,KJwIlC,CAAQ,GAAA,CAAI,SAAS,EAGnCA,EAAK,CIzIb,MJyIa,CAAQ,GAAA,CAAI,YAAS,CAAA,MAAA,EAC1BA,CI1I2C,CJ0ItC,OAAA,CAAQ,GAAA,CAAI,SAAA,CAAS,CAAA,KAAA,EAAA,EAAE,IAAF,IAAE,CAAS,iBAAX,KAAA,YAAW,CAAkC,CAEhE,CAAP,CAAA,AAEO,KAAK,KAAA,CAAM,QAIhB,EAAA,MAAA,CAAA,EAAcA,EAAK,OAAA,CAAQ,GAAA,CAAI,SAAA,CAAS,CAAA,KAAA,EAAA,EAAE,IAAF,CAAE,CAAM,qBAAR,KAAA,QAA0C,CAClF,EAAA,MAAA,CAAA,EAAeD,EAAI,OAAA,CAAQ,GAAA,CAAI,gBAAA,CAAgB,CAAA,KAAA,EAAA,EAAE,IAAF,CAAE,CAAM,IAAI,CAC7D,GAAe,GAAgB,EAAa,MADK,AACL,CAAS,EACvD,EAFmD,AAEnD,EAAQ,SAAS,CAAA,CAAa,GAAA,CAAG,CAK/BC,EAAK,aAAA,EAAiC,QAAhBA,CK/ID,CL+IM,MAAA,EAAoB,MAAM,OAAA,CAAQ,KAC3D,AADgE,CACpE,CAAS,AAAT,MAAS,CAAS,GAAG,GAGjB,KAAM,WACN,QAAA,CAAA,gBAAA,EAA4B,EAAK,MAAA,CAAO,uDAAA,CAAA,CACxC,KAAM,KACN,QAAS,2DAEJ,OACC,OACC,IACT,EAAa,kBAEb,EADyB,IAAhB,EAAA,MAAK,CACP,CAAA,CAAK,EAAA,CAEL,GKhJR,OLmJE,OACQ,MAAMD,EAAAA,IAAAA,MAEf,cACiB,EK9IX,OLiJE,OAAA,CAAQ,IAAyB,EAAnB,GAAwB,CAApBA,EAAAA,MAAI,KACvB,EAAA,gBAGM,cAET,CAEa,MAAfA,EAAI,MAAA,EAAkB,UACf,MACI,yBAGF,MAKX,GAASC,EAAAA,aAAAA,EAAAA,CAAAA,MAAAA,GAA6B,MAA7BA,CAAAA,EAAsB,EAAO,OAAA,CAAA,CAAA,IAAA,CAAA,EAAA,EAAS,QAAA,CAAS,SAAA,CAAS,GAAE,SAE5D,MACI,SAGFA,EAAAA,kBAAAA,CACX,MAAM,IAAI,EAAe,CKpJM,QLwJT,OACxB,iDASA,AAAC,IAAA,CAAA,kBAAA,GACH,EAAM,EAAI,KAAA,CAAA,AAAO,SKvJoB,WL2JnC,IAAI,EAAe,GAGb,EAAA,MAAA,EAAA,KAAA,EAAQ,EAAY,KAAA,CAC1B,GAAI,EAAO,CACT,AK5JA,IL4JM,EAAA,MAAA,CAAA,EAAA,MAAA,EAAA,KAAA,EAAe,EAAO,OAAA,EAAA,EAAW,EAAX,CACtB,EAAA,KADsB,CACtB,CAAA,EAAA,MAAA,EAAA,KAAA,EADsB,AACV,EAAO,GADG,CACH,EAAA,EAAQ,EAAR,QAAA,SAGT,CAAA,MAHS,KAAA,CAEP,EAAY,IAAA,EAAA,EAAQ,aAAa,EAAA,EAAA,QAAA,KAAA,EAAI,EAAY,OAAA;AACnD;AAAA,WAAA,EAAA,MAAA,CAAA,EAAA,MAAA,EAAA,KAAA,EAAkB,EAAO,IAAA,EAAA,EAAQ,EAAR,MAAgB,EAAhB,AAAgB,EAAI,EAAA,CAAA,AADM,KAGjE,GAAA,CAAA,EAFuC,AAEvC,EAAqB,EAAU,CAFQ,CAER,IOpNtC,cPsNS,EAAO,KAAA,GACT,IAAgB,CAAA;AAAA,EAAK,EAAM,KAAA,CAAA,CAAA,QAExB,yBAEU,EAAY,KAAA,EAAA,EAAS,EAAT,OAGtB,CAHsB,AAI3B,MAAO,CACL,QAAS,CAAA,EAAA,IALgB,EAKhB,CAAA,EAAA,AALgB,MAKhB,EAAA,KAAA,EAAG,EAAY,IAAA,EAAA,EAAQ,EAAR,QAAA,GAAqB,EAAA,QAAA,EAAA,KAAA,EAAI,AAAzB,EAAqC,GAArC,CAAqB,GAAgB,CAAA,CAAA,CAC7D,EAD6C,MACpC,EACT,KAAM,EAFuC,CAG7C,IAH6C,CAGvC,IAER,KAAM,KACN,MAAO,KACP,EUnPD,KVmPS,aACI,OAKX,EAAI,IAAA,CAAK,EAAA,GASlB,SAAA,aAmCA,eAAA,CAaE,OAAO,IAAA,mBYlTD,EAUR,OAIE,CAAA,CAAA,KAeI,GAAS,EACb,EAAA,OAAwB,EAAA,EAAW,GAAA,EAChC,KAAA,CAAM,GAAG,CACT,GAAA,CAAA,GACK,KAAK,IAAA,CAAK,EAAE,EAAI,CAAA,EACX,IAEC,UACR,EAAS,CAAC,CAAA,EAEL,IAER,IAAA,CAAK,gBACH,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,SAAU,GACpC,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,SAAU,yBACvB,IAAA,CFsCH,MEkBJ,CAAA,CACA,WACE,GAAY,CAAA,CACZ,YAAA,cACA,CAAA,iBACA,EAAkB,CAAA,CAAA,CAMhB,CAAA,CAAE,CACA,KACA,EAAM,EAAkB,CAAA,EAAA,EAAmB,MAAA,CAAA,CAAU,UACrC,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,IAAI,WAE/C,GAAA,CAAI,YAAA,CAAa,GAAA,CACpB,EAAA,CAAA,EACG,EAAgB,CAAA,EAAG,EAAc,CAAA,CAAA,CAAK,GAAA,EAAK,EAAO,CAAA,EAAG,EAAY,MAAQ,OAAA,EAC3D,KAAA,IAAf,EAA2B,GAAK,EAAa,cAAgB,aAAA,CAAA,CAEhE,CACM,IAAA,CAaT,MACE,CAAA,CACA,cACE,CE/DI,iBFgEJ,EAAkB,CAAA,CAAA,CACqC,CAAA,CAAE,CACrD,CACN,IAAA,EAAY,KAA2B,IAApB,EAAkC,QAAU,CAAA,EAAG,EAAgB,MAAA,CAAA,CAElF,OADA,IAAA,CAAK,GAAA,CAAI,EEjEP,UAAA,CFiEoB,GAAA,CAAI,EAAK,CAAA,EAAG,EAAA,CAAA,CAAQ,CACnC,IAAA,CAkBT,MACE,CAAA,CACA,CAAA,CACA,cACE,CAAA,iBACA,EAAkB,CjByRhB,CAAA,CiBxRqD,CAAA,CAAE,CACrD,AjBuRF,CiBtRJ,IAAM,EACJ,KAA2B,IAA3B,EAAyC,SAAW,CAAA,EAAG,EAAgB,OAAA,CAAA,CACnE,EAAW,KAA2B,IAApB,EAAkC,QAAU,CAAA,EAAG,EAAgB,MAAA,CAAA,iBAC9E,YAAA,CAAA,GAAA,CAAA,EAA4B,CAAA,EAAG,EAAA,CAAA,GjBmRkG,IiBjRrI,GAAA,CAAI,YAAA,CAAa,GAAA,CAAI,EAAU,CAAA,EAAG,EAAK,EAAO,EAAA,CAAA,CAAI,CAChD,IAAA,CAQT,YAAY,CAAA,CAA2B,aAChC,MAAA,CAAS,EACP,IAAA,CAST,QAGE,QACA,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,SAAU,qCACpB,IAAA,CAST,aAAA,OAKsB,oBAClB,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,SAAU,CH2GI,kBG3Ge,CAE9C,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,SAAU,0CAExB,aAAA,CAAA,CAAA,EACE,IAAA,CAMT,KAA+C,CAE7C,YADK,OAAA,CAAQ,GAAA,CAAI,SAAU,YACpB,IAAA,CAMT,SAAoE,aAC7D,OAAA,CAAQ,GAAA,CAAI,SAAU,4BACpB,CA4BT,QAAQ,SACN,GAAU,CAAA,CACV,WAAU,CAAA,UACV,EAAW,EAAA,SACX,GAAU,CAAA,KACV,GAAM,CAAA,QACN,EAAS,MAAA,CAAA,CAQP,CAAA,CAAE,CAAE,OACN,IAAM,EAAU,CACd,EAAU,UAAY,KACtB,EAAU,UAAY,KACtB,EAAW,WAAa,KACxB,EAAU,UAAY,KACtB,EAAM,MAAQ,KACf,CACE,MAAA,CAAO,QAAQ,CACf,IAAA,CAAK,IAAI,CAEN,EAAA,MAAA,GAAe,IAAA,CAAK,OAAA,CAAQ,GAAA,CAAI,SAAA,CAAS,CAAA,EAAI,GAAJ,QAAA,eAC/C,IAAA,CAAK,EAD0C,KAAA,AAC1C,CAAQ,GAAA,CACX,SACA,CAAA,2BAAA,EAA8B,EAAO,OAAA,EAAS,EAAa,WAAA,EAAa,EAAQ,CAAA,CAAA,CACjF,CAEQ,IAAA,YAaT,mBADK,CAAQ,MAAA,CAAO,SAAU,eACvB,IAAA,CAST,CI/PE,QJuQA,CACA,OAAO,IAAA,CAiBT,YAAY,CAAA,CAKiE,QAC3E,IAAA,CAAK,OAAA,CAAQ,MAAA,CAAO,SAAU,kBAAkB,MAC3C,OAAA,CAAQ,MAAA,CAAO,SAAU,CAAA,aAAA,EAAgB,EAAA,CAAA,CAAQ,CAC/C,IAAA,GK3UX,IAAM,EAA+B,AAAI,OAAO,QAAQ,KA2CnC,EAArB,OA3CM,OAmDI,EAiBR,GACE,CArEE,AAqEF,CACA,CAAA,CAQM,aACD,GAAA,CApBP,AAoBW,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CAC5C,IAAA,CAST,IACE,CAAA,CACA,CAAA,CAKM,QACN,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAA,CAAA,CAAQ,CAC7C,IAAA,CAWT,GAAG,CAAA,CAAgB,CAAA,CAAsB,aAClC,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,MAYrD,IAAI,CAAA,CAAgB,CAAA,CAAsB,aACnC,GAAA,CAAA,YAAI,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAA,CAAA,CAAQ,CAC7C,IAAA,CAWT,GAAA,CAAA,CAAmB,CAAA,CAAsB,aAClC,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CAC5C,IAAA,KAWL,CAAA,CAAgB,CAAA,CAAsB,aACnC,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAA,CAAA,CAAQ,CAC7C,IAAA,CAWT,KAAK,CAAA,CAAgB,CAAA,CAAuB,aACrC,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,KAAA,EAAQ,EAAA,CAAA,CAAU,CAChD,IAAA,CAcT,UAAU,CAAA,CAAgB,CAAA,CAAmC,CAE3D,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,WAAA,EAAc,EAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CAClE,IAAA,WAcC,CAAA,CAAgB,CAAA,CAAmC,CAE3D,eADK,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,WAAA,EAAc,EAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CAClE,IAAA,CAWT,MAAA,CAAA,CAAA,CAAA,CAA6C,aACtC,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,MAAA,EAAS,EAAA,CAAA,CAAU,CACjD,IAAA,CAcT,WAAW,CAAA,CAAgB,CAAA,CAAmC,iBACnD,YAAA,CAAa,IF+HK,CACvB,CAAA,CEhIyB,EAAQ,CAAA,YAAA,EAAe,EAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CACnE,IAAA,CAcT,WAAW,CAAA,CAAgB,CAAA,CAAmC,CAE5D,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,YAAA,EAAe,EAAS,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CACnE,IAAA,CAYT,WAAW,CAAA,CCvOF,CAAA,CDuOyC,aAC3C,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,MAAA,EAAS,EAAA,CAAA,CAAU,CACjD,IAAA,CAYT,YAAY,CAAA,CAAgB,CC9NrB,CD8N4C,EC9NrB,CAAA,UD+NvB,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,OAAA,EAAU,EAAA,CAAA,CAAU,MAqB3D,GAAG,CAAA,CAAgB,CAAA,CAA6B,aACzC,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,MAcrD,WACE,CAAA,CACA,CAAA,CAKM,CAEN,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,WAAA,EAAc,EAAA,CAAA,CAAQ,CACpD,IAAA,CAST,GACE,CAAA,CACA,CAAA,CAUM,CACN,IAAM,EAAgB,MAAM,IAAA,CAAK,IAAI,IAAI,IACtC,GAD6C,AAC7C,CAAK,AADyC,AAC9C,GAGC,AAAiB,GAHP,OAGN,OAAO,GAAkB,EAA6B,IAAA,CAAK,EAAE,CAAE,AAAO,CAAP,AAAO,CAAA,EAAI,EAAE,CAAA,CAAA,CACpE,CAAA,EAAG,EAAA,CAAA,EAEhB,IAAA,CAAK,IAAI,CAEZ,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAc,CAAA,CAAA,CAAG,CACtD,IAAA,CAST,MACE,CAAA,CACA,CAAA,CAAA,CAQA,IAAM,EAAgB,MAAA,IAAM,CAAK,IAAI,IAAI,IACtC,GAD6C,AAC7C,CAD8C,AAC9C,AAAK,GAGJ,AAAiB,GAHP,OAGN,OAAO,GAAkB,EAA6B,IAAA,CAAK,EAAE,CAAE,AAAO,CAAP,AAAO,CAAA,EAAI,EAAE,CAAA,CAAA,CACpE,CAAA,EAAG,EAAA,CAAA,EACf,IAAA,CACI,IAAI,CAEZ,OADA,IAAA,CAAA,GAAA,CAAS,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,QAAA,EAAW,EAAc,CAAA,CAAA,CAAG,CAC1D,IAAA,CAeT,SAAS,CAAA,CAAgB,CAAA,CAAoE,CAY3F,MAXqB,AAAjB,SAGF,QAHS,EAGT,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CAC1C,MAAM,OAAA,CAAQ,GAEvB,GAF6B,CAE7B,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CAG/D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,KAAK,SAAA,CAAU,GAAM,CAAA,CAAG,CAAH,AAE3D,IAAA,CAeT,YAAY,CAAA,CAAgB,CAAA,CAAoE,CAW9F,MAVqB,SAEnB,CAFE,OAAO,EAET,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CAC1C,MAAM,OAAA,CAAQ,GAEvB,GAF6B,CAE7B,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CAG/D,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,KAAK,SAAA,CAAU,GAAM,CAAA,CAAG,CAE9D,AAF2D,IAE3D,CAYT,QAAQ,CAAA,CAAgB,CAAA,CAAqB,CAE3C,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CAC5C,IAAA,CAaT,SAAS,CAAA,CAAA,CAAA,CAAA,CAEP,OADA,IAAA,CAAK,GAAA,CAAA,YAAA,CAAiB,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAA,CAAA,CAAQ,CAC7C,IAAA,SAYD,CAAA,CAAgB,CAAA,CAAqB,CAE3C,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CAC5C,IAAA,CAaT,SAAS,CAAA,CAAgB,CAAA,CAAqB,CAE5C,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAA,CAAA,CAAQ,CAC7C,IAAA,CAaT,cAAc,CAAA,CAAgB,CAAA,CAAqB,CAEjD,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAA,CAAA,CAAQ,CAC7C,IAAA,CAeT,SAAS,CAAA,CAAgB,CAAA,CAA0C,CAQjE,MAPqB,SAEnB,CAFE,OAAO,EAET,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,CAGnD,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAG,CAE1D,IAAA,CAuBT,WACE,CAAA,CACA,CAAA,CACA,QAAE,CAAA,MAAQ,CAAA,CAAA,CAAuE,CAAA,CAAE,CAC7E,CACN,IAAI,EAAW,EACX,CAAS,YAAA,EACA,KACO,SAClB,EADS,EACT,EAAW,KACO,YAClB,EADS,IACT,EAAW,GAAA,EAEb,IAAM,EAAwB,KAAA,IAAX,EAAW,GAAiB,CAAA,CAAA,EAAI,EAAO,CAAA,CAAA,CAE1D,OADA,IAAA,CAAA,GAAK,CAAI,YAAA,CAAa,MAAA,CAAO,EAAA,CAAA,EAAW,EAAA,GAAA,EAAc,EAAW,CAAA,EAAA,EAAA,CAAA,EACjE,IAAA,CAYF,MAAM,CAAA,CAAsC,CAI1C,OAHA,OAAO,OAAA,CAAQ,GAAO,GAAD,IAAC,CAAA,CAAS,CAAC,EAAQ,EAAA,IACtC,CADiD,AF2EnB,GAAA,CE1EzB,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,GAAA,EAAM,EAAA,CAAA,CAAQ,GAE9C,IAAA,CAsBT,IAAI,CAAA,CAAgB,CAAA,CAAkB,CAAA,CAAsB,CAE1D,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,IAAA,EAAO,EAAS,CAAA,EAAG,EAAA,CAAA,CAAQ,CACzD,IAAA,CAkBT,GACE,CAAA,CACA,cACE,CAAA,iBACA,EAAkB,CAAA,CAAA,CACqC,CAAA,CAAE,CACrD,CACN,IAAM,EAAM,EAAkB,CAAA,EAAG,EAAgB,GAAA,CAAA,CAAO,KAExD,OADA,IAAA,CAAK,GAAA,CAAI,YAAA,CAAa,MAAA,CAAO,EAAK,CAAA,CAAA,EAAI,EAAQ,CAAA,CAAA,CAAG,CAC1C,IAAA,CAsBT,OAAO,CAAA,CAAgB,CAAA,CAAkB,CAAA,CAAsB,iBACpD,YAAA,CAAa,MAAA,CAAO,EAAQ,CAAA,EAAG,EAAS,CAAA,EAAG,EAAA,CAAA,CAAQ,CACrD,IAAA,GElqBU,EAArB,MAME,AAoBA,YACE,CAAA,CACA,CACE,UAAU,CAAA,CAAE,QACZ,CAAA,CACA,MAAA,CAAA,CAAA,CAMF,CACA,IAAA,CAAK,GAAA,CAAM,EACX,IAAA,CAAK,OAAA,CAAU,IAAI,QAAQ,GAC3B,IAAA,CADmC,AAC9B,MAAA,CAAS,EACd,IAAA,CAAK,KAAA,CAAQC,EAMf,mBAA4D,CAC1D,MAAO,CACL,IAAK,IAAI,IAAI,IAAA,CAAK,GAAA,CAAI,QAAA,EAAU,CAAC,CACjC,QAAS,IAAI,QAAQ,IAAA,CAAK,OAAA,CAAQ,CACnC,QAmCD,CAAA,CACA,CAAA,CAYA,CACA,GAAM,MAAE,GAAO,CAAA,OAAO,CAAA,CAAA,OAAU,EAAA,EAAW,CAAA,CAAE,CAIzC,GAAS,EACP,AAL0B,EAK1B,MAL0B,CAKR,EAAA,EAAW,GAAA,CAAA,CAChC,EAN6B,CAKR,EACrB,CAAM,CANuB,EAMpB,CACT,CAFqB,EAErB,CAAK,AAAL,GACK,AAAJ,GADU,EACD,CAHW,GAGX,CAAK,CAHM,CAGJ,EAAI,CAAC,EACZ,IAEL,AAAM,CAFR,CAAA,GAGA,KAAA,EAAS,CAAC,CAAA,EAEL,IAER,IAAA,CAAK,GAAG,CAEL,KAAE,CAAA,SAAK,CAAA,CAAA,CAAY,IAAA,CAAK,iBAAA,EAAmB,CAOjD,OANA,EAAI,YAAA,CAAa,GAAA,CAAI,SAAU,GAE3B,GACF,EAAQ,CAAR,KAAQ,CAHoC,AAG7B,SAAU,CAAA,MAAA,EAAS,EAAA,CAAA,CAAQ,CAGrC,IAAI,EAAuB,CAChC,OAxBa,EAAO,OAAS,UAyB7B,UACA,EACA,OAAQ,IAAA,CAAA,MAAK,CACb,MAAO,IAAA,CAAK,KAAA,GA4DhB,OACE,CAAA,CACA,CACE,OAAA,eACA,GAAgB,CAAA,CAAA,CAId,CAAA,CAAE,CASN,eAEQ,CAAA,SAAK,CAAA,CAAA,CAAY,IAAA,CAAK,iBAAA,MAE9B,GACE,EAAQ,MAAA,CAAO,SAAU,CAAA,MAAA,EAAS,EAAA,CAAA,CAAQ,CAExC,AAAC,GAAA,EACK,MAAA,CAAO,SAAU,CAAA,kBAGvB,MAAM,OAAA,CAAQ,GAAS,CACzB,GADuB,CACjB,EAAU,EAAO,MAAA,CAAA,CAAQ,EAAK,IAAM,EAAI,MAAA,CAAO,OAAO,IAAA,CAAK,EAAE,CAAC,CAAE,EAAE,CAAa,CACrF,GAAI,EAAQ,MAAA,CAAS,EAAG,CACtB,IAAM,EAAgB,CAAC,GAAG,IAAI,IAAI,GAAS,CAAC,GAAA,CAAF,AAAE,AAAK,GAAW,CAAA,CAAA,EAAI,EAAO,CAAA,CAAA,CAAG,CAC1E,EAAI,YAAA,CAAa,GAAA,CAAI,UAAW,EAAc,IAAA,CAAK,IAAI,CAAC,EAI5D,OAAO,IAAI,EAAuB,CAChC,OAnBa,WAoBb,UACA,EACA,OAAQ,IAAA,CAAK,MAAA,CACb,KAAM,EACN,MAAA,MAAA,CAAA,EAAO,IAAA,CAAK,KAAA,EAAA,EAAS,EAAT,IACb,CAAC,GADY,KA6Hd,CAAA,CACA,SA9Hc,GA+HZ,CAAA,CACA,AAhIY,mBAgIO,EAAA,OACnB,CAAA,eACA,EAAgB,EAAA,CAAA,CAMd,CAAA,CAAE,CASN,OAEA,GAAM,KAAE,CAAA,SAAK,CAAA,CAAA,CAAY,IAAA,CAAK,iBAAA,EAAmB,CAYjD,GAVA,EAAQ,MAAA,CAAO,SAAU,CAAA,WAAA,EAAc,EAAmB,SAAW,QAAQ,WAAA,CAAA,EAE1D,KAAA,EAAW,EAA1B,GAA0B,EAAI,YAAA,CAAa,GAAA,CAAI,cAAe,GAC9D,GACF,EAAQ,CAAR,EAF2E,GAEnE,CAAO,SAAU,CAAA,MAAA,EAAS,EAAA,CAAA,CAAQ,CAExC,AAAC,GACH,EAAQ,MAAA,CAAO,SAAU,kBAAkB,CAGzC,MAAM,OAAA,CAAQ,GAAS,CACzB,GADuB,CACjB,EAAU,EAAO,EJuoBE,CACvB,GAAA,CAAA,CIxoB6B,EAAK,IAAM,EAAI,MAAA,CAAO,OAAO,IAAA,CAAK,EAAE,CAAC,CAAE,EAAE,CAAa,CACrF,GAAI,EAAQ,MAAA,CAAS,EAAG,CACtB,IAAM,EAAgB,CAAC,GAAG,IAAI,IAAI,GAAS,CAAC,GAAA,CAAA,AAAK,AAAP,GAAkB,CAAA,CAAA,EAAI,EAAO,CAAA,CAAA,CAAG,GACtE,YAAA,CAAa,GAAA,CAAI,UAAW,EAAc,IAAA,CAAK,IAAI,CAAC,EAI5D,OAAO,IAAI,EAAuB,CAChC,OAtBa,WAuBb,UACA,EACA,OAAQ,IAAA,CAAK,MAAA,CACb,KAAM,EACN,MAAA,MAAA,GAAO,IAAA,CAAK,KAAA,EAAA,EAAS,EAAT,IACb,CAAC,CAwBJ,EAzBgB,KA0Bd,CAAA,CACA,OACE,CAAA,CAAA,CA5BY,AA+BV,CAAA,CAAE,CASN,EAxCc,KA0Cd,GAAM,CAAE,KAAA,SAAK,CAAA,CAAA,CAAY,IAAA,CAAK,iBAAA,EAAmB,CAMjD,OAJI,GACF,EAAQ,CAAR,KAAQ,CAAO,SAAU,CAAA,MAAA,EAAS,EAAA,CAAA,CAAQ,CAGrC,IAAI,EAAuB,CAChC,OARa,YASb,UACA,EACA,OAAQ,IAAA,CAAK,MAAA,CACb,KAAM,EACN,MAAA,OAAA,EAAO,IAAA,CAAK,KAAA,EAAA,EAAS,EAAT,IACb,CAAC,CAsBJ,EAvBgB,KAuBT,OACL,CAAA,CAAA,CAGE,CAAA,CA3BY,AA2BV,CAQJ,IAnCc,GAqCd,GAAM,KAAE,CAAA,SAAK,CAAA,CAAA,CAAY,IAAA,CAAK,iBAAA,EAAmB,CAMjD,OAJI,GACF,EAAQ,CAAR,KAAQ,CAAO,SAAU,CAAA,MAAA,EAAS,EAAA,CAAA,CAAQ,CAGrC,IAAI,EAAuB,CAChC,OARa,aASb,UACA,EACA,OAAQ,IAAA,CAAK,MAAA,CACb,MAAA,MAAA,CAAA,EAAO,IAAA,CAAK,KAAA,EAAA,EAAS,EAAT,IACb,IADa,ACtfG,EAArB,MAAqB,EA6CnB,ODycgB,KCxcd,ADwcc,CCxcd,CA1BF,AA2BE,SACE,EAAU,CAAA,CAAE,QACZ,CAAA,CACA,MAAA,CAAA,CAAA,CAKE,CAAA,CAAE,CACN,MACK,GAAA,CAAM,EACX,IAAA,CAAK,OAAA,CAAU,IAAI,QAAQ,GAC3B,CLgqC+B,GKhqC/B,CAAK,AAD8B,UAC9B,CAAa,OACb,KAAA,CAAQA,EAcf,KAAK,CAAA,CAA0E,CAC7E,GAAI,CAAC,GAAgC,UAApB,OAAO,GAA6C,GACnE,EAD+C,EAAS,IAAA,EAAM,CAC9D,MAAM,AAAI,MAAM,8DAA8D,CAIhF,OAAO,IAAI,EADC,IAAI,IAAI,CAAA,EAAG,IAAA,CAAK,GAAA,CAAI,CAAA,EAAG,EAAA,CAAA,CAAW,CACR,CACpC,QAAS,IAAI,QAAQ,IAAA,CAAK,OAAA,EAC1B,OAAQ,IAAA,CAAK,UAAA,CACb,MAAO,IAAA,CAAK,KAAA,GAWhB,OACE,CAAA,CAMA,CACA,OAAO,IAAI,EAAgB,IAAA,CAAK,GAAA,CAAK,CACnC,QAAS,IAAA,CAAK,OAAA,QACd,EACA,MAAO,IAAA,CAAK,KAAA,GAoChB,IASE,CAAA,CACA,EAAa,CAAA,CAAE,CACf,CACE,QAAO,CAAA,KACP,GAAM,CAAA,OACN,CAAA,CAAA,CAKE,CAAA,CAAE,CASN,WACIsB,EAEAC,EADE,EAAM,IAAI,IAAI,CAAA,EAAG,IAAA,CAAK,GAAA,CAAI,KAAA,EAAO,EAAA,CAAA,CAAK,CAGtC,EAAA,AAAa,GACX,OAAN,GAA2B,UAAb,EAAa,KAAN,IAAmB,CAAC,MAAM,OAAA,CAAQ,EAAE,EAAI,EAAE,IAAA,CAAK,EAAA,CAAU,CAC1E,EAAgB,GAAQ,OAAO,MAAA,CAAO,GAAgB,EAAD,EAAC,CAAK,GAC7D,GACF,EAAS,EAFgE,KAGzE,EAAO,CAFU,EAGR,GAAQ,GACjB,EADsB,AACb,EAAO,OAAS,MACzB,OAAO,OAAA,CAAQ,GAGZ,EAHiB,IAGjB,CAAA,CAAQ,CAAC,EAAG,EAAA,GAAW,AAAU,KAAA,EAAU,KAE3C,GAAA,CAAA,CAAK,CAAC,EAAM,EAAA,GAAW,CAAC,EAAM,MAAM,OAAA,CAAQ,GAAS,CAAA,CAAA,CAAH,CAAO,EAAM,IAAA,CAAK,IAAI,CAAC,CAAA,CAAA,CAAK,CAAA,EAAG,EAAA,CAAA,CAAQ,CAAC,CAC1F,OAAA,CAAA,CAAS,CAAC,EAAM,EAAA,IACf,CAD0B,CACtB,YAAA,CAAa,MAAA,CAAO,EAAM,IAC9B,EADoC,CAGxC,EAAS,OACT,EAAO,GAGT,IAAM,EAAU,IAAI,QAAQ,IAAA,CAAK,OAAA,CAAQ,QACrC,EACF,EAAQ,GAAA,CAAI,MAAZ,GAAsB,EAAQ,CAAA,MAAA,EAAS,EAAM,eAAA,CAAA,CAAmB,iBAAiB,CACxE,GACT,EAAQ,CAAR,EAAQ,CAAI,SAAU,CAAA,MAAA,EAAS,EAAA,CAAA,CAAQ,CAGlC,IAAI,EAAuB,QAChC,MACA,UACA,EACA,OAAQ,IAAA,CAAK,UAAA,CACb,OACA,MAAA,MAAA,CAAA,EAAO,IAAA,CAAK,KAAA,EAAA,EAAS,EAAT,QAAA,gBAAA,KAAA,W1BvNL,EAAN,GCJE7C,IAAiB,GDIb,ECJK,EDIgB,KAAA,CAAM,AAOtC,OCVOC,IDUP,CACE,CCZ+C,ADY/C,CACA,CAAA,CAMA,KClB8B,CDmB9B,CAAM,GACN,GCpBsC,CDmBzB,AACb,CADa,AACb,IAAA,CAAY,ECjBE,aDkBd,IAAA,CAAA,ICrBoE,EDqBpE,CAAc,EAAK,EAAL,IAAK,CACnB,AClB0B,IDkB1B,CAAA,GClBkC,QDkBlC,CAAmB,ECjBE,ADiBG,KCjBK,MDiBL,CACxB,CGxB8C,GHwB9C,CAAA,WAAA,CAAmB,CCjBC,CDiBI,CCjBFE,CDiBH,ECnB4D,ODmBvD,CACxB,EClBsC,EADgC,ADmBtE,CAAK,KClByC,EDkBzC,CAAU,EAAK,EAAL,CChBC,EAClBC,EDesB,CAGpB,IAAA,CAAA,YCrB2E,EAGvD,MDkBpB,CACuB,CClBpB,YAC0D,gBDiBtC,GAArB,EAAK,EAAL,SAAK,EACJ,CAAC,IAAK,GAAA,CAAK,CCnB4C,EDmBzC,CAAA,CAAE,QAAA,CAAS,EAAK,MAAM,CAAA,EAAK,EAAK,WAAA,EAAa,QAAA,CAAS,aAAa,CAAA,IAAM,CAC5F,CAKA,EAN4F,UAMtE,QACb,AAAgB,GAAA,OAAhB,CAAA,MAAK,CAMd,YAAsB,CACpB,OAAuB,GAAA,GAAhB,IAAA,CAAK,MAAA,AACd,CAKA,CEzBG,wBFyBgC,CACjC,OAAuB,GAAA,GAAhB,IAAA,CAAK,MAAA,AACd,qBSrD8B,ERqEd,AQrEkE,ERsElFW,QQrE2B,QAAQ,GAAjB,IAAA,CAIT,aAAA,IAAA,CACA,CAAE,cAAe,CAAA,OAAA,EAAU,EAAK,EAAL,GAAU,CAAA,CAAA,CAAG,CAG/B,UAAU,CAAxB,EAAK,IAAA,EACE,CAAC,EAAK,EAAL,EAAS,CAAA,CAAG,EAAK,KAAA,CAAM,CAGjB,UAAU,GAAnB,IAAA,OACM,EAAK,UAAA,GAGpB,CAAO,CAAC,GACV,UEXS,EAAA,CAAgB,EACvB,OAAO,EAAU,IAAA,CAAK,QAGjB,IAAA,EAAA,MACL,YACmB,CAAA,CACA,EAAiB,EAAA,CAClC,KAFiB,CAAA,MAAA,CAAA,OACA,MAAA,CAAA,CAChB,uBAEkB,CAA8D,KAC3E,EAAQ,EAAS,CAAjB,AAAmB,MAAA,CAAQ,EAAgB,EAAO,SAAS,CAAA,CAAE,CAAI,KAAA,EAQvE,MAAO,CANU,MAAM,CDCG,CACxB,ECFqB,CAAK,MAAA,CAAO,OAAA,CAAgC,QACzD,MACR,KAAA,CAAA,EAAS,IAAA,CAAK,MAAM,CAAA,WAAA,CAAA,OACpB,CAAA,EACD,CAAA,CAEe,IAAA,CAAK,UAAA,CAAW,GAAA,CAAI,AAAC,EAAA,EAAQ,CAAR,AAAU,SAAA,CAAW,EAAA,CAAG,CAAE,AACjE,CADiE,AAGjE,MAAM,gBACJ,CAAA,CAAA,CACA,CACkC,OACM,CACtC,UAAW,EAAA,SAAA,CACX,WAAY,GAAU,YASxB,MAAO,CANU,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAAiC,eAElE,KAAA,CAAA,EAAS,IAAA,CAAK,MAAA,CAAM,WAAA,CAAA,MACd,KAGQ,IAAA,CAGlB,MAAM,cAAc,CAAA,CAAwC,CAC1D,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAAc,CAC9B,OAAQ,SACR,IAAA,CAAA,CAAA,EAAS,IAAA,CAAK,MAAM,CAAA,YAAA,EAAe,EAAgB,EAAA,AAAG,SAAS,CAAC,CAAA,AAA7B,CAA6B,EAEpE,CAEA,MAAM,sBAAA,CAAsB,CAAqD,CAM/E,MAAO,CACL,WAAY,CANG,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAA8B,CAC/D,OAAQ,KAAA,CACR,KAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAA,EAA+B,EAAG,AAAH,SAAY,CAAC,CAAA,CAAA,ELoJ7B,AKnJpC,CAAA,CAGsB,IAAA,CAAK,UAAA,CAE9B,CAEA,MAAM,gBAAgB,CAAA,CAA2C,IAC3D,CAKF,aAJM,IAAA,CAAA,MAAA,CAAA,OAAY,CAAc,CAC9B,OAAQ,OACR,KAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAe,EAAgB,EAAG,AAAH,ELuJrB,OKvJiC,CAAC,CAAA,CAAA,IAE3D,CACT,CAAA,EADS,IACA,EAAA,CACP,GAAI,aAAiB,GAAiC,GAAA,EAAK,CAAtB,EAAM,CAAtB,EAAgB,GAAM,QAClC,CAET,OAAM,CACR,CACF,CAEA,MAAA,2BAAA,CACE,CAAA,CACA,CACyC,KAEvC,OAAO,MAAM,IAAA,CAAK,eAAA,CAAgB,EAAI,AAAJ,GACpC,KADgD,CAAA,AACvC,EAAO,CACd,GAAI,aAAiB,GAAiC,KAAK,CAAtB,EAAA,KEvDkC,CFuDlC,AEvDmC,CFwDtE,MAEF,OAAM,CACR,CACF,GAFU,AKhFZ,SAASiB,EAAgB,CAAA,EAA6B,OAC7C,EAAU,IAAA,CAAK,QAGjB,IAAM,EAAN,IHwCkB,EGvCvB,YACmB,CAAA,CACA,EAAiB,EAAA,CACjB,CADA,AACA,CACjB,YAHiB,CAAA,EACA,GHyCjB,CAAA,CAAA,MAAA,CAAA,EGxCiB,IAAA,CAAA,gBAAA,CAAA,CAChB,CAEH,MAAM,WAAW,CAAA,CAA4D,CAM3E,MAAO,CALU,MAAM,IAAA,CAAA,MAAK,CAAA,OAAO,CAAA,CACjC,OAAQ,KAAA,CACR,KAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAeA,EAAgB,EAAU,CHqDE,CAAC,OGrDM,CAAC,CAAA,OAAA,CAAA,CHsDrD,GGnDJ,IAAA,CAAK,WAAA,AACvB,OAEM,YAAA,CACJ,CACA,CAAA,CHmD+B,AGlDP,CHkDQ,AGjDhC,IAAM,EAAA,CAAA,EAYN,OAXI,IAAA,CAAK,gBAAA,EAAkB,CACzB,CAAA,CAAQ,8BAAA,CAAiC,IAAA,CAAA,gBAAA,AAAK,EAUzC,CAPU,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAA2B,QACpD,OACR,KAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAA,EAA+B,EAAA,OAAA,EAAmB,CAAC,CAAA,OAAA,CAAA,CACvE,KAAM,eAID,IAAS,CAAK,QAAA,CAGvB,MAAA,YAAA,CAAkB,CAAA,CAAqB,CAA2D,CAChG,IAAM,EAAW,MAAX,AAAiB,IAAA,CAAK,MAAA,CAAO,OAAA,CAA2B,CAC5D,MDoEkD,CCpE1C,OACR,KAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAeA,EAAAA,EAAmB,SAAS,CAAC,CAAA,GH0FI,KG1FJ,EAAW,EAAA,AAAG,IAAI,CAAA,CAAA,CAClF,KAAM,IAGR,MAAO,CACL,oBAAqB,EAAA,IAAS,CAAK,oBAAmB,CACtD,QAAA,CAAU,EAAS,IAAA,CAAK,IC3DoE,IAAA,QD+D1F,UAAA,CAAU,CAAqB,CAAA,CAA2C,CAC9E,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAAA,QACR,SACR,KAAA,CAAA,EAAA,IAAS,CAAA,MAAW,CAAA,YAAA,EAAeA,EAAgB,EAAA,AAAG,SAAS,EAAC,QAAA,EAAW,EAAA,AAAG,IAAI,CAAA,CAAA,CAClF,MAAO,CAAE,eAAgB,OAAO,GAAS,KAAA,GAAS,EAAK,GAAA,CAAA,MAIrD,UAAU,CAAA,CAA6C,CAC3D,IAAM,EAAkC,CAAA,CAAC,CAWzC,OAVI,IAAA,CAAK,gBAAA,EAAkB,CACzB,CAAA,CAAQ,8BAA6B,CAAI,IAAA,CAAK,gBAAA,EASzC,CANU,MAAM,IAAA,CAAK,MAAA,CAAO,OAAA,CAA2B,CAC5D,OAAQ,MACR,KAAM,CAAA,EAAG,IAAA,CAAK,MAAM,CAAA,YAAA,EAAeA,EAAgB,EAAG,AAAH,SAAY,CAAC,CAAA,CAA7BA,OAA6B,EAAW,EAAA,AAAG,IAAI,CAAA,CAAA,cAI7E,IAAA,CAAc,QAAA,mBAGL,CAAA,CAAA,CAChB,IAAM,EAAkC,CAAA,CAAC,CACrC,IAAA,CAAA,gBAAA,EAAuB,CACzB,CAAA,CAAQ,8BAA6B,CAAI,IAAA,CAAK,gBAAA,EAGhD,GAAI,QACF,MAAM,IAAA,CAAK,MAAA,CAAA,OAAO,CAAA,CAChB,OAAQ,OACR,IAAA,CAAM,CAAA,EAAA,IAAG,CAAK,MAAM,CAAA,YAAA,EAAeA,EAAgB,EAAG,SAAS,CAAC,CAAA,QAAA,EAAW,EAAG,AAAH,IAAO,CAAA,CAAA,SAClF,KAEK,CACT,CAAA,MAAS,EAAO,CACd,EADO,CACH,aAAiB,GAAiC,GAAA,EAAK,CAAtB,EAAM,GAAN,GAAM,CACzC,OAAO,CAET,IAFS,GAEH,CACR,CACF,CAEA,MAAM,uBACJ,CAAA,CACA,CAAA,CACwB,CACxB,GAAI,CG7FkD,AH8FpD,OAAO,MAAM,IAAA,CAAK,WAAA,CAAY,EAAW,EAC3C,CAAA,MAAS,EAAO,CACd,GAAI,KAAA,QAAiB,GAAiC,GAAA,EAAK,CAAtB,EAAM,CAAtB,EAAgB,GAAM,CACzC,OAAO,MAAM,IAAA,CAAK,SAAA,CAAU,CAAE,SAAA,CAAW,EAAU,SAAA,CAAW,IAAA,CAAM,EAAQ,IAAA,CAAR,AAAc,CAAA,AAEpF,OAAM,CACR,EAEJ,EIlDa,EAAN,MAAyB,YAWlB,CAAA,CAAoC,CAC9C,IAAI,EAAA,IACA,GAAA,WAAQ,CDhCe,CCgCF,CACvB,GAAA,CAAU,CAAA,EAAI,EAAQ,WAAW,CAAA,CAAA,QAG7B,EAAA,EAAA,OAAkB,CAAQ,QAAA,CAAS,KAAO,EAAA,KAAA,EAAA,CAAkB,CAAA,EAAG,EAAQ,KAAR,EAAe,CAAA,CAAA,CAAA,CAEpF,IAAA,CAAK,MAAA,CAAS,SXpEF,AAAkB,CAAA,EAInB,AACb,CRuE2Bf,GQvErB,EAAU,EAAA,SAAA,EAAqB,WAAW,KAAA,CAEhD,MAAO,CACL,MAAM,QAAW,QACf,CAAA,MACA,CAAA,OACA,CAAA,MACA,CAAA,CACA,SAAA,CACF,EAA0C,AACxC,IAAM,EAAM,QAAA,CFtChB,AADc,CACd,CACA,CAAA,CACA,CAAA,EACQ,IACF,EAAM,IAAA,IAAQ,EAAM,GAE1B,GAAI,CAF6B,CAG/B,AAH+B,IAG/B,CADS,EACE,CAAC,EAAK,EAAK,GAAA,AAAK,OAAO,OAAA,CAAQ,GACxC,AAAc,IADkC,CAClC,CAAA,EAAW,CAAzB,GACE,EAAA,YAAI,CAAa,GAAA,CAAA,EAAS,GAKhC,OAAO,EAAI,QAAA,IEwBc,EAAQ,KAAR,EAAQ,CAAS,EAAM,GAC5C,EADiD,AAC7B,CAD6B,KACvB,EAAiB,EAAQ,IAAI,CAAA,CAEjD,EAAM,MAAA,EAAc,EAAK,CAAL,SAExB,QAAS,CACP,GAAA,EAAW,CAAE,cAAA,CAAgB,kBAAA,EAAuB,CAAA,CAAC,CACrD,GAAG,CAAA,CACH,GAAG,CAAA,EAEL,KAAM,EAAO,KAAK,SAAA,CAAU,GAAQ,KAAA,IAGhC,EAAO,MAAM,EAAI,IAAA,GACjB,EAAA,CAAA,EAAc,OAAA,CAAQ,GAAA,CAAI,iBAAmB,EAAA,EAAI,QAAA,CAAS,kBAAkB,CAAA,CAC5E,EAAA,GAAiB,EAAA,KAAa,KAAA,CAAM,GAAe,CDiB3D,CCfE,GAAI,CAAA,EAAA,EAAK,CAAI,WAC+C,KAAA,IACtC,GAAS,KAC7B,OAAM,IAAA,EAAA,GACS,SAAW,CAAA,2BAAA,EAA8B,EAAI,CAAJ,KAAU,CAAA,CAAA,CAChE,CACE,OAAQ,EAAI,CAAJ,KAAI,CACZ,YAAa,GAAa,iBACb,GAAa,IAAA,CAC1B,QAAS,GAGf,CAEA,MAAO,CAAE,OAAQ,EAAI,CAAJ,KAAI,CAAQ,OAAA,CAAS,EAAI,CAAJ,MAAI,MAAS,CAAA,CAAgB,AACrE,EADqD,EWsBrB,SAC9B,EACA,KAAA,EAAc,IAAA,CACd,UAAA,EAAmB,KAAA,CACpB,CAAA,CAGD,IAAA,CAAK,gBAAA,CAAmB,EAAQ,KAAR,WAAQ,EAAkB,IAAA,CAAK,GAAG,CAAA,CAE1D,IAAA,CAAK,YAAA,CAAe,IAAI,EAAA,IAAoB,CAAK,MAAA,CAAQ,GACzD,GAD+D,CAAA,AAC/D,CAAK,QAAA,CAAW,IAAI,EAAgB,IAAA,CAAK,MAAA,CAAQ,EAAQ,IAAR,AAAQ,CAAK,gBAAgB,CAAA,AAChF,OAiBM,eAAe,CAAA,CAA8D,CACjF,OAAO,IAAA,CAAK,YAAA,CAAa,cAAA,CAAe,GAoB1C,GApBgD,CAAA,EAoB1C,gBAAgB,CAAA,CAAA,CAAA,CAAyF,CAC7G,OAAO,IAAA,CAAA,YAAK,CAAa,eAAA,CAAgB,EAAA,AAAI,GAe/C,KAfuD,CAAA,AAevD,cAAoB,CAAA,CAAA,CAClB,MAAA,IAAM,CAAA,YAAK,CAAa,aAAA,CAAc,EAAE,AAC1C,CAD0C,AAe1C,MAAM,sBAAsB,CAAA,CAAqD,CAC/E,OAAO,IAAA,CAAK,YAAA,CAAa,qBAAA,CAAsB,EAAE,AACnD,CLiNG,AKlNgD,AAenD,MAAA,WAAiB,CAAA,CAA4D,CAC3E,AL6N8B,OK7NvB,IAAA,CAAK,QAAA,CAAS,UAAA,CAAW,EAClC,CAiCA,MAAM,WAAA,CACJ,CAAA,CACA,CAAA,CACwB,QACjB,IAAA,CAAK,QAAA,CAAS,SEtIS,CAChC,CAAA,CFqImC,EAAA,EACnC,CAuBA,MAAM,WAAA,CAAY,CAAA,CAAqB,CAAA,CAA2D,CAChG,OAAO,IAAA,CAAK,QAAA,CAAS,WAAA,CAAY,EAAA,AAAI,EACvC,CAYA,IAb8C,CAAA,CAaxC,SAAA,CAAU,CAAA,CAAqB,CAAA,CAA2C,CAC9E,MAAM,IAAA,CAAK,QAAA,CAAS,SAAA,CAAU,EAAA,AAAI,EACpC,CAeA,IAhB2C,CAAA,CAgBrC,UAAU,CAAA,CAA6C,CAC3D,OAAO,IAAA,CAAK,QAAA,CAAS,SAAA,CAAU,EAAE,AACnC,CADmC,AAenC,MAAM,gBAAgB,CAAA,CAA2C,CAC/D,CCFiD,MDE1C,IAAA,CAAK,YAAA,CAAa,eAAA,CAAgB,EAAE,AAC7C,CAD6C,AAe7C,MAAM,YAAY,CAAA,CAAuC,CACvD,OAAO,IAAA,CAAK,QAAA,CAAS,WAAA,CAAY,EAAE,AACrC,CADqC,AAyBrC,MAAM,0BAAA,CACJ,CAAA,CACA,CAAA,CACyC,CACzC,OAAO,IAAA,CAAK,YAAA,CAAa,0BAAA,CAA2B,EAAA,AAAI,EAC1D,CA6BA,KA9BkE,CA8B5D,AA9B4D,sBA8B5D,CACJ,CAAA,CACA,CAAA,CACwB,CACxB,OAAO,IAAA,CAAK,QAAA,CAAS,sBAAA,CAAuB,EAAW,EACzD,GlB5XW,EkB2XmC,AAAkB,AlB3XlE,CkB2XkE,GnBnX3C,EAAEf,QCRS,MAAM,AAGtC,ADKqC,QAAQ,ICLjC,CAAA,CAAiB,MDMQ,EDiBvB,MCjB+B,CCRnC,ODO8D,SCP9D,EAAmB,CF2BR,MEvBd,IAAA,CAAO,CDI8D,2BCA/C,CAAA,QACL,IDSG,MCTpB,CDSAG,MCTO,GAAgC,OAAV,GAAkB,GDSC,kBCTqB,MAGjE,EAAb,GDWSC,KAAqB,MCXO,EDWC,ACPpC,WAJgD,CAIpC,CAAA,CAAiB,CDQR,AAAEC,CCRsB,CDQtBA,ACRsB,CAAoB,KDQpB,ECPrC,CDQDC,KAD8C,EADe,ACL7D,EDSPC,EAAAA,CCTc,eDM4D,QCLnE,MAAA,CAAA,OACA,UAAA,CAAa,EAGpB,QAAS,EFwBT,KEvBS,CACL,KAAM,IAAA,CAAK,IAAA,CACX,QAAS,IAAA,CAAA,OAAA,CACT,OAAA,IAAA,CAAA,MAAA,YACY,IAAA,CAAK,UAAA,MAKvB,cAAyC,EAGvC,ODe6C,KCfjC,CAAA,CAAA,CAAA,CAAyC,OAC7C,GACN,IAAA,CAAK,IAAA,CAAO,MDc6C,qBCbpD,aAAA,CAAgB,GKnCH,KCHTI,EAAAA,AAAgB,GAC3B,AAAI,EACF,CAAQ,GAAG,IAAS,GAApB,AAFwD,EAErB,GAErC,CAAA,CAF0C,EAAR,AAElC,IAAA,SAA6B,GAO/B,EAPoC,AAOpC,AAAiC,IAC/B,GAAA,MAAA,OAAA,CAAA,GAAA,OACS,EAAK,GAAA,CAAK,AAAL,GAAY,EAAiB,GAAG,CAAC,GACpB,YAAhB,OAAO,GAAuB,IAAS,OAAO,GACvD,OAAO,EAGT,IAAMG,EAA8B,CAAA,EAMpC,OALA,OAAA,OAAA,CAAe,GAAA,OAAA,CAAA,CAAe,CAAC,EAAA,EAAA,MACd,EAAI,OAAA,CAAQ,gBAAA,AAAkB,GAAM,EAAE,WAAA,GAAc,OAAA,CAAQ,QAAS,MACnE,EAAiB,KAGpC,krCKVF,IAAA,EAAA,AAA0B,QACxB,WAAI,GAAA,EACJ,EAAI,OAAA,EACJ,EAAI,iBAAA,EACH,CAAqB,CADlB,gBACI,EAAI,KAAA,CAAqB,EAAI,KAAA,CAAA,MAAA,CAAA,EAAQ,EAAI,KAAA,EAAA,IAAA,CAAA,EAAA,EAAO,GAAP,IAAO,GACxD,KAAK,GAD4C,KAAA,CAC5C,CAAU,IAEXY,EAAc,MAClB,EACA,EACA,CF0DM,IEtDF,aAFQ,gBAEgB,CAAA,OAAA,EAAA,KAAA,EAAC,EAAS,aAAA,EACpC,EACG,IAAA,EAAM,CACN,IAAA,CAAM,AAAN,IACC,IADa,AACP,EAAS,EAAM,MAAA,EAAU,IACzB,EAAA,CAAA,MAAA,EAAA,KAAA,EAAa,EAAK,UAAA,GAAc,EAAS,GAC/C,EAAO,IAAI,EFuDT,AEvDyBC,EAAiB,GAAM,EAAQ,MAE3D,KAAA,CAAA,AAAO,MACC,IAAI,EAAA,EAAqC,GAAM,IAAI,CAAC,GAGxD,IAAI,EAAoBA,EAAiB,GAAQ,MAAM,CAAC,aA8BpDI,EG9CL,CAAA,CHgDR,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,EACc,OACP,IAAA,QAAA,CAAa,EAAS,SA5BvBF,SAA+B,CAAE,OA6BN,EA7Bc,QAAA,CAAA,MA6BN,EA7BM,KAAA,EAAS,EAAS,OAAA,GAAW,CAAA,CAAE,EAE9E,AAAI,WAAoB,CAAC,EAChB,GAGLb,ALxBOA,AKqBT,CLrBSA,AAAiB,AKqB1B,OLpBmB,QKuBH,ELvBd,OAAA,GAA6B,AAAU,KACzC,IAAA,OAAO,EAGT,IAAM,EAAY,OAAA,cAAO,CAAA,UAER,UAAA,IACC,OAAO,SAAA,EACrB,AAAqC,cAA9B,cAAA,CAAe,EAAe,CAAA,EACvC,CAAA,CAAE,GADgC,IACzB,WAAA,IAAe,CAAA,CAAA,EACxB,CAAA,CAAE,OAAO,QAAA,IAAY,CAAA,CAAA,GKoCuC,GGrDP,GH+B9C,IGxCT,GAAA,CAAA,EAAA,CHwCqB,eAAgB,mCAAuB,EAAS,OAAA,EACnE,EAAO,IAAA,CAAO,KAAK,GGxCF,MAAA,CHwCY,KAAK,CAE3B,IAAA,GAAO,AAGhB,CAAA,CG5CmB,OH4CnB,KAAA,EAAI,EAAS,MAAA,CACX,EAAA,GAAO,MAAA,CAAS,EAAQ,MAAA,SAGd,GAYsC,KGrDXc,CHyChB,AGzCgC,IAAA,CAAA,IHuDjD,GAAI,CAAC,EAAO,EAAA,CAAI,MAAM,wBAClB,EAAS,aAAA,CAAe,CAAA,AAAO,EAC5B,EAAO,IAAA,EAAM,GAErB,IAAA,CAAA,AAAM,GAAA,EAAiB,IACvB,KAAA,CAAA,AAAO,GAAUJ,EAAY,EAAO,EAAQ,MAInD,EAJ2D,CAAC,YAItC,EACpB,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,SAEOK,EAAe,EAAS,MAAO,EAAK,EAAS,WAAW,OAG3CE,EACpB,CAAA,CACA,CAAA,CACA,CAAA,CAAA,CAAA,CAEA,CAAA,EACc,AACd,OAAOF,EG/DH,AH+DkB,EAAS,OAAQ,EAAK,EAAS,CG/DdD,CH+D0B,KAAK,aAGlD,EACpB,CAAA,CAAA,CAAA,CAEA,CAAA,CACA,CAAA,CACA,CAAA,EACc,AACd,GED+D,IFCxDC,EAAAA,EAAwB,MAAO,EAAK,EAAS,EAAY,EECZ,GFDiB,aAGjD,EAAA,CAAA,CAEpB,CAAA,CACA,CAAA,CACA,CEJ4C,WFO1C,EACA,OAAA,EAAA,EAAA,EAAA,CAAA,EAGK,GAAA,CAAA,EAAA,CACH,cAAe,EAAA,GAEjB,WACD,OAGmB,EACpB,CAAA,CAAA,CAAA,CAEA,CAAA,CACA,CAAA,CACA,CAAA,EAEA,OAAA,EAAsB,EAAS,SAAU,EAAK,EAAA,EAAA,OI/I3B,GAArB,MACE,YACUG,CAAAA,CACAC,CAAAA,CACR,uBADQ,CAAA,kBAAA,CAAA,EAGV,KAAA,CAAA,CAIE,CDuDU,CCtDoB,CDsDpB,OCrDH,CDsDL,GAAA,CCtDU,OAAA,GAAU,IAAA,CAAK,EAAa,GAG1C,MAAA,SAAiE,IAC3D,cACa,MAAMhB,KAAK,UAAA,EAAA,CAAY,CAGvB,IAAA,CACb,MAAO,YAEF,EAAA,IACHA,KDsDJ,ACtDS,kBAAA,CAAA,MACD,EAGR,GAAI,EAAe,CDmDnB,CDkFA,CEpIE,MAAO,CAAE,KAAA,oBAGL,cE9BO,WAAA,KADE,GAArB,MAIE,YAAA,CAAA,CAEUgB,CAAAA,CACR,CAFQ,IAAA,CAAA,UAAA,CAAA,EACA,IAAA,CAAA,kBAAA,CAAA,UAL8B,2BAChC,OAAA,CAAgD,KAOxD,UAAkC,CAChC,OAAO,IAAI,GAAsB,CH4FzB,GG5FyB,CAAK,UAAA,CAAY,IAAA,CAAK,kBAAA,CAAmB,CAG5E,KACE,CAAA,CACA,CAAA,CAC8B,QACvB,IAAA,CAAK,UAAA,GAAa,GHyFrB,CAAA,CGzF0B,EAAa,GAG7C,MACE,CAAA,CAAA,QAEO,IAAA,CAAK,UAAA,GAAa,KAAA,CAAM,GAGjC,QAAQ,AAHoC,CAGpC,CAAgE,QAC/D,IAAA,CAAK,UAAA,GAAA,OAAa,CAAQ,eAGiB,QAC9C,AAAC,IAAA,CAAK,OAAA,EACR,KAAA,CAAK,OAAA,CAAU,IAAA,CAAK,OAAA,EAAA,CAAS,CAExB,IAAA,CAAK,OAAA,CAGd,MAAc,SAAyC,CACrD,GAAI,CAGF,MAAO,CACL,KAAM,MAAA,CAHO,MAAMhB,KAAK,UAAA,EAAA,CAAY,CAGjB,IAAA,EAAM,CACzB,MAAO,YAEF,EAAO,CACd,GAAIA,KAAK,CCmCP,iBAAA,CDlCA,MAAM,EAGR,GAAI,EAAe,GAAA,MACV,CAAE,KAAM,ECgCjB,SDhCuB,cEtC7B,IAAM,GAAyB,CAC7B,MAAO,CDoFe,GCnFtB,OAAQ,EACR,OAAQ,CACN,OAAQ,aACD,QAILkB,GAAoC,CACxC,aAAc,mBACD,mCACL,OAeW,GAArB,MAOE,YACE,CAAA,CACA,EAAqC,CAAA,CAAE,CACvC,CAAA,CACA,CAAA,CACA,4BACA,IAAA,CAAA,GAAA,CAAW,OACN,OAAA,CAAU,OACV,QAAA,CAAW,OACX,KAAA,CAAQ1B,EAAAA,iBAQa,aACrB,kBAAA,EAAqB,EACnB,IAAA,CAUT,MAAc,eACZ,CD4DI,CC3DJ,CAAA,CAAA,CAAA,CAEA,CAAA,CAUA,IACI,CAEF,IADI,EACE,EAAA,EAAA,EAAA,CAAA,EAAe,IAAyB,GAC9C,EAAA,EAAA,EAAA,CAAA,EACKQ,KAAK,OAAA,EACO,SAAX,GAAqB,CAAE,WAAY,OAAO,EAAQ,MAAA,CAAkB,CAAE,EAGtE,EAAW,EAAQ,QAAA,AAErB,CAAgB,oBAAT,MAAwB,aAAoB,MAAM,GACpD,IAAI,QAAA,EACN,MAAA,CAAA,eAAuB,EAAQ,YAAA,EAChC,GACF,EAAK,MAAA,CAAO,WAAYA,KAAK,cAAA,CAAA,IAE/B,EAAA,MAAA,CAAY,GAAI,IACa,aAApB,OAAO,UAA4B,aAAoB,UAG5D,AAAC,GAFE,CAAA,EAEG,GAAA,CAAI,iBACZ,EAAK,MAAA,CAAO,eAAgB,EAAQ,YAAA,CAAuB,IAE7C,CAAC,EAAA,GAAA,CAAS,aACxB,EAAK,MAAA,CAAO,WAAYA,KAAK,cAAA,CAAe,QAGvC,CAHgD,CAAC,EAIhD,gBAAA,CAAmB,CAAA,QAAA,EAAW,EAAQ,YAAA,CAAA,CAAA,kBACtC,CAAkB,EAAQ,WAAA,CAE9B,IACF,CAAA,CAAQ,GAAR,UAAQ,CAAgBA,KAAK,QAAA,CAASA,KAAK,cAAA,CAAe,GAAS,CAAC,EAMzC,aAA1B,OAAO,gBAAkC,aAAgB,gBACzD,GAAwB,UAAhB,OAAO,GAAqB,SAAU,GAAQ,AAAqB,mBAAd,EAAK,IAAA,AAAS,CAAA,EAE9D,CAAC,EAAQ,MAAA,CACvB,CAAA,GAAQ,MAAA,CAAS,MAAA,mBAIjB,EAAa,OAAA,CACf,GAAA,EAAA,EAAA,EAAA,CAAA,EAAe,GAAY,EAAY,QAAA,MAGnC,EAAYA,KAAK,mBAAA,CAAoB,KHyGK,AGzGA,AAClCA,KAAK,aAAA,CAAc,GAC3B,EAAO,KAD8B,CAC9B,CAAiB,OAAV,EAAkB,EAAMc,CAAAA,CAAAA,CAC1Cd,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAA,CAAA,CACtB,EAAA,EAAA,SACE,CAAA,EAAA,OAAA,EAAA,KAAA,EAAa,EAAS,CAAtB,KAAsB,EAAS,CAAE,AAAjC,OAAyC,EAAQ,GAAjD,GAAiD,CAAQ,CAAG,AAA5D,CAA4D,CAAE,EACjE,OAEM,CACL,KAAM,CAAE,KAAM,EAAW,GAAI,EAAK,EAAA,CAAI,SAAA,EAAe,GAAA,EACrD,MAAO,YAEF,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,KAEJ,EAAe,GACjB,MAAO,CAAE,KAAM,WAAM,SAGjB,GAgDV,MAAM,OACJ,CAAA,CACA,CAAA,CACA,CAAA,CAUA,CACA,OAAA,IAAA,CAAY,cAAA,CAAe,OAAQ,EAAM,EAAU,GAkCrD,MAAM,GAlC2D,eAmC/D,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CACA,IAAM,EAAYA,KAAK,mBAAA,CAAoB,GACrC,EAD0C,AAClCA,KAAK,aAAA,CAAc,GAE3B,EAAM,IAAI,CAF2B,GAEvBA,KAAK,GAAA,CAAM,CAAA,oBAAA,EAAuB,EAAA,CAAA,CAAQ,CAC9D,EAAI,YAAA,CAAa,GAAA,CAAI,QAAS,GAE9B,GAFoC,AAEhC,CAEF,IADI,EACE,EAAA,EAAA,CAAY,OAAQ,GAAqB,MAAA,EAAW,GAC1D,EAAMmB,EAAAA,EAAAA,CAAAA,EACDnB,KAAK,OAAA,EACL,CAAE,WAAY,OAAO,EAAQ,MAAA,CAAkB,CAAE,EAkBtD,MAfoB,aAAhB,OAAO,MAAwB,aAAoB,MAAM,iBAEtD,MAAA,CAAO,eAAgB,EAAQ,YAAA,CAAuB,GACtD,MAAA,CAAO,GAAI,IACa,KADJ,QAChB,OAAO,UAA4B,aAAoB,UAAU,AAC1E,EAAO,CAAA,EACF,MAAA,CAAO,eAAgB,EAAQ,YAAA,CAAuB,QAGnD,gBAAA,CAAmB,CAAA,QAAA,EAAW,EAAQ,YAAA,CAAA,CAAA,GACtC,eAAA,CAAkB,EAAQ,WAAA,EAK7B,CACL,KAAM,CAAE,KAAM,EAAW,SAAA,CAHd,MAAM,EAAIA,KAAK,KAAA,CAAO,EAAI,QAAA,EAAU,CAAE,EAAgB,CAAE,SAAA,EAAS,CAAC,CAGrC,GAAA,EACxC,MAAO,YAEF,EAAO,IACVA,KAAK,kBAAA,CACP,MAAM,KAEJ,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,SAGjB,GAkCV,MAAA,sBACE,CAAA,CACA,CAAA,CAUA,IACI,CACF,IAAI,EAAQA,KAAK,aAAA,CAAc,GAEzB,EAAA,AAF8B,EAE9B,CAAA,EAAeA,KAAK,OAAA,kBAEtB,EAAS,MAAA,CACX,GAAA,CAAA,CAAQ,WAAA,CAAc,MAAA,EAGxB,IAAM,EAAO,MAAMc,EACjBd,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,oBAAA,EAAsB,EAAA,CAAA,CAClC,CAAA,CAAE,CACF,SAAE,CAAA,CAAS,CACZ,CAEK,EAAM,IAAI,IAAIA,KAAK,GAAA,CAAM,EAAK,GAAA,CAAI,CAElC,EAAQ,EAAI,YAAA,CAAa,GAAA,CAAI,QAAQ,IAEvC,CAAC,EAAA,MACG,IAAI,EAAa,2BAA2B,OAG7C,CAAE,KAAM,CAAE,UAAW,EAAI,QAAA,EAAU,MAAE,QAAM,GAAS,MAAO,YAC3D,EAAO,IACVA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,MAAO,CAAE,KAAM,KAAM,QAGvB,OAAM,SAgDJ,OACJ,CAAA,CACA,CAAA,CAWA,CAAA,CAUA,CACA,OAAA,IAAA,CAAY,cAAA,CAAe,MAAO,EAAM,EAAU,GA8BpD,MAAM,GA9B0D,EA+B9D,CAAA,CACA,CAAA,CACA,CAAA,CAUA,CACA,GAAI,CAYF,MAAO,CAAE,KAXI,MAAMc,EACjBd,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,YAAA,CAAA,CACZ,CACE,SAAUA,KAAK,QAAA,CACf,UAAW,EACX,EE9GG,aF8Ga,EAChB,kBAAA,MAAA,EAAA,KAAA,EAAmB,EAAS,iBAAA,EAE9B,CAAE,QAASA,KAAK,OAAA,GAEH,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAGvB,AAH8B,OAGxB,SA+BJ,KACJ,CAAA,CACA,CAAA,CACA,CAAA,CAUA,CACA,GAAI,CAYF,MAAO,CAAE,KAAM,CAAE,KAAA,CAXJ,MAAMc,EACjBd,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,YAAA,CAAA,CACZ,CACE,SAAUA,KAAK,QAAA,CACf,UAAW,EACX,eAAgB,EAChB,wBAAA,EAAA,KAAA,EAAmB,EAAS,CAA5B,QAAA,QAA4B,EAE9B,CAAE,CAFA,KAAA,EAEA,KAAc,OAAA,EAAS,CAC1B,CAC2B,GAAA,CAAK,CAAE,MAAO,YACnC,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAuDV,MAAM,gBACJ,CAAA,CACA,CAAA,CACA,CAAA,CAUA,CACA,GAAI,CACF,IAAI,EAAQA,KAAK,aAAA,CAAc,GAE/B,EAAW,MAAMc,EACfd,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,aAAA,EAAe,EAAA,CAAA,CE1E6C,EAAA,CF2EtE,WAAA,EAAA,OAAA,EAAA,KAAA,EAAe,EAAS,CAAxB,QAAA,AAAwB,EAAY,CAAE,SAAtC,CAAiD,EAAQ,EAAzD,OAAyD,CAAW,CAAG,CAAA,CAAE,EAC3E,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACD,EAAM,OAAA,EAAA,KAAA,EAAqB,EAAS,CAA9B,OAA8B,CAA9B,CACF,CAAA,UAAA,AADE,EACgC,GADhC,EACW,EAAQ,QAAA,CAAoB,GAAK,EAAQ,QAAA,CAAA,CAAA,CACtD,GAGJ,MAAO,CAAE,KADT,EAAO,CAAE,UADS,UAAU,CAAA,EAAGA,KAAK,GAAA,CAAA,EAAM,EAAK,SAAA,CAAA,EAAY,EAAA,CAAA,CAAqB,CAC5D,CACL,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAGvB,CE5EA,MF4EM,GA0CV,MAAM,iBACJ,CAAA,CACA,CAAA,CACA,CAAA,CAUA,YACA,GAAI,CACF,IAAM,EAAO,MAAMc,EACjBd,EAAK,KAAA,CACL,CAAA,EAAGA,EAAK,GAAA,CAAI,aAAA,EAAeA,EAAK,QAAA,CAAA,CAAA,CAChC,WAAE,QAAW,EAAO,CACpB,CAAE,QAASA,EAAK,OAAA,CAAS,CAC1B,CAEK,EAAA,CAAA,QAAA,IAAA,CAAA,EAAqB,EAAS,GAA9B,KAA8B,EAChC,CAAA,IADE,KAAA,CACF,GAAkC,IAArB,EAAQ,QAAA,CAAoB,GAAK,EAAQ,QAAA,CAAA,CAAA,CACtD,GACJ,MAAO,CACL,KAAM,EAAK,GAAA,CAAK,AAAL,GAAK,EAAA,EAAA,CAAA,EACX,GAAA,CAAA,EAAA,CACH,UAAW,EAAM,SAAA,CACb,UAAU,CAAA,EAAGA,EAAK,GAAA,CAAA,EAAM,EAAM,SAAA,CAAA,EAAY,EAAA,CAAA,CAAqB,CAC/D,IAAA,GACH,CACH,MAAO,KACR,OACM,EAAO,CACd,GAAA,EAAS,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GA0CV,SACE,CAAA,CACA,CAAA,CACqB,CAErB,IAAM,EADsB,KAA8B,EAA9B,SAAA,EAAA,KAAA,EAAO,EAAS,CAAhB,QAAgB,AAAhB,AAAgB,EACH,UADb,KAAA,cAC4C,SAClE,EAAsB,IAAA,CAAK,0BAAA,CAAA,OAAA,EAAA,KAAA,EAA2B,EAAS,CAApC,QAAoC,AAApC,AAAoC,GAAa,CAAA,CAAE,CAAC,CAC/E,EAAc,EAAsB,CAAA,AADT,CACS,EAAI,EAAA,AADb,CACa,CAAwB,GAChE,EAAQ,IAAA,CAAK,aAAA,CAAc,GAMjC,EANsC,KAM/B,IAAI,GALL,IACJ,EAAI,IAAA,CAAK,KAAA,CAAO,AAIa,CAJb,EAAG,IAAA,CAAK,GAAA,CAAI,CAAA,EAAG,EAAW,CAAA,EAAG,EAAA,EAAQ,EAAA,CAAA,CAAe,CAClE,QAAS,IAAA,CAAK,OAAA,CACd,eAAe,EAChB,CAAC,CACuC,IAAA,CAAK,kBAAA,CAAmB,CAkBrE,MAAM,KAAK,CAAA,CAST,CACA,IAAM,EAAQA,KAAK,aAAA,CAAc,GAEjC,EAFsC,CAElC,CAKF,MAAO,CAAE,KAAM,EAJF,MAAM,EAAIA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,aAAA,EAAe,EAAA,CAAA,CAAS,CACrE,QAASA,KAAK,OAAA,CACf,CAAC,CAEmC,CAA4B,MAAO,KAAM,OACvE,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAmBV,MAAM,OAAO,CAAA,CASX,OACcA,KAAAA,aAAAA,CAAmB,KAAK,CAElC,CAKF,KI1qBA,QJsqBM,EAAKA,KInqBX,EAAA,GJmqBgB,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAA,CAAA,CAAA,CAC3C,QAASA,KAAK,OAAA,CACf,CAAC,CAEK,CAAE,MAAM,EAAM,MAAO,YACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,IAAU,EAAJ,WAAqB,EAAqB,CACjE,IAAM,EAAgB,EAAM,aAAA,IAExB,CAAC,IAAK,IAAI,CAAC,QAAA,OAAA,EAAA,KAAA,EAAS,EAAe,MAAA,CAAO,AAA/B,CACb,MAAO,CAAE,AADI,MACE,QAAO,IADT,KAAA,AAKX,GAsDV,aACE,CAAA,CACA,CAAA,CACiC,CACjC,IAAM,EAAQ,IAAA,CAAK,aAAA,CAAc,GAC3BoB,EAAyB,AADO,EACL,CAE3B,EAAA,SAAA,GAAA,EAAA,EAAqB,EAAS,EAA9B,MAA8B,EAChC,CAAA,GADE,KAAA,CACF,GAAiC,IAArB,EAAQ,QAAA,CAAoB,GAAK,EAAQ,QAAA,CAAA,CAAA,CACrD,EAEA,CAAuB,GACzB,KAAA,EAAa,IAAA,CAAK,GAIpB,IAAM,EADsB,AAA8B,OAA9B,GAHW,MAGX,EAAA,KAAA,EAAO,EAAS,CAAhB,QAAgB,AAAhB,EACa,UADb,KAC8B,AAD9B,SAEtB,EAAsB,IAAA,CAAK,0BAAA,CAAA,OAAA,EAAA,KAAA,EAA2B,EAAS,CAApC,QAAA,AAAoC,GAAa,CAAA,CAAE,CAAC,CAEzD,GAC1B,EADE,AAF6B,GAG/B,EAAa,AAHkB,IAGlB,CAAK,GAGpB,IAAI,EAAc,EAAa,IAAA,CAAK,IAAI,AAHA,CAQxC,MAJoB,GAClB,EADE,IACF,EAAc,CAAA,CAAA,EAAI,EAAA,CAAA,EAGb,CACL,KAAM,CAAE,UAAW,UAAU,CAAA,EAAG,IAAA,CAAK,GAAA,CAAI,CAAA,EAAG,EAAW,QAAA,EAAU,EAAA,EAAQ,EAAA,CAAA,CAAc,CAAE,CAC1F,OA0BG,OAAA,CAAA,CASJ,IACI,QAOO,KAAA,MANU,EACjBpB,KAAK,KAAA,CACL,CAAA,EAAA,KAAQ,GAAA,CAAI,QAAA,EAAUA,KAAAA,QAAAA,CAAAA,CAAAA,CACtB,CAAE,SAAU,CAAA,CAAO,CACnB,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,YACf,EAAO,GIvoBd,CJwoBIA,KAAK,kBAAA,CACP,MAAM,KAEJ,EAAe,GACjB,MAAO,CAAE,KAAM,aAGjB,OAAM,GA8HV,MAAM,KACJ,CAAA,CACA,CAAA,CACA,CAAA,CAUA,CACA,GAAI,KACI,EAAA,EAAA,EAAA,EAAA,CAAA,EAAY,IAA2B,GAAA,CAAA,EAAA,CAAS,OAAQ,GAAQ,EAAA,eACzD,MAAMc,EACjBd,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,aAAA,EAAeA,KAAK,QAAA,CAAA,CAAA,CAChC,EACA,CAAE,QAASA,KAAK,OAAA,CAAS,CACzB,GAEa,MAAO,EADrB,GAC2B,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAWV,MAAM,OACJ,CAAA,CACA,CAAA,CAUA,CACA,GAAI,CACF,IAAM,EAAA,EAAA,CAAA,EAAY,GAQlB,MAAO,CAAE,KAPI,MAAMc,EACjBd,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,gBAAA,EAAkBA,KAAK,QAAA,CAAA,CAAA,CACnC,EACA,CAAE,QAASA,KAAK,OAAA,CAAS,CACzB,GAEa,MAAO,EADrB,GAC2B,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAIA,eAAe,CAAA,CAA+B,QAC/C,KAAA,SAAA,CAAe,GAGxB,SAAS,CAAA,CAAc,OACrB,AAAsB,YACpB,CADE,AACF,OADS,OACF,OAAO,IAAA,CAAK,GAAM,EAAD,MAAC,CAAS,SAAS,CAEtC,KAAK,GAGN,EAHW,YAGG,CAAA,CAAc,CAClC,MAAO,CAAA,EAAG,IAAA,CAAK,QAAA,CAAS,CAAA,EAAG,EAAK,OAAA,CAAQ,OAAQ,GAAG,CAAA,CAAA,qBAGzB,CAAA,CAAc,QACjC,EAAK,OAAA,CAAQ,WAAY,GAAG,CAAC,OAAA,CAAQ,OAAQ,IAAI,CAGlD,2BAAA,CAAA,CAAwD,CAC9D,IAAMqB,EAAmB,EAAE,CAqB3B,OApBI,EAAU,KAAA,CACZ,CAAA,EAAO,IAAA,CAAK,CAAA,MAAA,EAAS,EAAU,KAAA,CAAA,CAAA,CAAQ,CAGrC,EAAU,MAAA,CACZ,CAAA,EAAO,IAAA,CAAK,CAAA,OAAA,EAAU,EAAU,MAAA,CAAA,CAAA,CAAS,CAGvC,EAAU,MAAA,CACZ,CAAA,EAAO,IAAA,CAAK,CAAA,OAAA,EAAU,EAAU,MAAA,CAAA,CAAA,CAAS,CAGvC,EAAU,MAAA,CACZ,CAAA,EAAO,IAAA,CAAK,CAAA,OAAA,EAAU,EAAU,MAAA,CAAA,CAAA,CAAS,CAGvC,EAAU,OAAA,CACZ,CAAA,EAAO,IAAA,CAAK,CAAA,QAAA,EAAW,EAAU,OAAA,CAAA,CAAA,CAAU,CAGtC,EAAO,IAAA,CAAK,IAAI,OM5wCd,GAAU,SCLVC,GAAkB,CAC7B,gBAAiB,CAAA,WAAA,EAAc,GAAA,CAAA,CAChC,CCID,IAAqB,GAArB,MAAsC,AAMpC,YACE,CAAA,CACA,EAAqC,CAAA,CAAE,CACvC,CAAA,CACA,CAAA,CACA,MAPQ,kBAAA,CAAqB,GAQ7B,MAAM,EAAU,IAAI,IAAI,IAAI,MAI5B,EAAA,KAAA,EAAA,AAAI,EAAM,MAAV,QAAU,CAAV,CAEE,CADuB,GADzB,sBACkD,IAAA,CAAK,EAAQ,QAAA,CAAS,EAChD,CAAC,EAAQ,QAAA,CAAS,QAAA,CAAS,oBAAoB,CACnE,EAAA,EAAQ,QAAA,CAAW,EAAQ,QAAA,CAAS,OAAA,CAAQ,YAAa,oBAAA,CAAoB,CAIjF,IAAA,CAAK,GAAA,CAAM,EAAQ,IAAA,CAAK,OAAA,CAAQ,MAAO,GAAG,CAC1C,IAAA,CAAK,OAAA,CAAA,EAAA,EAAA,CAAA,EAAeA,IAAoB,GACxC,IAAA,CAAK,KAAA,CAAQ9B,EAAaS,GAQrB,KAR2B,SAQN,CAE1B,OADA,IAAA,CAAK,kBAAA,EAAqB,EACnB,IAAA,CAmCT,MAAM,YAAY,CAAA,CAShB,CACA,GAAI,KACI,EAAcD,KAAK,8BAAA,CAA+B,QAAQ,CAIzD,CAAE,KAHI,MAAM,EAAIA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,OAAA,EAAS,EAAA,CAAA,CAAe,CACrE,QAASA,KAAK,OAAA,CACf,CAAC,CACa,MAAA,YACR,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,KAAM,eAGjB,GAqCV,MAAM,UAAU,CAAA,CASd,CACA,GAAI,CAEF,MAAO,CAAE,KADI,MAAM,EAAIA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAA,CAAA,CAAM,CAAE,QAASA,KAAK,OAAA,CAAS,CAAC,CAC1E,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAyCV,MAAM,aACJ,CAAA,CACA,EAKI,CACF,QAAQ,CAAA,CACT,CAUD,CACA,GAAI,CAcF,MAAO,CAAE,KAbI,MAAMc,EACjBd,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,OAAA,CAAA,CACZ,IACE,EACA,KAAM,EACN,KAAM,EAAQ,IAAA,CACd,OAAQ,EAAQ,MAAA,CAChB,gBAAiB,EAAQ,aAAA,CACzB,mBAAoB,EAAQ,gBAAA,CAC7B,CACD,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAuCV,MAAM,aACJ,CAAA,CACA,CAAA,CAcA,CACA,GAAI,CAaF,MAAO,CAAE,KAZI,MAAM,EACjBA,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAA,CAAA,CACtB,IACE,EACA,KAAM,EACN,OAAQ,EAAQ,MAAA,CAChB,gBAAiB,EAAQ,aAAA,CACzB,mBAAoB,EAAQ,gBAAA,CAC7B,CACD,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GA4BV,MAAM,YAAY,CAAA,CAShB,CACA,GAAI,CAOF,MAAO,CAAE,KANI,MAAMc,EACjBd,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAG,MAAA,CAAA,CACzB,CAAA,CAAE,CACF,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GA6BV,MAAM,aAAa,CAAA,CASjB,CACA,GAAI,CAOF,MAAO,CAAE,KANI,MAAM,EACjBA,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAA,CAAA,CACtB,CAAA,CAAE,CACF,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAIF,+BAA+B,CAAA,CAAqC,CAC1E,IAAMyB,EAAiC,CAAA,CAAE,CAkBzC,OAjBI,IACE,KADO,KACI,GACb,GAAO,EAAP,GAAO,CAAQ,OAAO,EAAQ,MAAA,CAAM,CAElC,WAAY,IACd,EAAO,EAAP,IAAO,CAAS,OAAO,EAAQ,OAAA,CAAO,CAEpC,EAAQ,MAAA,CACV,EAAA,EAAO,MAAA,CAAS,EAAQ,MAAA,EAEtB,EAAQ,UAAA,CACV,EAAA,EAAO,UAAA,CAAa,EAAQ,UAAA,EAE1B,EAAQ,SAAA,CACV,EAAA,EAAO,SAAA,CAAY,EAAQ,SAAA,GAGxB,OAAO,IAAA,CAAK,GAAQ,IAAD,EAAC,CAAS,EAAI,IAAM,IAAI,gBAAgB,GAAQ,IAAD,IAAC,EAAU,CAAG,KElbtE,GAArB,MAA4C,AAuB1C,YAAY,CAAA,CAAa,EAAqC,CAAA,CAAE,CAAE,CAAA,CAAe,MAnBvE,kBAAA,EAAqB,EAoB7B,IAAA,CAAK,GAAA,CAAM,EAAI,OAAA,CAAQ,MAAO,GAAG,CACjC,IAAA,CAAK,OAAA,CAAA,EAAA,EAAA,CAAA,EAAeH,IAAoB,GACxC,IAAA,CAAK,KAAA,CAAQ9B,EAAaS,GAcrB,KAd2B,SAcN,CAE1B,OADA,IAAA,CAAK,kBAAA,EAAqB,EACnB,IAAA,CAqCT,MAAM,aAAa,CAAA,CASjB,CACA,GAAI,CAEF,MAAO,CAAE,KADI,MAAMa,EAAKd,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,OAAA,CAAA,CAAU,MAAE,CAAA,CAAM,CAAE,CAAE,QAASA,KAAK,OAAA,CAAS,CAAC,CAC/E,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GAkDV,MAAM,YAAY,CAAA,CAehB,CACA,GAAI,CAEF,IAAM,EAAc,IAAI,eACxB,EADyC,MACzC,EAAA,KAAA,EAAI,EAAS,CAAb,IAAa,IAAb,AAAuB,KAAA,EAAW,CAAA,EAAY,EAA9C,CAA8C,CAAI,GAAlD,KAA2D,EAAQ,KAAA,CAAM,QAAA,EAAU,CAAC,CACpF,OAAA,EAAA,KAAA,EAAI,EAAS,CAAb,KAAa,GAAb,CAAwB,KAAA,EAAW,CAAA,EAAY,CAA/C,EAA+C,CAAI,EAAnD,OAA6D,EAAQ,MAAA,CAAO,QAAA,EAAU,CAAC,QACvF,EAAA,KAAA,EAAI,EAAS,CAAb,QAAA,CAAa,CAAY,EAAA,EAAY,GAAA,CAAI,EAAzC,KAAA,MAAuD,EAAQ,UAAA,CAAW,QAC1E,EAAA,KAAA,EAAI,EAAS,CAAb,QAAA,AAAa,CAAW,EAAA,EAAY,GAAA,CAAI,GAAxC,KAAA,IAAqD,EAAQ,SAAA,CAAU,QACvE,EAAA,KAAA,EAAI,EAAS,CAAb,KAAa,CAAQ,EAArB,AAAqB,EAAY,GAAA,CAAI,MAArC,GAA+C,EAA/C,AAAuD,MAAA,CAAO,CAE9D,IAAM,EAAc,EAAY,QAAA,EAAU,CACpC,EAAM,EAAc,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAA,CAAA,CAAgB,CAAA,EAAGA,KAAK,GAAA,CAAI,OAAA,CAAA,CAI5E,MAAO,CAAE,KAFI,MAAM,EAAIA,KAAK,KAAA,CAAO,EAAK,CAAE,QAASA,KAAK,OAAA,CAAS,CAAC,CAE7C,MAAO,KAAM,OAC3B,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,KAAM,QAAO,AAG9B,OAAM,GAmCV,MAAM,aAAa,CAAA,CASjB,CACA,GAAI,CAOF,MAAO,CAAE,KANI,MAAM,EACjBA,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,QAAA,EAAU,EAAA,CAAA,CACtB,CAAA,CAAE,CACF,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,EAAe,GACjB,GADuB,CACvB,EAAO,CAAE,KAAM,WAAM,EAAO,AAG9B,OAAM,GA+HV,KAAK,CAAA,CAA+C,YAElD,GAAI,CAAC,GvB7UH,IAAqC,SACvC,CADiB,OAAO,GAKX,IAAX,EAAW,MAAA,EAAgB,CChBJ,CDgBe,MAAA,CAAS,KACjD,AAIE,ECrByD,ADqB9C,IAAA,CAJN,MAIiB,CuBmUD,AvB5TrB,EAAA,QAAA,CuB4TgC,AvB5ThC,CuB6TA,KvB7T4B,CANvB,CAMkC,ECzBX,MDyBW,CAAS,KAAK,CACvD,CAAA,CAOF,MAPS,sBAOc,IAAA,CAAK,CChCO,CDQjC,EuB6UE,MAAM,IAAI,EACR,qJAED,CAOH,IAAM,EAAU,IAAI,EAAmB,CACrC,QAAS,IAAA,CAAK,GAAA,CACd,YAAa,EACb,KAAM,CACJ,KAAM,SACN,WAAY,SAAYA,EAAK,OAAA,CAC9B,CACD,MAAO,IAAA,CAAK,KAAA,CACb,CAAC,CAEI,EAAqB,IAAA,CAAK,kBAAA,CAuBhC,OArBuB,IAAI,MAAM,EAAS,CACxC,IAAI,CAAA,CAAQ,CAAA,EAAgC,AAC1C,IAAM,EAAQ,CAAA,CAAO,EAAA,OACrB,AAAqB,WACnB,CADE,AACF,OADS,EACF,EAGF,MAAO,GAAG,KACf,GAAI,CAD+B,AAGjC,MAAO,CAAE,KADI,MAAO,EAAmB,KAAA,CAAM,EAAQ,GACtC,EAD2C,IACpC,KAAM,OACrB,EAAO,CACd,GAAI,EACF,MAAM,EAER,MAAO,CAAE,EAFP,GAEa,WAAa,EAAuB,IAI1D,CAAC,GCvbN,IAAa,GAAkB,CAC7B,gBAAiB,CAAA,WAAA,EAAc,GAAA,CAAA,CAC/B,eAAgB,mBACjB,CCDD,IAAa,GAAb,cAAyC,MAAM,AAG7C,YAAY,CAAA,CAAiB,CAC3B,KAAA,CAAM,QAAQ,AAHN,uBAAA,EAA0B,EAIlC,IAAA,CAAK,IAAA,CAAO,wBAShB,SAAgB,GAAsB,CAAA,EAA8C,AAClF,MAAwB,UAAjB,OAAO,GAAsB,AAAU,UAAQ,4BAA6B,EAOrF,IAAa,GAAb,cAA4C,GAI1C,YAAY,CAAA,CAAiB,CAAA,CAAgB,CAJiB,AAIjB,CAAoB,CAC/D,KAAA,CAAM,GACN,IAAA,CADc,AACT,IAAA,CAAO,yBACZ,IAAA,CAAK,MAAA,CAAS,EACd,IAAA,CAAK,UAAA,CAAa,EAGpB,QAAS,CACP,MAAO,CACL,KAAM,IAAA,CAAK,IAAA,CACX,QAAS,IAAA,CAAK,OAAA,CACd,OAAQ,IAAA,CAAK,MAAA,CACb,WAAY,IAAA,CAAK,UAAA,CAClB,GAQQ,GAAb,cAAgD,GAG9C,YAAY,CAAA,CAAiB,CAAA,CAAwB,CACnD,AAJgE,KAIhE,CAAM,GACN,IAAA,CAAK,AADS,IACT,CAAO,6BACZ,IAAA,CAAK,aAAA,CAAgB,IC/CzB,IAAa,GAAA,AAAgB,GAC3B,AAAI,EACF,CAAQ,GAAG,IAAS,EAApB,CAFwD,AAExD,EAAmC,GAErC,CAAQ,CAFkC,EAAR,AAEvB,IAAS,MAAM,GAAG,GCezB,EDf8B,CCe9B,AAAoB,GACxB,EAAI,GAAA,EAAO,EAAI,OAAA,EAAW,EAAI,iBAAA,EAAqB,EAAI,KAAA,EAAS,KAAK,SAAA,CAAU,GAQ3E,CAR+E,EAQjE,MAClB,EACA,EACA,KAWA,GANE,GACiB,CALhB,SAKD,OAAO,GACP,WAAY,GACZ,OAAQ,GACyB,UAAjC,OAAQ,EAAc,MAAA,EAEF,CAAA,OAAA,EAAA,KAAA,EAAC,EAAS,CAAV,QAAA,IAAU,EAAe,CAC7C,IAAM,CADc,CACJ,EAAc,EADV,IACU,EAAU,IAIN,WAChC,CADE,OAAO,EAAc,IAAA,CACvB,AAJoB,EAKjB,IAAA,EAAM,CACN,IAAA,CAAA,AAAM,IACL,IADkB,AACZ,EAAA,OAAA,EAAA,KAAA,CAAA,CAAa,EAAK,KAAlB,KAAkB,GAAlB,CAAkB,CAAA,GAAlB,IAAkB,KAAA,EAAc,CAAd,CAAmB,IAAA,GAAQ,AAA3B,EAAoC,GAApC,AACxB,EAAO,IAAI,GAAuB,GAAiB,GAAM,CAAF,CAAU,KACjE,CACD,KAF6E,AAE7E,CAF8E,AAE9E,KAIC,CAJW,CAIJ,IAAI,GADK,EAAc,UAAA,EAAc,CAAA,KAAA,EAAQ,EAAO,MAAA,CAAA,CAChB,EAFxB,EAAS,IAEuB,EACnD,CAKJ,EAAO,IAAI,EANuD,CAAC,AAKnD,EAAc,UAAA,EAAc,CAAA,KAAA,EAAQ,EAAO,MAAA,CAAA,CAChB,EAFxB,EAAS,IAEuB,MAGrD,EAAO,GAHyD,CAAC,AAGtD,GAA2B,GAAiB,GAAQ,GAAF,EA4CjE,CA5CyE,CAAC,aA4C3D,GACb,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,EACc,AACd,OAAO,IAAI,QAAA,CAAS,EAAS,WAAW,AACtC,EAAQ,GAnCJU,EAA+B,AAmCtB,CAnCwB,OAmCN,EAnCc,QAAA,CAAA,QAAA,IAAA,CAAA,EAAS,AAmCf,EAnCwB,GAAlB,IAAkB,GAAW,CAAA,CAAE,CAAE,CAEhF,AAAI,AAAW,CAFgC,KAAA,KAEvB,CAAC,AAiCqC,EAhCrD,GAAP,AAGE,AA6B+D,CAAC,AAhClE,AD/DS,AAAiB,IAC5B,GAAqB,GADkC,GCkErC,IDjEd,CCiEmB,EAAE,IDjEd,GAAgC,KACzC,EAD+B,EAC/B,OAAO,EAGT,IAAM,EAAY,OAAO,cAAA,CAAe,GACxC,GAD8C,GAC9C,CACiB,OAAd,GACC,IAAc,OAAO,SAAA,EACgB,OAArC,OAAO,cAAA,CAAe,EAAe,CAAA,EACvC,CAAA,CAAE,GADgC,IACzB,WAAA,IAAe,CAAA,CAAA,EACxB,CAAA,CAAE,OAAO,QAAA,IAAY,CAAA,CAAA,OCwDrB,EAAO,OAAA,CAAA,EAAA,CAAY,eAAgB,kBAAA,EAAA,QAAA,IAAA,CAAA,EAAuB,EAAS,GAAhC,IAAgC,EACnE,EAAO,IAD4B,AAC5B,CAAO,IADqB,CAChB,SAAA,CAAU,IAE7B,CAFkC,CAE3B,IAAA,GAAO,AAGhB,EAAA,EAAA,CAAA,EAAY,GAsBsC,MAtB3B,AAuBlB,IAAA,CAAA,AAAM,IACL,GAAI,CAAC,EAAO,CADI,CACJ,CAAI,MAAM,EACtB,SAAA,EAAA,KAAA,EAAI,EAAS,CAAb,QAAA,IAAa,CAAe,OAAO,AAAnC,EAEA,GAFA,CAEM,EAAc,EAAO,OAAA,CAAQ,GAAA,CAAI,eAAe,QACtD,AAAI,AAAC,GAAgB,EAAY,QAAA,CAAS,CAAtB,kBAAyC,CAC3D,AAEK,CAFL,CAEY,IAAA,EAAM,CAFX,CAAA,CAAE,EAGX,CACD,IAAA,CAAA,AAAM,GAAS,EAAQ,IACvB,CAD4B,CAAC,GAC7B,CAAA,AAAO,GAAU,GAAY,EAAO,EAAQ,KAC/C,CA6BJ,EA9B2D,CAAC,YA8BtC,GACpB,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,EACc,AACd,OAAO,GAAe,EAAS,OAAQ,EAAK,EAAS,EAAY,GC/InE,ED+IwE,EC/InD,GAArB,MAAoC,AAOlC,YAAY,CAAA,CAAa,EAAqC,CAAA,CAAE,CAAE,CAAA,CAAe,MAHvE,kBAAA,EAAqB,EAI7B,IAAA,CAAK,GAAA,CAAM,EAAI,OAAA,CAAQ,MAAO,GAAG,CACjC,IAAA,CAAK,OAAA,CAAA,EAAA,EAAA,CAAA,EAAe,IAAoB,GACxC,IAAA,CAAK,KAAA,CAAQ,GAAaT,GAIrB,KAJ2B,SAIN,CAE1B,OADA,IAAA,CAAK,kBAAA,EAAqB,EACnB,IAAA,CAIT,MAAM,YAAY,CAAA,CAA8D,CAC9E,GAAI,CAIF,MAAO,CAAE,KAHI,MAAM,GAAKD,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,YAAA,CAAA,CAAe,EAAS,CACtE,QAASA,KAAK,OAAA,CACf,CAAC,EACqB,CAAA,CAAE,CAAE,MAAO,KAAM,OACjC,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,GAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,SACJ,CAAA,CACA,CAAA,CAC8C,CAC9C,GAAI,CAOF,MAAO,CAAE,KANI,MAAM,GACjBA,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,SAAA,CAAA,CACZ,kBAAE,YAAkB,EAAW,CAC/B,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,GAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAEvB,AAF8B,OAExB,GAKV,MAAM,YAAY,CAAA,CAAwE,CACxF,GAAI,CAIF,MAAO,CAAE,KAHI,MAAM,GAAKA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,YAAA,CAAA,CAAe,EAAS,CACtE,QAASA,KAAK,OAAA,CACf,CAAC,CACa,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,GAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,YAAY,CAAA,CAA0B,CAAA,CAAoD,CAC9F,GAAI,CAOF,MAAO,CAAE,KANI,MAAM,GACjBA,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,YAAA,CAAA,CACZ,kBAAE,YAAkB,EAAW,CAC/B,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,EACsB,CAAA,CAAE,CAAE,MAAO,KAAM,OACjC,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,GAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAEvB,AAF8B,OAExB,KC9GS,GAArB,MAAmC,AAOjC,YAAY,CAAA,CAAa,EAAqC,CAAA,CAAE,CAAE,CAAA,CAAe,MAHvE,kBAAA,EAAqB,EAI7B,IAAA,CAAK,GAAA,CAAM,EAAI,OAAA,CAAQ,MAAO,GAAG,CACjC,IAAA,CAAK,OAAA,CAAA,EAAA,EAAA,CAAA,EAAe,IAAoB,GACxC,IAAA,CAAK,KAAA,CAAQ,GAAaC,GAIrB,KAJ2B,SAIN,CAE1B,OADA,IAAA,CAAK,kBAAA,EAAqB,EACnB,IAAA,CAIT,MAAM,WAAW,CAAA,CAA6D,CAC5E,GAAI,CAEF,GAAI,EAAQ,OAAA,CAAQ,MAAA,CAAS,GAAK,EAAQ,OAAA,CAAQ,MAAA,CAAS,IACzD,MAAM,AAAI,MAAM,oDAAoD,CAMtE,MAAO,CAAE,KAHI,MAAM,GAAKD,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,WAAA,CAAA,CAAc,EAAS,CACrE,QAASA,KAAK,OAAA,CACf,CAAC,EACqB,CAAA,CAAE,CAAE,MAAO,KAAM,OACjC,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,GAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,KAAM,QAAO,AAE9B,OAAM,GAKV,MAAM,WAAW,CAAA,CAAsE,CACrF,GAAI,CAIF,MAAO,CAAE,KAHI,MAAM,GAAKA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,WAAA,CAAA,CAAc,EAAS,CACrE,QAASA,KAAK,OAAA,CACf,CAAC,CACa,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,GAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,YAAY,CAAA,CAAwE,CACxF,GAAI,CAEF,GAA6B,KAAA,IAAzB,EAAQ,YAAA,CAA4B,CACtC,GAAI,EAAQ,YAAA,CAAe,GAAK,EAAQ,YAAA,CAAe,GACrD,MAAM,AAAI,MAAM,wCAAwC,CAE1D,GAAI,AAAyB,KAAA,GAC3B,GADU,YAAA,GACN,EAAQ,YAAA,CAAe,GAAK,EAAQ,YAAA,EAAgB,EAAQ,YAAA,CAC9D,CAAA,MAAM,AAAI,MAAM,CAAA,mCAAA,EAAsC,EAAQ,YAAA,CAAe,EAAA,CAAA,CAAI,CAQvF,MAAO,CAAE,KAHI,MAAM,GAAKA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,YAAA,CAAA,CAAe,EAAS,CACtE,QAASA,KAAK,OAAA,CACf,CAAC,CACa,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,GAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAEvB,AAF8B,OAExB,GAKV,MAAM,aAAa,CAAA,CAA0E,CAC3F,GAAI,CAIF,MAAO,CAAE,KAHI,MAAM,GAAKA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,aAAA,CAAA,CAAgB,EAAS,CACvE,QAASA,KAAK,OAAA,CACf,CAAC,CACa,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,GAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,cAAc,CAAA,CAAgE,CAClF,GAAI,CAEF,GAAI,EAAQ,IAAA,CAAK,MAAA,CAAS,GAAK,EAAQ,IAAA,CAAK,MAAA,CAAS,IACnD,MAAU,AAAJ,MAAU,kDAAkD,CAMpE,MAAO,CAAE,KAHI,MAAM,GAAKA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,cAAA,CAAA,CAAiB,EAAS,CACxE,QAASA,KAAK,OAAA,CACf,CAAC,EACqB,CAAA,CAAE,CAAE,MAAO,KAAM,OACjC,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,GAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,KCpIS,GAArB,MAAqC,AAOnC,YAAY,CAAA,CAAa,EAAqC,CAAA,CAAE,CAAE,CAAA,CAAe,MAHvE,kBAAA,EAAqB,EAI7B,IAAA,CAAK,GAAA,CAAM,EAAI,OAAA,CAAQ,MAAO,GAAG,CACjC,IAAA,CAAK,OAAA,CAAA,EAAA,EAAA,CAAA,EAAe,IAAoB,GACxC,IAAA,CAAK,KAAA,CAAQ,GAAaC,GAIrB,KAJ2B,SAIN,CAE1B,OADA,IAAA,CAAK,kBAAA,EAAqB,EACnB,IAAA,CAIT,MAAM,aAAa,CAAA,CAA2D,CAC5E,GAAI,CAOF,MAAO,CAAE,KANI,MAAM,GACjBD,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,mBAAA,CAAA,CACZ,kBAAE,CAAA,CAAkB,CACpB,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,EACsB,CAAA,CAAE,CAAE,MAAO,KAAM,OACjC,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,GAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,UAAU,CAAA,CAAgF,CAC9F,GAAI,CAOF,MAAO,CAAE,KANI,MAAM,GACjBA,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,gBAAA,CAAA,CACZ,CAAE,kBAAA,CAAkB,CACpB,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,CACc,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,GAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,YACJ,EAAoC,CAAA,CAAE,CACW,CACjD,GAAI,CAIF,MAAO,CAAE,KAHI,MAAM,GAAKA,KAAK,KAAA,CAAO,CAAA,EAAGA,KAAK,GAAA,CAAI,kBAAA,CAAA,CAAqB,EAAS,CAC5E,QAASA,KAAK,OAAA,CACf,CAAC,CACa,MAAO,KAAM,OACrB,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,GAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,GAKV,MAAM,aAAa,CAAA,CAA2D,CAC5E,GAAI,CAOF,MAAO,CAAE,KANI,MAAM,GACjBA,KAAK,KAAA,CACL,CAAA,EAAGA,KAAK,GAAA,CAAI,mBAAA,CAAA,CACZ,kBAAE,CAAA,CAAkB,CACpB,CAAE,QAASA,KAAK,OAAA,CAAS,CAC1B,EACsB,CAAA,CAAE,CAAE,MAAO,KAAM,OACjC,EAAO,CACd,GAAIA,KAAK,kBAAA,CACP,MAAM,EAER,GAAI,GAAsB,GACxB,GAD8B,CAC9B,EAAO,CAAE,KAAM,WAAM,EAAO,AAE9B,OAAM,KCnCC,GAAb,cAA0C,GAkBxC,YAAY,CAAA,AAlB4C,CAkB/B,EAAuC,CAAA,CAAE,CAAE,CAClE,KAAA,CAAM,EAAK,EAAQ,OAAA,EAAW,CAAA,CAAE,CAAE,EAAQ,KAAA,CAAM,CAqBlD,KAAK,CAAA,CAA6C,CAChD,OAAO,IAAI,GAAkB,IAAA,CAAK,GAAA,CAAK,IAAA,CAAK,OAAA,CAAS,EAAkB,IAAA,CAAK,KAAA,CAAM,CAwBpF,MAAM,aAAa,CAAA,CAA2D,CAC5E,OAAO,AAAP,KAAO,CAAM,aAAb,CAAa,GAAb,CAAa,AAAb,IAAa,CAAa,GAyB5B,MAAM,UAAU,CAAA,CAAgF,CAC9F,OAAO,AAAP,KAAO,CAAM,UAAb,CAAa,GAAb,CAAa,AAAb,IAAa,CAAU,GA2BzB,MAAM,YACJ,EAAoC,CAAA,CAAE,CACW,CACjD,OAAO,AAAP,KAAO,CAAM,YAAb,CAAa,GAAb,CAAa,AAAb,IAAa,CAAY,GAwB3B,MAAM,aAAa,CAAA,CAA2D,CAC5E,OAAA,AAAO,KAAA,CAAM,aAAb,CAAa,GAAb,CAAa,AAAb,IAAa,CAAa,KAajB,GAAb,cAAuC,GAgBrC,YACE,AAjBkD,CAiBlD,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CACA,KAAA,CAAM,EAAK,EAASC,GACpB,IAAA,CAAK,AADqB,gBACrB,CAAmB,EA8B1B,MAAe,YAAY,CAAA,CAAuD,CAChF,OAAO,AAAP,KAAO,CAAM,YAAb,CAAa,GAAb,CAAA,KAAA,EAAA,EAAA,CAAA,EACK,GAAA,CAAA,EAAA,CACH,iBAFW,AAEOD,IAFP,CAEY,gBAAA,IAuB3B,MAAe,YAAY,EAAwD,CAAA,CAAE,CAAE,CACrF,OAAO,AAAP,KAAO,CAAM,YAAb,CAAa,GAAb,CAAA,KAAA,EAAA,EAAA,CAAA,EACK,GAAA,CAAA,EAAA,CACH,iBAFW,AAEOA,IAFP,CAEY,gBAAA,IAwB3B,MAAe,SAAS,CAAA,CAAmB,CACzC,OAAO,AAAP,KAAO,CAAM,SAAb,CAAa,GAAb,CAAA,KAAa,AAASA,IAAT,CAAc,gBAAA,CAAkB,GAsB/C,MAAe,YAAY,CAAA,CAAmB,CAC5C,OAAO,AAAP,KAAO,CAAM,YAAb,CAAa,GAAb,CAAA,KAAa,AAAYA,IAAZ,CAAiB,gBAAA,CAAkB,GAkClD,MAAM,CAAA,CAAqC,CACzC,OAAO,IAAI,GACT,IAAA,CAAK,GAAA,CACL,IAAA,CAAK,OAAA,CACL,IAAA,CAAK,gBAAA,CACL,EACA,IAAA,CAAK,KAAA,CACN,GAaQ,GAAb,cAAsC,GAkBpC,WAlBkD,CAmBhD,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CAAA,CACA,CACA,KAAA,CAAM,EAAK,EAASC,GACpB,IAAA,CAD0B,AACrB,gBAAA,CAAmB,EACxB,IAAA,CAAK,SAAA,CAAY,EA8BnB,MAAe,WAAW,CAAA,CAAoE,CAC5F,OAAO,AAAP,KAAO,CAAM,WAAb,CAAa,GAAb,CAAA,KAAA,EAAA,EAAA,CAAA,EACK,GAAA,CAAA,EAAA,CACH,iBAAkBD,KAAK,gBAAA,CACvB,UAHW,AAGAA,IAHA,CAGK,SAAA,IA0BpB,MAAe,WAAW,CAAA,CAAoE,CAC5F,OAAO,AAAP,KAAO,CAAM,WAAb,CAAa,GAAb,CAAA,KAAA,EAAA,EAAA,CAAA,EACK,GAAA,CAAA,EAAA,CACH,iBAAkBA,KAAK,gBAAA,CACvB,UAAWA,AAHA,IAAA,CAGK,SAAA,IA0BpB,MAAe,YACb,EAAsE,CAAA,CAAE,CACxE,CACA,OAAO,AAAP,KAAO,CAAM,YAAb,CAAa,GAAb,CAAA,KAAA,EAAA,EAAA,CAAA,EACK,GAAA,CAAA,EAAA,CACH,iBAAkBA,KAAK,gBAAA,CACvB,UAAWA,AAHA,IAAA,CAGK,SAAA,IA6BpB,MAAe,aACb,CAAA,CACA,CACA,OAAO,AAAP,KAAO,CAAM,aAAb,CAAa,GAAb,CAAA,KAAA,EAAA,EAAA,CAAA,EACK,GAAA,CAAA,EAAA,CACH,iBAAkBA,KAAK,gBAAA,CACvB,UAAWA,AAHA,IAAA,CAGK,SAAA,IAyBpB,MAAe,cACb,CAAA,CACA,CACA,OAAO,AAAP,KAAO,CAAM,cAAb,CAAa,GAAb,CAAA,KAAA,EAAA,EAAA,CAAA,EACK,GAAA,CAAA,EAAA,CACH,iBAAkBA,KAAK,gBAAA,CACvB,UAAWA,AAHA,IAAA,CAGK,SAAA,MC1lBT,GAAb,cAAmC,GAejC,YACE,CAAA,CAhBgD,AAiBhD,EAAqC,CAAA,CAAE,CACvC,CAAA,CACA,CAAA,CACA,CACA,KAAA,CAAM,EAAK,EAASC,EAAO,GAc7B,EAdkC,GAc7B,CAAA,CAA4B,CAC/B,OAAO,IAAI,GAAe,IAAA,CAAK,GAAA,CAAK,IAAA,CAAK,OAAA,CAAS,EAAI,IAAA,CAAK,KAAA,CAAM,CAcnE,IAAI,SAAgC,CAClC,OAAO,IAAI,GAAqB,IAAA,CAAK,GAAA,CAAM,UAAW,CACpD,QAAS,IAAA,CAAK,OAAA,CACd,MAAO,IAAA,CAAK,KAAA,CACb,CAAC,CAcJ,IAAI,WAAoC,CACtC,OAAO,IAAI,GAAuB,IAAA,CAAK,GAAA,CAAM,WAAY,IAAA,CAAK,OAAA,CAAS,IAAA,CAAK,KAAA,CAAM,sCnC1EtF,IAAI,GAAS,GAEO,GAAhB,AAAgB,oBAAhB,KAAgB,OAEW,aAApB,AACT,GJuBUZ,IAAAA,SIvBV,MAC8B,aAArB,OAAA,WAA0D,eACnE,CAD6C,UAAU,OAAA,CAC9C,eAEA,cAK2B,CACpC,QAH6B,CAGpB,gBAHuC,CAAA,YAAA,EAAe,OAAO,CAAA,EAAG,CAAA,CAAW,EAMzE,GAAqB,CAChC,OAAQ,QAAA,CACT,CAEYC,GAAkD,CAC7D,kBAAkB,EAClB,eAAA,CAAA,EACA,oBAAoB,ILyBpB,mBKrBWC,GAAkD,CAAA,CAAE,gsCS/BjE,cAAwC,GAAA,OAAA,CAAW,AACjD,YAAY,CAAA,CAAA,OACJ,KC+BW,CT2NV,EQ1PO,AC+BlB,kBA4EcsB,CAAAA,CACV,CAAA,CACA,CAAA,CACA,WAHU,IAAA,CAAA,WAAA,CAAA,EACA,IAAA,CAAA,WAAA,CAAA,EAGV,MAAM,EHnCV,AInCM,ADsEc,CCtER,QJmCwB,AAApB,CAAoB,EAClC,IAAA,EAAA,MAAA,EAAA,KAAA,EAAmB,EAAa,IAAA,EAAM,CAEtC,GAAI,CAAC,EACH,MAAA,MAAA,+BAGE,CAAC,EAAW,KAAA,CAAM,iBACpB,MAAA,AAAU,MAAM,2DAGlB,GAAI,QACK,IAAI,IAAI,EAjFN,QAAA,CAAS,OAiFiB,AAjFJ,EAAM,SAiFS,CAAC,GACzC,CACN,MAAM,MAAM,qDGqBwB,OAC/B,EAAA,MAAA,AAAuB,MAAM,iCAE7B,WAAA,CAAc,IAAA,IAAQ,cAAe,QACrC,WAAA,CAAY,QAAA,CAAW,IAAA,CAAK,WAAA,CAAY,QAAA,CAAS,OAAA,CAAQ,OAAQ,KAAK,MACtE,OAAA,CAAU,IAAI,IAAI,UAAW,QAC7B,UAAA,CAAA,IAAA,IAAqB,aAAc,QACnC,YAAA,CAAe,IAAI,IAAI,eAAA,GAG5B,MAAM,EAAoB,CAAA,CCvExB,EDuEwB,EAAM,EAAA,QAAA,CAAA,KAAA,CAAuB,IAAA,CAAK,CFmBhD,CAAA,CEnBmD,WAAA,CAAA,CAQzD,EAAW,SH/GnB,CAAA,CAAA,CAAA,UAGA,GAAM,CACJ,GDgBE,AChBE,CAAA,CACJ,KAAM,CAAA,CACN,SAAU,CAAA,CACV,OAAQ,CAAA,CAAA,CACN,EACE,CACJ,CDWE,EAAA,CAAA,CCVF,KAAMX,CAAAA,CACN,SAAUC,CAAAA,CACV,OAAQC,CAAAA,CAAAA,CACN,EAEEC,EAAAA,CACJ,GAAA,GAAA,GAAA,CAAA,EACKC,GACA,GAEL,KAAA,GAAA,GAAA,CAAA,EACKJ,GACA,qBAGAC,GACA,WAEI,CAAA,EACT,OAAA,GAAA,GAAA,GAAA,CAAA,EACKC,GACA,GAAA,CAAA,EAAA,CACH,QAAA,GAAA,GAAA,CAAA,EAAA,OAAA,QAAA,EAAA,KAAA,EACMA,EAAwB,OAAA,EAAA,EAAW,CAAA,CAAE,AAAb,EAAa,GAD3C,GAC8B,CAAa,IAD3C,IAC2C,EAAA,KAAA,EACrC,EAAe,MADS,CAAa,AACtB,EAAA,EAAW,AADF,CACE,CAAE,AAAb,CAFrB,AAEkC,CADS,EAI7C,EALE,EAEqB,QAGV,IAJgC,KAAA,AAIhC,SAHU,IAMb,CANa,UAMb,CACV,EAAO,WAAA,CAAc,EAAQ,WAAA,CAG7B,OAAA,EAAuB,WAAA,UGkEe,EAAA,EAAW,CAAA,CAAE,CAPlC,CACf,AAMmD,GAN/C,GCvEJ,ADwEA,GAK4D,MALlD,GACV,KAAA,GAAA,GAAA,CAAA,EAAW,IAAA,CAAA,EAAA,CAAsB,WAAY,CAAA,GAC7C,OAAQ,cCtER,MD2EG,CAAA,OAAA,EAAa,EAAA,IAAA,CAAA,UAAA,EAAA,EAA4B,yBAC/B,EAAS,MAAA,CAAO,OAAA,EAAA,EAAW,CAAA,CAAX,AAAa,CAEvC,EAAS,KAFiB,MAEjB,OAOP,WAAA,CAAc,CATU,CASD,IATC,OASD,MAEvB,IAAA,CAAO,IAAI,MAA0B,CAAA,CAAE,CAAS,CACnD,IAAA,CAAM,EAAG,WACD,AAAI,MAAA,CAAA,0GAAA,EACqG,OAC3G,GACA,EAAD,cAAC,CAAA,CACH,KAdL,IAAA,CAAK,IAAA,CAAO,IAAA,CAAA,uBAAA,CAAA,MAAA,CAAA,EACV,EAAS,IAAA,EAAA,EAAQ,CAAA,CAAE,CACnB,IAAA,CAAK,OAAA,CACL,EAAS,MAAA,CAAO,KAAA,CACjB,CAeH,IAAA,CAAK,KAAA,CAAQ,ELjJf,EACA,EACA,KAEA,IAAMH,IAdJ,CAAQ,CADN,EACS,EAcC,EAAa,AAdc,GJyIL,EIzIoB,EAAtD,CAEF,CAAQ,CAFqD,EAElD,IAA4B,SAAS,GJ4If,AI/H3B,EATC,AAJ8C,CToKnD,kBSvJyB,IAEN,ECHF,SDIjB,IAAM,EAAA,MAH8C,AAG9C,CAAA,EAAe,MAAM,GAAA,CAAgB,CAAA,EAAK,EAC5C,EAAU,IAAI,EAAA,MAAA,EAAA,KAAA,EAAmB,EAAM,OAAA,CAAQ,CAUnD,OARI,AAAC,EAAQ,GAAA,CAAI,WACf,EAAA,GAAA,CAAY,SAAU,GAGnB,EAAQ,GAAA,CAAA,kBACX,EAAQ,GAAA,CAAI,gBAAiB,CAAA,OAAA,EAAU,EAAA,CAAA,CAAc,CAGvD,EAAa,EAAA,GAAA,GAAA,CAAA,EAAY,GAAA,CAAA,EAAA,SAAM,CAAA,GAAU,IK8Hd,EAAa,CClFD,GAAA,CAAA,eAAA,CDkFsB,IAAA,CAAK,IAAA,CAAK,CAAE,EAAS,MAAA,CAAO,KAAA,CAAM,MAC1F,QAAA,CAAW,IAAA,CAAK,mBAAA,CAAA,GAAA,CACnB,QAAS,IAAA,CAAK,OAAA,aACD,GCjFL,CAAA,CDiFU,eAAA,CAAgB,IAAA,CAAK,IAAA,CAAK,EACzC,EAAS,QAAA,GAEd,IAAA,CAAS,WAAA,CAEP,CAAA,IAAA,CAAK,WAAA,EAAa,CACf,IAAA,CAAA,AAAM,GAAU,IAAA,CAAK,QAAA,CAAS,OAAA,CAAQ,IACtC,EAD4C,CAAC,EAC7C,CAAA,AAAO,GAAM,QAAQ,IAAA,CAAK,6CAA8C,EAAE,CAAC,MAG3E,IAAA,CAAO,IAAI,EAAgB,IAAI,IAAI,UAAW,GAAS,IAAA,CAAD,AAAO,CAChE,QAAS,IAAA,CAAA,OAAA,CACT,OAAQ,EAAS,EAAA,CAAG,MAAA,CACpB,MAAO,IAAA,CAAK,KAAA,GAGd,IAAA,CAAA,OAAA,CAAe,CG9HT,GH8HagB,GACjB,IAAA,CAAK,UAAA,CAAW,IAAA,CAChB,IAAA,CAAK,OAAA,CACL,IAAA,CAAK,KAAA,OAAA,EAAA,KAAA,EACL,EAAS,CADJ,MACI,CACV,CAEI,AAJE,EAIF,UAJE,CAIF,EACH,EALK,EAKL,CAAK,SC9FgC,WAAA,GDqGzC,IAAI,WAAA,QACK,IAAI,EAAA,eAAA,CAAgB,IAAA,CAAK,YAAA,CAAa,IAAA,CAAM,CACjD,QAAS,IAAA,CAAK,OAAA,CACd,YAAa,CC/FN,GAAA,CD+FW,KAAA,GAiBtB,KAAK,CAAA,CAAA,QACI,IAAA,CAAK,IAAA,CAAK,IAAA,CAAK,SAAS,IAmB/B,OAAO,IAAA,CAAK,IAAA,CAAK,MAAA,CAAsB,GA2BzC,IASE,CAAA,CACA,EAAA,CAAA,CAAA,CACA,EAII,OACI,EACN,KAAK,EACL,MAAO,KAAA,EACR,CASD,QACO,IAAA,CAAK,IAAA,CAAK,GAAA,CAAI,EAAA,EAAU,GAkBjC,QAAQ,CAAA,CAAA,EAA6C,CAAE,OAAQ,CAAA,CAAE,CAAE,CAAmB,QAC7E,IAAA,CAAK,QAAA,CAAS,OAAA,CAAQ,EAAM,CMxPH,INwPQ,WAMT,CAC/B,OAAO,IAAA,CAAK,QAAA,CAAS,WAAA,GASvB,cAAc,CAAA,CAAiE,QACtE,IAAA,CAAA,QAAA,CAAc,aAAA,CAAc,GAMrC,mBAA+D,CAC7D,OAAO,IAAA,CAAK,QAAA,CAAS,iBAAA,GAGvB,MAAc,iBAAkB,SAC9B,GAAA,KAAS,WAAA,CAAA,OACA,MAAMjB,KAAK,WAAA,GAGpB,GAAM,MAAE,CAAA,CAAA,CAAA,MAAeA,KAAK,IAAA,CAAK,UAAA,4BAE1B,EAAK,OAAA,EAAA,KAAA,EAAA,EAAS,YAAA,EAAA,EAAgBA,EAAhB,GAAqB,KAArB,MAAqB,oBAArB,KAAA,AAIrB,kBACE,CAAA,gBACA,CAAA,oBACA,CAAA,SACA,CAAA,CACA,aAAA,CACA,YAAA,UACA,CAAA,MACA,CAAA,OACA,CAAA,cACA,CAAA,CAAA,CAEF,CAAA,CACA,CAAA,CACA,CACA,IAAA,EAAoB,yBACO,IAAA,CAAA,WAAA,CAAA,CAAA,CACzB,OAAQ,CAAA,EAAG,IAAA,CAAK,WAAA,CAAA,CAAA,SAEX,IAAI,GAAmB,CAC5B,IAAK,GG5H+B,CH4H/B,CAAA,OAAK,CAAQ,IAAA,CAClB,QAAA,GAAA,GAAA,CAAA,EAAc,GAAgB,cAClB,EACZ,kCACA,qBACA,UACA,yBAEA,eAEA,eACA,EACA,MAAA,EAGA,6BAA8B,OAAO,IAAA,CAAK,IAAA,CAAA,OAAA,EAAc,IAAA,CAAA,AACrD,GAA8B,gBAChC,EADU,EAAI,WAAA,EAAa,IAKxB,oBAAoB,CAAA,CAAgC,CAC1D,OAAO,IAAI,EAAA,OAAA,CAAe,IAAA,CAAK,WAAA,CAAY,IAAA,CAAA,GAAA,GAAA,CAAA,EACtC,GAAA,CAAA,EAAA,CACH,OAAA,GAAA,GAAA,CAAA,EAAa,CAAE,OAAQ,IAAA,CAAK,WAAA,CAAa,QAAA,EAAA,KAAA,EAAK,EAAS,CAAd,KAAc,CAAA,EAAd,CACzC,CAGI,UAJqC,KAAA,OAId,IMxOF,CACvB,GNwOS,IAAA,CAAK,IAAA,CAAK,iBAAA,CAAA,CAAmB,EAAO,KAC/C,IAAA,CAAK,EADsD,iBACtD,CAAoB,EAAO,eAAA,EAAA,KAAA,EAAU,EAAS,CAAnB,QAAA,GAAmB,CAAa,GAK5D,KAL4B,KAAA,UAMlC,CAAA,CACA,CAAA,CACA,CAAA,CACA,EAEa,oBAAV,GAAyC,cAAV,CAAU,CAAA,EAC1C,IAAA,CAAK,kBAAA,GAAuB,OAC5B,CACK,kBAAA,CAAqB,OACrB,QAAA,CAAS,OAAA,CAAQ,IACH,cAAc,CAAxB,OK9N8B,CAAA,CL+NlC,QAAA,CAAS,OAAA,EAAS,CACT,UAAW,CAArB,GAAqB,IAAA,CAAK,IAAA,CAAK,OAAA,EAAS,CAC5C,IAAA,CAAK,kBAAA,CAAqB,KAAA,IOjUhC,CAAA,UA3BS,EAQP,IAAA,EAAkB,WAAmB,OAAA,IACjC,CAT2C,AAS1C,EACH,OAAO,EAGT,IAAM,EAAiB,EAAS,MAAT,CAAS,UAC5B,EACF,OAAO,EAGT,IAAM,EAAe,EAAe,AAJb,KAIa,AAJb,CAImB,IAJN,QAIkB,QAClD,CAAC,EALkD,CAUhC,IATrB,AAQmB,MAHnB,CAAA,EAG4B,CAAA,CAAa,EAAA,CAAI,AAHtC,GAGyC,MAIpD,QACU,EFqI2B,EAAA,CEpIjC,MFoImD,CAAA,uOEjIpD,CxB1FH,IAAM,OwBkDO,GxBjDX,CADe,OACP,GAAG,CAAC,AwBkDV,YxBlDsB,CwBmDtB,CxBnD0B,GAC5B,QAAQ,GAAG,CAAC,yBAAyB,EAAI,GwBmDvC,GxBhDE,GAAe,CACnB,CwBgDC,WxBhDY,CAAE,KAAM,OAAQ,SAAU,oBAAqB,EAC5D,aAAc,CAAE,KAAM,OAAQ,SAAU,UAAW,EACnD,WAAY,CAAE,KAAM,OAAQ,SAAU,UAAW,EACjD,aAAc,CAAE,KAAM,OAAQ,SAAU,UAAW,EACnD,iBAAkB,CAAE,KAAM,OAAQ,SAAU,UAAW,CACzD,EAUO,eAAe,GAAK,CAAO,EAChC,GAAI,CACF,IAQI,EARE,EAAO,MAAM,EAAQ,IAAI,GACzB,EAXV,AAWqB,SAXZ,AAAgB,CAAI,EAC3B,GAAM,OAAE,CAAK,UAAE,CAAQ,MAAE,CAAI,MAAE,CAAI,CAAE,CAAG,SACxC,AAAI,AAAC,GAAU,EAAY,CAAC,EAAM,CAApB,AACT,CAD+B,CAEtB,QADC,QACX,CAA2B,EAAC,AAAC,GAAS,EACnC,EADuC,CAAL,EAAe,AAAP,6CAD3B,uBADqB,eAI7C,EAKqC,GACjC,GAAI,EAAU,OAAO,EAAA,YAAY,CAAC,IAAI,CAAC,CAAE,OAAQ,QAAS,QAAS,CAAS,EAAG,CAAE,OAAQ,GAAI,GAE7F,GAAM,OAAE,CAAK,UAAE,CAAQ,MAAE,CAAI,CAAE,MAAI,SAAE,CAAO,CAAE,CAAG,EAC3C,EAAM,EAAY,CAAC,EAAM,CACzB,EAAM,IAAI,OAAO,WAAW,GAGlC,GAAiB,SAAb,EAAI,IAAI,CAAa,CACvB,IAAI,EACJ,GAAI,CACF,EAA4B,UAAnB,OAAO,EAAuB,KAAK,KAAK,CAAC,GAAW,CAC/D,CAAE,MAAO,EAAG,CACV,OAAO,EAAA,YAAY,CAAC,IAAI,CAAC,CAAE,OAAQ,QAAS,QAAS,4BAA6B,EAAG,CAAE,OAAQ,GAAI,EACrG,CAEE,EADY,eAAe,CAAzB,EACQ,MAAE,OAAM,EAAM,WAAU,aAAc,EAAQ,WAAY,EAAK,UAAW,CAAI,EAE9E,UAAE,EAAU,UAAW,OAAQ,aAAc,EAAQ,WAAY,EAAK,UAAW,CAAI,CAEnG,MAEE,CAFK,CAEK,UAAE,EAAU,UAAW,OAAQ,aAAc,GAAW,GAAI,WAAY,EAAK,UAAW,CAAI,EAGxG,GAAM,OAAE,CAAK,CAAE,CAAG,MAAM,GACrB,IAAI,CAAC,GACL,MAAM,CAAC,EAAS,CAAE,WAAY,EAAI,QAAQ,CAAE,kBAAkB,CAAM,GAEvE,GAAI,EACF,KADS,EACF,EAAA,YAAY,CAAC,IAAI,CAAC,CAAE,OAAQ,QAAS,QAAS,EAAM,OAAO,AAAC,EAAG,CAAE,OAAQ,GAAI,GAGtF,OAAO,EAAA,YAAY,CAAC,IAAI,CAAC,CAAE,OAAQ,gBAAW,WAAO,EAAU,WAAY,CAAI,EACjF,CAAE,MAAO,EAAO,CACd,OAAO,EAAA,YAAY,CAAC,IAAI,CAAC,CAAE,OAAQ,QAAS,QAAS,EAAM,OAAO,AAAC,EAAG,CAAE,OAAQ,GAAI,EACtF,CACF,4BCrDA,IAAA,GAAA,EAAA,CAAA,CAAA,OAIA,IAAM,GAAc,IAAI,EAAA,mBAAmB,CAAC,CACxC,WAAY,CACR,KAAM,EAAA,SAAS,CAAC,SAAS,CACzB,KAAM,2BACN,SAAU,qBACV,SAAU,QACV,WAAY,EAChB,EACA,QAAS,CAAA,OACT,IADiD,eACc,CAA3C,EACpB,iBAAkB,2CAClB,iBAZqB,GAarB,SAAA,EACJ,GAIM,kBAAE,EAAgB,sBAAE,EAAoB,aAAE,EAAW,CAAE,CAAG,GAChE,SAAS,KACL,MAAO,CAAA,EAAA,EAAA,UAAA,AAAW,EAAC,kBACf,wBACA,EACJ,EACJ,CAEO,eAAe,GAAQ,CAAG,CAAE,CAAG,CAAE,CAAG,EACnC,GAAY,KAAK,EAAE,AACnB,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,EAAK,+BAAgC,QAAQ,MAAM,CAAC,MAAM,IAE7E,IAAI,EAAU,2BAKV,EAAU,EAAQ,OAAO,CAAC,WAAY,KAAO,IAMjD,IAAM,EAAgB,MAAM,GAAY,OAAO,CAAC,EAAK,EAAK,SACtD,EACA,mBAHE,CAAA,CAIN,GACA,GAAI,CAAC,EAID,OAHA,EAAI,IADY,MACF,CAAG,IACjB,EAAI,GAAG,CAAC,eACS,MAAjB,CAAwB,CAApB,IAAyB,KAAhB,EAAoB,EAAI,SAAS,CAAC,IAAI,CAAC,EAAK,QAAQ,OAAO,IACjE,KAEX,GAAM,SAAE,CAAO,QAAE,CAAM,YAAE,CAAU,WAAE,CAAS,aAAE,CAAW,mBAAE,CAAiB,CAAE,qBAAmB,sBAAE,CAAoB,yBAAE,CAAuB,kBAAE,CAAgB,yBAAE,CAAuB,uBAAE,CAAqB,CAAE,CAAG,EACnN,EAAoB,CAAA,EAAA,EAAA,gBAAA,AAAgB,EAAC,GACvC,GAAQ,CAAQ,GAAkB,aAAa,CAAC,EAAkB,EAAI,EAAkB,MAAM,CAAC,EAAA,AAAiB,EAC9G,EAAY,WAEa,MAAvB,EAA8B,KAAK,EAAI,EAAoB,SAAA,AAAS,EAAE,AACtE,MAAM,EAAoB,SAAS,CAAC,EAAK,EAAK,GAAW,GAEzD,EAAI,GAAG,CAAC,gCAEL,MAEX,GAAI,GAAS,CAAC,EAAa,CACvB,IAAM,GAAgB,CAAQ,EAAkB,MAAM,CAAC,EAAiB,CAClE,EAAgB,EAAkB,aAAa,CAAC,EAAkB,CACxE,GAAI,IAC+B,IAA3B,EAAc,KADH,GACW,EAAc,CAAC,EAAe,CACpD,GAAI,EAAW,YAAY,CAAC,WAAW,CACnC,CADqC,MAC9B,MAAM,GAEjB,OAAM,IAAI,EAAA,eAAe,AAC7B,CAER,CACA,IAAI,EAAW,MACX,GAAU,GAAY,GAAb,EAAkB,EAAK,EAAD,EAG/B,EAAW,AAAa,OAHqB,IAC7C,GAAW,CAAA,EAEwB,IAAM,CAAA,EAE7C,IAAM,GACgB,IAAtB,GAAY,CAAkB,IAAb,EAEjB,CAAC,EAKK,EAAqB,GAAS,CAAC,EAIjC,GAAyB,GACzB,CAAA,EAAA,EAAA,iBADkD,IAClD,AAAqB,EAAC,CAClB,KAAM,YAbqF,cAc3F,EACA,uBACJ,GAEJ,IAAM,EAAS,EAAI,MAAM,EAAI,MACvB,EAAS,CAAA,EAAA,EAAA,SAAA,AAAS,IAClB,EAAa,EAAO,kBAAkB,GACtC,EAAU,QACZ,oBACA,EACA,WAAY,CACR,aAAc,CACV,gBAAgB,CAAQ,EAAW,YAAY,CAAC,cAAc,AAClE,EACA,iBAAiB,CAAQ,EAAW,eAAe,yBACnD,EACA,iBAAkB,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,EAAK,oBACtC,kBAAmB,EAAW,SAAS,CACvC,UAAW,EAAI,SAAS,CACxB,QAAU,AAAD,IACL,EAAI,EAAE,CAAC,QAAS,EACpB,EACA,sBAAkB,EAClB,8BAA+B,CAAC,EAAO,EAAU,EAAc,IAAa,GAAY,cAAc,CAAC,EAAK,EAAO,EAAc,EAAY,EACjJ,EACA,cAAe,SACX,CACJ,CACJ,EACM,EAAc,IAAI,EAAA,eAAe,CAAC,GAClC,EAAc,IAAI,EAAA,gBAAgB,CAAC,GACnC,EAAU,EAAA,kBAAkB,CAAC,mBAAmB,CAAC,EAAa,CAAA,EAAA,EAAA,sBAAA,AAAsB,EAAC,IAC3F,GAAI,CACA,IAAM,EAAoB,MAAO,GACtB,GAAY,MAAM,CAAC,EAAS,GAAS,OAAO,CAAC,KAChD,GAAI,CAAC,EAAM,OACX,EAAK,aAAa,CAAC,CACf,mBAAoB,EAAI,UAAU,CAClC,YAAY,CAChB,GACA,IAAM,EAAqB,EAAO,qBAAqB,GAEvD,GAAI,CAAC,EACD,OAEJ,GAAI,EAAmB,GAAG,CAAC,EAHF,kBAGwB,EAAA,cAAc,CAAC,aAAa,CAAE,YAC3E,QAAQ,IAAI,CAAC,CAAC,2BAA2B,EAAE,EAAmB,GAAG,CAAC,kBAAkB,qEAAqE,CAAC,EAG9J,IAAM,EAAQ,EAAmB,GAAG,CAAC,cACrC,GAAI,EAAO,CACP,IAAM,EAAO,CAAA,EAAG,EAAO,CAAC,EAAE,EAAA,CAAO,CACjC,EAAK,aAAa,CAAC,CACf,aAAc,EACd,aAAc,EACd,iBAAkB,CACtB,GACA,EAAK,UAAU,CAAC,EACpB,MACI,CADG,CACE,UAAU,CAAC,CAAA,EAAG,EAAO,CAAC,EAAE,EAAA,CAAS,CAE9C,GAEE,GAAgB,CAAoC,CAAA,EAAA,EAAA,EAA5B,YAA4B,AAAc,EAAC,EAAK,eACxE,EAAiB,MAAO,QACtB,EA4FI,EA3FR,IAAM,EAAoB,MAAO,oBAAE,CAAkB,CAAE,IACnD,GAAI,CACA,GAAI,CAAC,GAAiB,GAAwB,GAA2B,CAAC,EAKtE,OAJA,EAAI,SADsF,CAC5E,CAAG,IAEjB,EAAI,SAAS,CAAC,iBAAkB,eAChC,EAAI,GAAG,CAAC,gCACD,KAEX,IAAM,EAAW,MAAM,EAAkB,GACzC,EAAI,YAAY,CAAG,EAAQ,UAAU,CAAC,YAAY,CAClD,IAAI,EAAmB,EAAQ,UAAU,CAAC,gBAAgB,CAGtD,GACI,EAAI,SAAS,EAAE,CACf,CAFc,CAEV,SAAS,CAAC,GACd,OAAmB,GAG3B,IAAM,EAAY,EAAQ,UAAU,CAAC,aAAa,CAGlD,IAAI,EA6BA,OADA,MAAM,CAAA,EAAA,EAAA,YAAY,AAAZ,EAAa,EAAa,EAAa,EAAU,EAAQ,UAAU,CAAC,gBAAgB,EACnF,IA7BA,EACP,IAAM,EAAO,MAAM,EAAS,IAAI,GAE1B,EAAU,CAAA,EAAA,EAAA,yBAAyB,AAAzB,EAA0B,EAAS,OAAO,CACtD,KACA,CAAO,CAAC,EAAA,EADG,oBACmB,CAAC,CAAG,CAAA,EAElC,CAAC,CAAO,CAAC,eAAe,EAAI,EAAK,IAAI,EAAE,CACvC,CAAO,CAAC,eAAe,CAAG,EAAK,IAAA,AAAI,EAEvC,IAAM,EAAa,KAAkD,IAA3C,EAAQ,UAAU,CAAC,mBAAmB,IAAoB,EAAQ,UAAU,CAAC,mBAAmB,EAAI,EAAA,cAAA,AAAc,GAAG,AAAQ,EAAQ,UAAU,CAAC,mBAAmB,CACvL,EAAS,KAA8C,IAAvC,EAAQ,UAAU,CAAC,eAAe,EAAoB,EAAQ,UAAU,CAAC,eAAe,EAAI,EAAA,cAAc,MAAG,EAAY,EAAQ,UAAU,CAAC,eAAe,CAcjL,MAZmB,CAYZ,AAXH,MAAO,CACH,KAAM,EAAA,eAAe,CAAC,SAAS,CAC/B,OAAQ,EAAS,MAAM,CACvB,KAAM,OAAO,IAAI,CAAC,MAAM,EAAK,WAAW,YACxC,CACJ,EACA,aAAc,YACV,SACA,CACJ,CACJ,CAEJ,CAKJ,CAAE,KALS,CAKF,EAAK,CAeV,MAZI,AAAsB,QAAO,KAAK,EAAI,EAAmB,OAAO,AAAP,EAAS,CAElE,MAAM,GAAY,cAAc,CAAC,EAAK,EAAK,CACvC,WAAY,aACZ,UAAW,EACX,UAAW,QACX,iBAAkB,CAAA,EAAA,EAAA,mBAAA,AAAmB,EAAC,oBAClC,EACA,sBACJ,EACJ,GATmB,AAShB,EAAY,GAEb,CACV,CACJ,EACM,EAAa,MAAM,GAAY,cAAc,CAAC,KAChD,aACA,WACA,EACA,UAAW,EAAA,SAAS,CAAC,SAAS,CAC9B,YAAY,oBACZ,EACA,mBAAmB,uBACnB,0BACA,oBACA,EACA,UAAW,EAAI,SAAS,eACxB,CACJ,GAEA,GAAI,CAAC,EACD,KADQ,EACD,KAEX,GAAI,CAAe,MAAd,CAAqB,EAAS,AAA0C,GAA9C,IAAK,EAAoB,EAAW,KAAA,AAAK,EAAY,KAAK,EAAI,EAAkB,IAAI,IAAM,EAAA,eAAe,CAAC,SAAS,CAE9I,CAFgJ,KAE1I,OAAO,cAAc,CAAC,AAAI,MAAM,CAAC,kDAAkD,EAAgB,MAAd,CAAqB,EAAS,AAA2C,GAA/C,IAAK,EAAqB,EAAW,KAAK,AAAL,EAAiB,KAAK,EAAI,EAAmB,IAAI,CAAA,CAAE,EAAG,oBAAqB,CACjO,MAAO,OACP,WAAY,GACZ,cAAc,CAClB,EAEA,CAAC,GACD,EAAI,SAAS,CADG,AACF,iBAAkB,EAAuB,cAAgB,EAAW,MAAM,CAAG,OAAS,EAAW,OAAO,CAAG,QAAU,OAGnI,GACA,EAAI,QADS,CACA,CAAC,gBAAiB,2DAEnC,IAAM,EAAU,CAAA,EAAA,EAAA,2BAAA,AAA2B,EAAC,EAAW,KAAK,CAAC,OAAO,EAcpE,OAbI,AAAE,CAAD,EAAkB,GACnB,EADwB,AAChB,GADmB,GACb,CAAC,EAAA,sBAAsB,GAIrC,EAAW,YAAY,EAAK,EAAD,AAAK,SAAS,CAAC,kBAAqB,EAAD,AAAS,GAAG,CAAC,kBAAkB,AAC7F,EAAQ,GAAG,CAAC,gBAAiB,CAAA,EAAA,EAAA,qBAAA,AAAqB,EAAC,EAAW,YAAY,GAE9E,MAAM,CAAA,EAAA,EAAA,YAAA,AAAY,EAAC,EAAa,EAChC,IAAI,SAAS,EAAW,KAAK,CAAC,IAAI,CAAE,SAChC,EACA,OAAQ,EAAW,KAAK,CAAC,MAAM,EAAI,GACvC,IACO,IACX,EAGI,EACA,MAAM,EAAe,EADT,CAGZ,MAAM,EAAO,qBAAqB,CAAC,EAAI,OAAO,CAAE,IAAI,EAAO,KAAK,CAAC,EAAA,cAAc,CAAC,aAAa,CAAE,CACvF,SAAU,CAAA,EAAG,EAAO,CAAC,EAAE,EAAA,CAAS,CAChC,KAAM,EAAA,QAAQ,CAAC,MAAM,CACrB,WAAY,CACR,cAAe,EACf,cAAe,EAAI,GAAG,AAC1B,CACJ,EAAG,GAEf,CAAE,MAAO,EAAK,CAeV,GAdM,aAAe,EAAA,eAAe,EAEhC,CAFmC,KAE7B,GAAY,cAAc,CAAC,EAAK,EAAK,CACvC,WAAY,aACZ,UAAW,EACX,UAAW,QACX,iBAAkB,CAAA,EAAA,EAAA,mBAAA,AAAmB,EAAC,oBAClC,uBACA,CACJ,EACJ,GAAG,AATgB,EASJ,GAIf,EAAO,MAAM,EAKjB,OAHA,MAAM,CAAA,EAAA,EAAA,YAAA,AAAY,EAAC,EAAa,EAAa,IAAI,SAAS,KAAM,CAC5D,OAAQ,GACZ,IACO,IACX,CACJ,EAEA,qCAAqC","ignoreList":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42]}