module.exports=[75351,e=>{"use strict";var t=e.i(47909),a=e.i(74017),s=e.i(96250),n=e.i(59756),i=e.i(61916),r=e.i(74677),l=e.i(69741),o=e.i(16795),c=e.i(87718),d=e.i(95169),h=e.i(47587),p=e.i(66012),f=e.i(70101),u=e.i(26937),_=e.i(10372),E=e.i(93695);e.i(52474);var m=e.i(220);let y=e.r(22734),g=e.r(14747),D=e.r(54799),{NextResponse:O}=e.r(89171),b=e.r(75667),{mapFileToTable:N,getFileExtension:w,ALLOWED_EXTENSIONS:S,IGNORED_DIRS:C,getPublicDir:R}=e.r(77953);async function T(e){console.log("ðŸ”„ Syncing /public (Postgres)...");let t=I(),a={new:0,modified:0,deleted:0};try{let s=await e`SELECT file_path, file_hash, table_name FROM sync_manifest`,n=new Map((s||[]).map(e=>[e.file_path,e]));for(let e of t){let t=n.get(e.relativePath);t?t.file_hash!==e.hash&&a.modified++:a.new++}for(let[e]of n)!t.find(t=>t.relativePath===e)&&a.deleted++}catch(e){return{status:"error",operation:"syncopublic",error:e.message}}return{status:"success",operation:"syncopublic",files_scanned:t.length,changes:a}}async function v(e){console.log("ðŸ“¥ Pumping data (Postgres)...");let t=I(),a=0;for(let s of t){let t=g.basename(s.relativePath,g.extname(s.relativePath)),n=w(s.relativePath),i=new Date().toISOString();try{await e`
        INSERT INTO sync_manifest (file_path, file_hash, table_name, last_synced)
        VALUES (${s.relativePath}, ${s.hash}, ${s.table}, ${i})
        ON CONFLICT (file_path) DO UPDATE SET file_hash = EXCLUDED.file_hash, table_name = EXCLUDED.table_name, last_synced = EXCLUDED.last_synced
      `}catch{}try{switch(s.table){case"collections":{let n=s.relativePath.split(g.sep),r=n.findIndex(e=>"collections"===e);if(-1!==r&&r+2<n.length){let l=n[r+1],o=n[r+2],c=JSON.parse(s.content);await e`
              INSERT INTO collections (lang, type, filename, file_content, file_hash, synced_at)
              VALUES (${l}, ${o}, ${t}, ${e.json(c)}, ${s.hash}, ${i})
              ON CONFLICT (lang, type, filename)
              DO UPDATE SET file_content = EXCLUDED.file_content, file_hash = EXCLUDED.file_hash, synced_at = EXCLUDED.synced_at
            `,a++}break}case"static_files":await e`
            INSERT INTO static_files (filename, file_type, file_content, file_hash, synced_at)
            VALUES (${t}, ${n}, ${s.content}, ${s.hash}, ${i})
            ON CONFLICT (filename) DO UPDATE SET file_type = EXCLUDED.file_type, file_content = EXCLUDED.file_content, file_hash = EXCLUDED.file_hash, synced_at = EXCLUDED.synced_at
          `,a++;break;case"config_files":{let r=JSON.parse(s.content);await e`
            INSERT INTO config_files (filename, file_type, file_content, file_hash, synced_at)
            VALUES (${t}, ${n}, ${e.json(r)}, ${s.hash}, ${i})
            ON CONFLICT (filename) DO UPDATE SET file_type = EXCLUDED.file_type, file_content = EXCLUDED.file_content, file_hash = EXCLUDED.file_hash, synced_at = EXCLUDED.synced_at
          `,a++;break}case"data_files":{let r=JSON.parse(s.content);await e`
            INSERT INTO data_files (filename, file_type, file_content, file_hash, synced_at)
            VALUES (${t}, ${n}, ${e.json(r)}, ${s.hash}, ${i})
            ON CONFLICT (filename) DO UPDATE SET file_type = EXCLUDED.file_type, file_content = EXCLUDED.file_content, file_hash = EXCLUDED.file_hash, synced_at = EXCLUDED.synced_at
          `,a++;break}case"images":await e`
            INSERT INTO images (filename, file_path, mime_type, file_hash, synced_at)
            VALUES (${t}, ${s.relativePath}, ${`image/${n}`}, ${s.hash}, ${i})
            ON CONFLICT (filename) DO UPDATE SET file_path = EXCLUDED.file_path, mime_type = EXCLUDED.mime_type, file_hash = EXCLUDED.file_hash, synced_at = EXCLUDED.synced_at
          `,a++;break;case"resumes":await e`
            INSERT INTO resumes (filename, file_type, file_path, file_hash, synced_at)
            VALUES (${t}, ${n}, ${s.relativePath}, ${s.hash}, ${i})
            ON CONFLICT (filename) DO UPDATE SET file_type = EXCLUDED.file_type, file_path = EXCLUDED.file_path, file_hash = EXCLUDED.file_hash, synced_at = EXCLUDED.synced_at
          `,a++;break;case"javascript_files":await e`
            INSERT INTO javascript_files (filename, file_path, file_content, file_hash, synced_at)
            VALUES (${t}, ${s.relativePath}, ${s.content}, ${s.hash}, ${i})
            ON CONFLICT (filename) DO UPDATE SET file_path = EXCLUDED.file_path, file_content = EXCLUDED.file_content, file_hash = EXCLUDED.file_hash, synced_at = EXCLUDED.synced_at
          `,a++}}catch(e){console.error("âŒ",s.table,e.message)}}return{status:"success",operation:"pumpdata",files_scanned:t.length,tables_loaded:a}}function I(){let e=R(),t=[];return!function a(s){if(y.existsSync(s))for(let n of y.readdirSync(s,{withFileTypes:!0})){let i=g.join(s,n.name),r=g.relative(e,i);if(n.isDirectory())C.includes(n.name)||a(i);else if(S.includes(g.extname(i).toLowerCase()))try{let e=y.readFileSync(i,"utf-8"),a=D.createHash("sha256").update(e).digest("hex"),{table:s,fileType:n}=N(i);"unknown"!==s&&t.push({path:i,relativePath:r,content:e,hash:a,table:s,fileType:n})}catch(e){console.warn(`âš ï¸  Failed to read: ${i}`)}}}(e),t}async function A(e){console.log("ðŸ“¥ Pumping data...");let t=I(),a={collections:[],static_files:[],config_files:[],data_files:[],images:[],resumes:[],javascript_files:[],sync_manifest:[]};for(let e of t){let t=g.basename(e.relativePath,g.extname(e.relativePath)),s=w(e.relativePath),n=new Date().toISOString();switch(a.sync_manifest.push({file_path:e.relativePath,file_hash:e.hash,table_name:e.table,last_synced:n}),e.table){case"collections":{let s=e.relativePath.split(g.sep),i=s.findIndex(e=>"collections"===e);if(-1!==i&&i+2<s.length)try{a.collections.push({lang:s[i+1],type:s[i+2],filename:t,file_content:JSON.parse(e.content),file_hash:e.hash,synced_at:n})}catch(t){console.warn(`âš ï¸  Invalid JSON: ${e.relativePath}`)}break}case"static_files":a.static_files.push({filename:t,file_type:s,file_content:e.content,file_hash:e.hash,synced_at:n});break;case"config_files":try{a.config_files.push({filename:t,file_type:s,file_content:JSON.parse(e.content),file_hash:e.hash,synced_at:n})}catch(t){console.warn(`âš ï¸  Invalid JSON: ${e.relativePath}`)}break;case"data_files":try{a.data_files.push({filename:t,file_type:s,file_content:JSON.parse(e.content),file_hash:e.hash,synced_at:n})}catch(t){console.warn(`âš ï¸  Invalid JSON: ${e.relativePath}`)}break;case"images":a.images.push({filename:t,file_path:e.relativePath,mime_type:`image/${s}`,file_hash:e.hash,synced_at:n});break;case"resumes":a.resumes.push({filename:t,file_type:s,file_path:e.relativePath,file_hash:e.hash,synced_at:n});break;case"javascript_files":a.javascript_files.push({filename:t,file_path:e.relativePath,file_content:e.content,file_hash:e.hash,synced_at:n})}}let s=0;for(let[t,n]of Object.entries(a))if(0!==n.length)try{await e.from(t).insert(n),s++}catch(e){console.error(`âŒ ${t}: ${e.message}`)}return{status:"success",operation:"pumpdata",files_scanned:t.length,tables_loaded:s}}async function P(e){console.log("ðŸ”„ Syncing /public...");let t=I(),a={new:0,modified:0,deleted:0};try{let{data:s}=await e.from("sync_manifest").select("*"),n=new Map((s||[]).map(e=>[e.file_path,e]));for(let e of t){let t=n.get(e.relativePath);t?t.file_hash!==e.hash&&a.modified++:a.new++}for(let[e]of n)!t.find(t=>t.relativePath===e)&&a.deleted++}catch(e){return{status:"error",operation:"syncopublic",error:e.message}}return{status:"success",operation:"syncopublic",files_scanned:t.length,changes:a}}async function U(e){console.log("[ADMIN OPERATIONS] POST request received");try{let t,a=e.headers?.get?.("x-vercel-id"),s=process.env.VERCEL_REGION||"unknown-region",n=process.env.VERCEL_ENV||"production";console.log("[ADMIN OPERATIONS] Env",{vercelId:a,region:s,env:n});let{mode:i,sql:r,supabase:l}=b.db(),o="postgres"===i;console.log("[ADMIN OPERATIONS] DB mode",{mode:i});let{operation:c,batch:d}=await e.json();if(console.log("[ADMIN OPERATIONS] Operation:",c,"Batch:",d),d&&Array.isArray(d)){let e=[];for(let t of d){let a;try{switch(t.toLowerCase()){case"createdb":a=await b.createdb();break;case"deletedb":a=await b.deletedb();break;case"pumpdata":a=o?await v(r):await A(l);break;case"syncopublic":a=o?await T(r):await P(l);break;case"status":{let e={};for(let t of b.TABLES)e[t]=await b.count(t);let t=I();a={status:"success",operation:"status",database:e,public_folder_files:t.length,timestamp:new Date().toISOString()};break}default:a={status:"error",operation:t,error:"Unknown operation"}}console.log("[ADMIN OPERATIONS] Batch operation result:",a)}catch(e){console.log("[ADMIN OPERATIONS] Batch Exception:",e.message),a={status:"error",operation:t,error:e.message}}e.push(a)}try{console.log("[ADMIN OPERATIONS] Redis cache simulated for batch")}catch(e){console.log("[ADMIN OPERATIONS] Redis Exception:",e.message)}return O.json({status:"success",operations:d,results:e,timestamp:new Date().toISOString()})}try{switch(c?.toLowerCase()){case"createdb":t=await b.createdb();break;case"deletedb":t=await b.deletedb();break;case"pumpdata":t=o?await v(r):await A(l);break;case"syncopublic":t=o?await T(r):await P(l);break;case"status":{let e={};for(let t of b.TABLES)e[t]=await b.count(t);let a=I();t={status:"success",operation:"status",database:e,public_folder_files:a.length,timestamp:new Date().toISOString()};break}default:throw Error("Unknown operation. Use: createdb, deletedb, pumpdata, syncopublic, status")}console.log("[ADMIN OPERATIONS] Operation result:",t)}catch(e){console.log("[ADMIN OPERATIONS] Operation Exception:",e.message),t={status:"error",error:e.message}}try{console.log("[ADMIN OPERATIONS] Redis cache simulated for operation")}catch(e){console.log("[ADMIN OPERATIONS] Redis Exception:",e.message)}return O.json({...t,timestamp:new Date().toISOString()})}catch(e){return console.log("[ADMIN OPERATIONS] Handler error:",e.message),O.json({status:"error",error:e.message},{status:500})}}async function L(){return O.json({status:"success",message:"Admin Operations API",available_operations:[{name:"createdb",description:"Create all database tables"},{name:"deletedb",description:"Delete all data from tables"},{name:"pumpdata",description:"Load data from /public to database"},{name:"syncopublic",description:"Detect changes in /public folder"},{name:"status",description:"Get system status and counts"}],usage:{single:'POST /api/admin/operations { "operation": "createdb" }',batch:'POST /api/admin/operations { "batch": ["createdb", "pumpdata", "status"] }'}})}e.s(["GET",()=>L,"POST",()=>U],75394);var $=e.i(75394);let x=new t.AppRouteRouteModule({definition:{kind:a.RouteKind.APP_ROUTE,page:"/api/admin/operations/route",pathname:"/api/admin/operations",filename:"route",bundlePath:""},distDir:".next",relativeProjectDir:"",resolvedPagePath:"[project]/app/api/admin/operations/route.js",nextConfigOutput:"",userland:$}),{workAsyncStorage:k,workUnitAsyncStorage:X,serverHooks:M}=x;function j(){return(0,s.patchFetch)({workAsyncStorage:k,workUnitAsyncStorage:X})}async function F(e,t,s){x.isDev&&(0,n.addRequestMeta)(e,"devRequestTimingInternalsEnd",process.hrtime.bigint());let y="/api/admin/operations/route";y=y.replace(/\/index$/,"")||"/";let g=await x.prepare(e,t,{srcPage:y,multiZoneDraftMode:!1});if(!g)return t.statusCode=400,t.end("Bad Request"),null==s.waitUntil||s.waitUntil.call(s,Promise.resolve()),null;let{buildId:D,params:O,nextConfig:b,parsedUrl:N,isDraftMode:w,prerenderManifest:S,routerServerContext:C,isOnDemandRevalidate:R,revalidateOnlyGenerated:T,resolvedPathname:v,clientReferenceManifest:I,serverActionsManifest:A}=g,P=(0,l.normalizeAppPath)(y),U=!!(S.dynamicRoutes[P]||S.routes[v]),L=async()=>((null==C?void 0:C.render404)?await C.render404(e,t,N,!1):t.end("This page could not be found"),null);if(U&&!w){let e=!!S.routes[v],t=S.dynamicRoutes[P];if(t&&!1===t.fallback&&!e){if(b.experimental.adapterPath)return await L();throw new E.NoFallbackError}}let $=null;!U||x.isDev||w||($="/index"===($=v)?"/":$);let k=!0===x.isDev||!U,X=U&&!k;A&&I&&(0,r.setManifestsSingleton)({page:y,clientReferenceManifest:I,serverActionsManifest:A});let M=e.method||"GET",j=(0,i.getTracer)(),F=j.getActiveScopeSpan(),H={params:O,prerenderManifest:S,renderOpts:{experimental:{authInterrupts:!!b.experimental.authInterrupts},cacheComponents:!!b.cacheComponents,supportsDynamicResponse:k,incrementalCache:(0,n.getRequestMeta)(e,"incrementalCache"),cacheLifeProfiles:b.cacheLife,waitUntil:s.waitUntil,onClose:e=>{t.on("close",e)},onAfterTaskError:void 0,onInstrumentationRequestError:(t,a,s,n)=>x.onRequestError(e,t,s,n,C)},sharedContext:{buildId:D}},q=new o.NodeNextRequest(e),V=new o.NodeNextResponse(t),B=c.NextRequestAdapter.fromNodeNextRequest(q,(0,c.signalFromNodeResponse)(t));try{let r=async e=>x.handle(B,H).finally(()=>{if(!e)return;e.setAttributes({"http.status_code":t.statusCode,"next.rsc":!1});let a=j.getRootSpanAttributes();if(!a)return;if(a.get("next.span_type")!==d.BaseServerSpan.handleRequest)return void console.warn(`Unexpected root span type '${a.get("next.span_type")}'. Please report this Next.js issue https://github.com/vercel/next.js`);let s=a.get("next.route");if(s){let t=`${M} ${s}`;e.setAttributes({"next.route":s,"http.route":s,"next.span_name":t}),e.updateName(t)}else e.updateName(`${M} ${y}`)}),l=!!(0,n.getRequestMeta)(e,"minimalMode"),o=async n=>{var i,o;let c=async({previousCacheEntry:a})=>{try{if(!l&&R&&T&&!a)return t.statusCode=404,t.setHeader("x-nextjs-cache","REVALIDATED"),t.end("This page could not be found"),null;let i=await r(n);e.fetchMetrics=H.renderOpts.fetchMetrics;let o=H.renderOpts.pendingWaitUntil;o&&s.waitUntil&&(s.waitUntil(o),o=void 0);let c=H.renderOpts.collectedTags;if(!U)return await (0,p.sendResponse)(q,V,i,H.renderOpts.pendingWaitUntil),null;{let e=await i.blob(),t=(0,f.toNodeOutgoingHttpHeaders)(i.headers);c&&(t[_.NEXT_CACHE_TAGS_HEADER]=c),!t["content-type"]&&e.type&&(t["content-type"]=e.type);let a=void 0!==H.renderOpts.collectedRevalidate&&!(H.renderOpts.collectedRevalidate>=_.INFINITE_CACHE)&&H.renderOpts.collectedRevalidate,s=void 0===H.renderOpts.collectedExpire||H.renderOpts.collectedExpire>=_.INFINITE_CACHE?void 0:H.renderOpts.collectedExpire;return{value:{kind:m.CachedRouteKind.APP_ROUTE,status:i.status,body:Buffer.from(await e.arrayBuffer()),headers:t},cacheControl:{revalidate:a,expire:s}}}}catch(t){throw(null==a?void 0:a.isStale)&&await x.onRequestError(e,t,{routerKind:"App Router",routePath:y,routeType:"route",revalidateReason:(0,h.getRevalidateReason)({isStaticGeneration:X,isOnDemandRevalidate:R})},!1,C),t}},d=await x.handleResponse({req:e,nextConfig:b,cacheKey:$,routeKind:a.RouteKind.APP_ROUTE,isFallback:!1,prerenderManifest:S,isRoutePPREnabled:!1,isOnDemandRevalidate:R,revalidateOnlyGenerated:T,responseGenerator:c,waitUntil:s.waitUntil,isMinimalMode:l});if(!U)return null;if((null==d||null==(i=d.value)?void 0:i.kind)!==m.CachedRouteKind.APP_ROUTE)throw Object.defineProperty(Error(`Invariant: app-route received invalid cache entry ${null==d||null==(o=d.value)?void 0:o.kind}`),"__NEXT_ERROR_CODE",{value:"E701",enumerable:!1,configurable:!0});l||t.setHeader("x-nextjs-cache",R?"REVALIDATED":d.isMiss?"MISS":d.isStale?"STALE":"HIT"),w&&t.setHeader("Cache-Control","private, no-cache, no-store, max-age=0, must-revalidate");let E=(0,f.fromNodeOutgoingHttpHeaders)(d.value.headers);return l&&U||E.delete(_.NEXT_CACHE_TAGS_HEADER),!d.cacheControl||t.getHeader("Cache-Control")||E.get("Cache-Control")||E.set("Cache-Control",(0,u.getCacheControlHeader)(d.cacheControl)),await (0,p.sendResponse)(q,V,new Response(d.value.body,{headers:E,status:d.value.status||200})),null};F?await o(F):await j.withPropagatedContext(e.headers,()=>j.trace(d.BaseServerSpan.handleRequest,{spanName:`${M} ${y}`,kind:i.SpanKind.SERVER,attributes:{"http.method":M,"http.target":e.url}},o))}catch(t){if(t instanceof E.NoFallbackError||await x.onRequestError(e,t,{routerKind:"App Router",routePath:P,routeType:"route",revalidateReason:(0,h.getRevalidateReason)({isStaticGeneration:X,isOnDemandRevalidate:R})},!1,C),U)throw t;return await (0,p.sendResponse)(q,V,new Response(null,{status:500})),null}}e.s(["handler",()=>F,"patchFetch",()=>j,"routeModule",()=>x,"serverHooks",()=>M,"workAsyncStorage",()=>k,"workUnitAsyncStorage",()=>X],75351)}];

//# sourceMappingURL=node_modules_next_dist_esm_build_templates_app-route_c50ae147.js.map